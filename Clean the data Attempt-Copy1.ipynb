{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77419fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27c4fc",
   "metadata": {},
   "source": [
    "# Read in the data to on dictionary of each Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426f416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On act\n",
      "On acw\n",
      "On dc\n",
      "On pm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, '1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "# Test out the read in helper function\n",
    "def get_subject_action(sensor, full_path):\n",
    "    index = full_path.find(sensor)\n",
    "    index += len(sensor)\n",
    "    subject = int(full_path[index+1:index+3])\n",
    "    action = int(full_path[index+4:index+6])\n",
    "    if action == 4:\n",
    "        if full_path.find(f\"{sensor}_1\") > 0:\n",
    "            action = '4-1'\n",
    "        else:\n",
    "            action = '4-2'\n",
    "        \n",
    "    return (subject, str(action))\n",
    "\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                #print(full_path, get_subject_action(sensor, full_path))\n",
    "                \n",
    "test_str = '.\\\\data\\\\act\\\\01\\\\01_act_1.csv'\n",
    "get_subject_action('act', test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5b8e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d54df7fd843dd9f726e6de5bd6bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data:   0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_data = {\n",
    "    'act': None,\n",
    "    'acw': None,\n",
    "    'dc': None,\n",
    "    'pm': None,\n",
    "}\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'act': ['times', 'X', 'Y', 'Z'],\n",
    "    'acw': ['times', 'X', 'Y', 'Z'],\n",
    "    'dc': ['times'],\n",
    "    'pm': ['times']\n",
    "}\n",
    "for i in range(1,513):\n",
    "    headers['pm'].append(f\"sensor_{i}\")\n",
    "for i in range(1,193):\n",
    "    headers['dc'].append(f\"sensor_{i}\")\n",
    "\n",
    "actions = ['1', '2', '3', '4-1', '4-2', '5', '6', '7']\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "#sensor_list = ['acw']\n",
    "\n",
    "# there are 956 files in our dataset\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(desc=\"load data\", total=956)\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        #print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                df_tmp = pd.read_csv(full_path, names=headers[sensor])\n",
    "                i+=1\n",
    "                pbar.update(1)\n",
    "                subject, action = get_subject_action(sensor, full_path)\n",
    "                # add one to make it match the given format\n",
    "                df_tmp['subject'] = subject\n",
    "                df_tmp['action'] = action\n",
    "                if total_data[sensor] is None:\n",
    "                    total_data[sensor] = df_tmp\n",
    "                else:\n",
    "                    total_data[sensor] = pd.concat([total_data[sensor], df_tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b125061",
   "metadata": {},
   "source": [
    "## Show what is in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a129e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1400856 entries, 0 to 6418\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1400856 non-null  object \n",
      " 1   X        1400856 non-null  float64\n",
      " 2   Y        1400856 non-null  float64\n",
      " 3   Z        1400856 non-null  float64\n",
      " 4   subject  1400856 non-null  int64  \n",
      " 5   action   1400856 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 74.8+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "acw\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1313695 entries, 0 to 6013\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1313695 non-null  object \n",
      " 1   X        1313695 non-null  float64\n",
      " 2   Y        1313695 non-null  float64\n",
      " 3   Z        1313695 non-null  float64\n",
      " 4   subject  1313695 non-null  int64  \n",
      " 5   action   1313695 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 70.2+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "dc\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140694 entries, 0 to 624\n",
      "Columns: 195 entries, times to action\n",
      "dtypes: float64(192), int64(1), object(2)\n",
      "memory usage: 210.4+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "pm\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 202682 entries, 0 to 927\n",
      "Columns: 515 entries, times to action\n",
      "dtypes: float64(512), int64(1), object(2)\n",
      "memory usage: 797.9+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in total_data.keys():\n",
    "    if total_data[key] is not None:\n",
    "        print(key)\n",
    "        print(total_data[key]['action'].unique())\n",
    "        print(total_data[key]['subject'].unique())\n",
    "        for header in headers[key]:\n",
    "            if(total_data[key][header].isnull().values.any()):\n",
    "                print(f\"{header} has Null data\")\n",
    "        print(total_data[key].info())\n",
    "        print('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83bc0733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>2018-11-08 11:35:56.373000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>2018-11-08 11:35:56.383000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>2018-11-08 11:35:56.394000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>2018-11-08 11:35:56.404000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>2018-11-08 11:35:56.414000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           times         X         Y        Z  subject action\n",
       "0     2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1     2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2     2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3     2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4     2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1\n",
       "...                          ...       ...       ...      ...      ...    ...\n",
       "6269  2018-11-08 11:35:56.373000  0.093750 -0.265625  0.87500        1      1\n",
       "6270  2018-11-08 11:35:56.383000  0.093750 -0.281250  0.87500        1      1\n",
       "6271  2018-11-08 11:35:56.394000  0.093750 -0.265625  0.87500        1      1\n",
       "6272  2018-11-08 11:35:56.404000  0.093750 -0.265625  0.87500        1      1\n",
       "6273  2018-11-08 11:35:56.414000  0.093750 -0.265625  0.87500        1      1\n",
       "\n",
       "[6274 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acw = total_data['acw']\n",
    "subject = 1\n",
    "action = '1'\n",
    "df_acw[(df_acw.subject == subject) & (df_acw.action == action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e445b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_505</th>\n",
       "      <th>sensor_506</th>\n",
       "      <th>sensor_507</th>\n",
       "      <th>sensor_508</th>\n",
       "      <th>sensor_509</th>\n",
       "      <th>sensor_510</th>\n",
       "      <th>sensor_511</th>\n",
       "      <th>sensor_512</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.468000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.535000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.602000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.669000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.737000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0  2018-11-08 11:34:51.468000      20.0       3.0       2.0       0.0   \n",
       "1  2018-11-08 11:34:51.535000      20.0       3.0       2.0       0.0   \n",
       "2  2018-11-08 11:34:51.602000      20.0       3.0       2.0       0.0   \n",
       "3  2018-11-08 11:34:51.669000      20.0       3.0       2.0       0.0   \n",
       "4  2018-11-08 11:34:51.737000      20.0       3.0       2.0       0.0   \n",
       "\n",
       "   sensor_5  sensor_6  sensor_7  sensor_8  sensor_9  ...  sensor_505  \\\n",
       "0       0.0       0.0      72.0    1493.0    1949.0  ...        68.0   \n",
       "1       0.0       0.0      72.0    1493.0    1949.0  ...        58.0   \n",
       "2       0.0       0.0      72.0    1493.0    1949.0  ...        64.0   \n",
       "3       0.0       0.0      72.0    1493.0    1949.0  ...        66.0   \n",
       "4       0.0       0.0      72.0    1493.0    1949.0  ...        64.0   \n",
       "\n",
       "   sensor_506  sensor_507  sensor_508  sensor_509  sensor_510  sensor_511  \\\n",
       "0        77.0        55.0       193.0       387.0       331.0       125.0   \n",
       "1        78.0        53.0       192.0       388.0       330.0       123.0   \n",
       "2        78.0        53.0       195.0       390.0       330.0       119.0   \n",
       "3        79.0        55.0       196.0       391.0       324.0       106.0   \n",
       "4        79.0        55.0       194.0       391.0       321.0       114.0   \n",
       "\n",
       "   sensor_512  subject  action  \n",
       "0         6.0        1       1  \n",
       "1         6.0        1       1  \n",
       "2         7.0        1       1  \n",
       "3         5.0        1       1  \n",
       "4         6.0        1       1  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data['pm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91052a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  4],\n",
       "       [ 4,  5,  6,  4,  5,  6,  7,  5,  6,  7,  8,  9],\n",
       "       [ 7,  8,  9,  8,  9, 10, 11, 10, 11, 12, 13, 14],\n",
       "       [10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19],\n",
       "       [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
       "       [16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show reshape is doing what we think\n",
    "x = np.array([[1,2,3],\n",
    "          [4,5,6],\n",
    "          [7,8,9],\n",
    "          [10,11,12],\n",
    "          [13,14,15],\n",
    "          [16,17,18]])\n",
    "y = np.array(range(0,24))\n",
    "y = np.reshape(y, (6,4))\n",
    "\n",
    "z = np.array(range(0,30))\n",
    "z = np.reshape(z, (6, 5))\n",
    "\n",
    "\n",
    "np.hstack((x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe597356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c88b6d0119408fa3d97e2486fb8d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch data:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acw_X_0</th>\n",
       "      <th>acw_Y_0</th>\n",
       "      <th>acw_Z_0</th>\n",
       "      <th>acw_X_1</th>\n",
       "      <th>acw_Y_1</th>\n",
       "      <th>acw_Z_1</th>\n",
       "      <th>acw_X_2</th>\n",
       "      <th>acw_Y_2</th>\n",
       "      <th>acw_Z_2</th>\n",
       "      <th>acw_X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>act_X_297</th>\n",
       "      <th>act_Y_297</th>\n",
       "      <th>act_Z_297</th>\n",
       "      <th>act_X_298</th>\n",
       "      <th>act_Y_298</th>\n",
       "      <th>act_Z_298</th>\n",
       "      <th>act_X_299</th>\n",
       "      <th>act_Y_299</th>\n",
       "      <th>act_Z_299</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640625</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>-0.656250</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.671875</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.796875</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acw_X_0   acw_Y_0   acw_Z_0   acw_X_1   acw_Y_1   acw_Z_1   acw_X_2  \\\n",
       "0  0.125000 -0.046875  0.906250  0.109375 -0.062500  0.906250  0.109375   \n",
       "1  0.156250 -0.062500  0.906250  0.156250 -0.062500  0.890625  0.156250   \n",
       "2  0.218750 -0.078125  0.890625  0.218750 -0.078125  0.875000  0.234375   \n",
       "3  0.281250 -0.093750  0.859375  0.281250 -0.093750  0.875000  0.281250   \n",
       "4  0.359375 -0.062500  0.843750  0.359375 -0.062500  0.843750  0.359375   \n",
       "\n",
       "    acw_Y_2   acw_Z_2   acw_X_3  ...  act_X_297  act_Y_297  act_Z_297  \\\n",
       "0 -0.062500  0.906250  0.125000  ...  -0.640625  -0.562500   0.437500   \n",
       "1 -0.062500  0.890625  0.156250  ...  -0.625000  -0.796875   0.171875   \n",
       "2 -0.078125  0.890625  0.234375  ...  -0.593750  -0.750000   0.281250   \n",
       "3 -0.093750  0.859375  0.281250  ...  -0.593750  -0.734375   0.296875   \n",
       "4 -0.078125  0.843750  0.359375  ...  -0.593750  -0.734375   0.312500   \n",
       "\n",
       "   act_X_298  act_Y_298  act_Z_298  act_X_299  act_Y_299  act_Z_299  action  \n",
       "0  -0.656250  -0.562500   0.468750  -0.671875  -0.578125   0.468750       1  \n",
       "1  -0.625000  -0.781250   0.171875  -0.625000  -0.781250   0.171875       1  \n",
       "2  -0.609375  -0.750000   0.296875  -0.609375  -0.750000   0.296875       1  \n",
       "3  -0.593750  -0.734375   0.296875  -0.593750  -0.734375   0.296875       1  \n",
       "4  -0.578125  -0.734375   0.312500  -0.593750  -0.734375   0.296875       1  \n",
       "\n",
       "[5 rows x 33481 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# take the total dfs and make batches for each action each subject completed\n",
    "# samples100 is how many samples should be in the 100HZ (the two accleromter data)\n",
    "# samples15 is how many samples from the images should be take\n",
    "subjects = range(1,31)\n",
    "dc_X_cols = [f\"sensor_{i}\" for i in range(1,193)]\n",
    "pm_X_cols = [f\"sensor_{i}\" for i in range(1,513)]\n",
    "acw_X_cols = [\"X\", \"Y\", \"Z\"]\n",
    "\n",
    "def batch_data(total_dfs, seconds=5):\n",
    "    samples100 = 100*seconds\n",
    "    samples15 = 15*seconds\n",
    "    df_acw = total_dfs['acw']\n",
    "    df_act = total_dfs['act']\n",
    "    df_dc = total_dfs['dc']\n",
    "    df_pm = total_dfs['pm']\n",
    "    \n",
    "    all_cols = []\n",
    "    for i in range(0, samples100):\n",
    "        all_cols += [f\"acw_{val}_{i}\" for val in acw_X_cols]\n",
    "    for i in range(0, samples15):\n",
    "        all_cols += [f\"dc_{val}_{i}\" for val in dc_X_cols]\n",
    "    for i in range(0, samples15):\n",
    "        all_cols += [f\"pm_{val}_{i}\" for val in pm_X_cols]\n",
    "    for i in range(0, samples100):\n",
    "        all_cols += [f\"act_{val}_{i}\" for val in acw_X_cols]\n",
    "    \n",
    "    \n",
    "    df_all = pd.DataFrame(columns=all_cols+['action'])\n",
    "    \n",
    "    actions = df_acw['action'].unique()\n",
    "    pbar = tqdm(desc=\"batch data\", total=len(subjects)*len(actions))\n",
    "    for subject in subjects:\n",
    "        actions = df_acw['action'].unique()\n",
    "        for action in actions:\n",
    "            X_acw = df_acw[(df_acw.subject == subject) & (df_acw.action == action)][acw_X_cols].to_numpy()\n",
    "            X_acw = X_acw[range(0, (X_acw.shape[0]//samples100)*samples100)] # cut off records that don't fit in the window\n",
    "            X_acw = np.reshape(X_acw, (X_acw.shape[0]//samples100, samples100*len(acw_X_cols)))\n",
    "            \n",
    "            X_dc = df_dc[(df_dc.subject == subject) & (df_dc.action == action)][dc_X_cols].to_numpy()\n",
    "            X_dc = X_dc[range(0, (X_dc.shape[0]//samples15)*samples15)]\n",
    "            X_dc = np.reshape(X_dc, (X_dc.shape[0]//samples15, samples15*len(dc_X_cols)))\n",
    "            \n",
    "            X_pm = df_pm[(df_pm.subject == subject) & (df_pm.action == action)][pm_X_cols].to_numpy()\n",
    "            X_pm = X_pm[range(0, (X_pm.shape[0]//samples15)*samples15)]\n",
    "            X_pm = np.reshape(X_pm, (X_pm.shape[0]//samples15, samples15*len(pm_X_cols)))\n",
    "            \n",
    "            X_act = df_act[(df_act.subject == subject) & (df_act.action == action)][acw_X_cols].to_numpy()\n",
    "            X_act = X_act[range(0, (X_act.shape[0]//samples100)*samples100)]\n",
    "            X_act = np.reshape(X_act, (X_act.shape[0]//samples100, samples100*len(acw_X_cols)))\n",
    "            \n",
    "            # trim to the smallest one of these 4\n",
    "            num_records = min(X_acw.shape[0], X_act.shape[0], X_pm.shape[0], X_dc.shape[0])\n",
    "            X_acw = X_acw[range(0,num_records)]\n",
    "            X_dc = X_dc[range(0,num_records)]\n",
    "            X_pm = X_pm[range(0,num_records)]\n",
    "            X_act = X_act[range(0,num_records)]\n",
    "            \n",
    "            X_total = np.hstack((X_acw, X_dc, X_pm, X_act))\n",
    "            \n",
    "            df_tmp = pd.DataFrame(X_total, columns=all_cols)\n",
    "            df_tmp['action'] = action\n",
    "            df_all = pd.concat([df_all, df_tmp])\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "    return df_all\n",
    "\n",
    "df_batched = batch_data(total_data, seconds=3)\n",
    "df_batched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e15e1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acw_X_0</th>\n",
       "      <th>acw_Y_0</th>\n",
       "      <th>acw_Z_0</th>\n",
       "      <th>acw_X_1</th>\n",
       "      <th>acw_Y_1</th>\n",
       "      <th>acw_Z_1</th>\n",
       "      <th>acw_X_2</th>\n",
       "      <th>acw_Y_2</th>\n",
       "      <th>acw_Z_2</th>\n",
       "      <th>acw_X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>act_Z_296</th>\n",
       "      <th>act_X_297</th>\n",
       "      <th>act_Y_297</th>\n",
       "      <th>act_Z_297</th>\n",
       "      <th>act_X_298</th>\n",
       "      <th>act_Y_298</th>\n",
       "      <th>act_Z_298</th>\n",
       "      <th>act_X_299</th>\n",
       "      <th>act_Y_299</th>\n",
       "      <th>act_Z_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>...</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>...</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>...</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-1</th>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>...</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>...</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>...</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acw_X_0  acw_Y_0  acw_Z_0  acw_X_1  acw_Y_1  acw_Z_1  acw_X_2  \\\n",
       "action                                                                  \n",
       "1           419      419      419      419      419      419      419   \n",
       "2           447      447      447      447      447      447      447   \n",
       "3           449      449      449      449      449      449      449   \n",
       "4-1         226      226      226      226      226      226      226   \n",
       "4-2         198      198      198      198      198      198      198   \n",
       "5           427      427      427      427      427      427      427   \n",
       "6           398      398      398      398      398      398      398   \n",
       "7           441      441      441      441      441      441      441   \n",
       "\n",
       "        acw_Y_2  acw_Z_2  acw_X_3  ...  act_Z_296  act_X_297  act_Y_297  \\\n",
       "action                             ...                                    \n",
       "1           419      419      419  ...        419        419        419   \n",
       "2           447      447      447  ...        447        447        447   \n",
       "3           449      449      449  ...        449        449        449   \n",
       "4-1         226      226      226  ...        226        226        226   \n",
       "4-2         198      198      198  ...        198        198        198   \n",
       "5           427      427      427  ...        427        427        427   \n",
       "6           398      398      398  ...        398        398        398   \n",
       "7           441      441      441  ...        441        441        441   \n",
       "\n",
       "        act_Z_297  act_X_298  act_Y_298  act_Z_298  act_X_299  act_Y_299  \\\n",
       "action                                                                     \n",
       "1             419        419        419        419        419        419   \n",
       "2             447        447        447        447        447        447   \n",
       "3             449        449        449        449        449        449   \n",
       "4-1           226        226        226        226        226        226   \n",
       "4-2           198        198        198        198        198        198   \n",
       "5             427        427        427        427        427        427   \n",
       "6             398        398        398        398        398        398   \n",
       "7             441        441        441        441        441        441   \n",
       "\n",
       "        act_Z_299  \n",
       "action             \n",
       "1             419  \n",
       "2             447  \n",
       "3             449  \n",
       "4-1           226  \n",
       "4-2           198  \n",
       "5             427  \n",
       "6             398  \n",
       "7             441  \n",
       "\n",
       "[8 rows x 33480 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batched.groupby('action').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72df9b6",
   "metadata": {},
   "source": [
    "# Stick the data into a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4218b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = 3\n",
    "samples100 = 100*seconds\n",
    "samples15 = 15*seconds\n",
    "\n",
    "all_cols = []\n",
    "for i in range(0, samples100):\n",
    "    all_cols += [f\"acw_{val}_{i}\" for val in acw_X_cols]\n",
    "for i in range(0, samples15):\n",
    "    all_cols += [f\"dc_{val}_{i}\" for val in dc_X_cols]\n",
    "for i in range(0, samples15):\n",
    "    all_cols += [f\"pm_{val}_{i}\" for val in pm_X_cols]\n",
    "for i in range(0, samples100):\n",
    "    all_cols += [f\"act_{val}_{i}\" for val in acw_X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72132f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3005, 33480)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_batched[all_cols].to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9cb0aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.get_dummies(df_batched.action, prefix='action_ohe')\n",
    "y = df_y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2baead",
   "metadata": {},
   "source": [
    "### Train test split real quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1302b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17b02d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Input, GRU, SimpleRNN, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "def get_combined_model():\n",
    "    input_all = Input(shape=(X.shape[1],))\n",
    "    x = Dense(units=2048, activation='sigmoid',kernel_initializer='random_normal')(input_all)\n",
    "    x = Dense(units=1024, activation='sigmoid',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(units=512, activation='sigmoid',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "    prediction = Dense(units=8, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_all, outputs=prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba4a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 33480)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              68569088  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 71,984,136\n",
      "Trainable params: 71,984,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model = get_combined_model()\n",
    "model.compile(optimizer=Adam(learning_rate=0.000001, beta_1=0.99, beta_2=0.999),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0c56351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2404 samples, validate on 601 samples\n",
      "Epoch 1/200\n",
      "2404/2404 [==============================] - 5s 2ms/sample - loss: 2.2838 - accuracy: 0.1331 - val_loss: 2.0574 - val_accuracy: 0.1464\n",
      "Epoch 2/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2493 - accuracy: 0.1485 - val_loss: 2.0255 - val_accuracy: 0.1597\n",
      "Epoch 3/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2334 - accuracy: 0.1402 - val_loss: 2.0164 - val_accuracy: 0.1614\n",
      "Epoch 4/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2151 - accuracy: 0.1498 - val_loss: 2.0080 - val_accuracy: 0.2246\n",
      "Epoch 5/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1825 - accuracy: 0.1577 - val_loss: 2.0022 - val_accuracy: 0.2579\n",
      "Epoch 6/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 2.1848 - accuracy: 0.1585 - val_loss: 1.9948 - val_accuracy: 0.3028\n",
      "Epoch 7/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 2.1971 - accuracy: 0.1593 - val_loss: 1.9878 - val_accuracy: 0.3228\n",
      "Epoch 8/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 2.1872 - accuracy: 0.1514 - val_loss: 1.9816 - val_accuracy: 0.3261\n",
      "Epoch 9/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1932 - accuracy: 0.1443 - val_loss: 1.9753 - val_accuracy: 0.3311\n",
      "Epoch 10/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1679 - accuracy: 0.1664 - val_loss: 1.9689 - val_accuracy: 0.3627\n",
      "Epoch 11/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1929 - accuracy: 0.1531 - val_loss: 1.9610 - val_accuracy: 0.3727\n",
      "Epoch 12/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1719 - accuracy: 0.1651 - val_loss: 1.9549 - val_accuracy: 0.3894\n",
      "Epoch 13/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1413 - accuracy: 0.1701 - val_loss: 1.9483 - val_accuracy: 0.4110\n",
      "Epoch 14/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1585 - accuracy: 0.1668 - val_loss: 1.9419 - val_accuracy: 0.4010\n",
      "Epoch 15/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1453 - accuracy: 0.1822 - val_loss: 1.9331 - val_accuracy: 0.4326\n",
      "Epoch 16/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1559 - accuracy: 0.1739 - val_loss: 1.9278 - val_accuracy: 0.4359\n",
      "Epoch 17/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1676 - accuracy: 0.1643 - val_loss: 1.9202 - val_accuracy: 0.4493\n",
      "Epoch 18/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1285 - accuracy: 0.1789 - val_loss: 1.9105 - val_accuracy: 0.4559\n",
      "Epoch 19/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1405 - accuracy: 0.1893 - val_loss: 1.9055 - val_accuracy: 0.4476\n",
      "Epoch 20/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1208 - accuracy: 0.1780 - val_loss: 1.8974 - val_accuracy: 0.4692\n",
      "Epoch 21/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0849 - accuracy: 0.1963 - val_loss: 1.8902 - val_accuracy: 0.4642\n",
      "Epoch 22/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0992 - accuracy: 0.1905 - val_loss: 1.8822 - val_accuracy: 0.4908\n",
      "Epoch 23/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1198 - accuracy: 0.1872 - val_loss: 1.8742 - val_accuracy: 0.4908\n",
      "Epoch 24/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0820 - accuracy: 0.2047 - val_loss: 1.8644 - val_accuracy: 0.4942\n",
      "Epoch 25/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1038 - accuracy: 0.1901 - val_loss: 1.8564 - val_accuracy: 0.5075\n",
      "Epoch 26/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0747 - accuracy: 0.2009 - val_loss: 1.8468 - val_accuracy: 0.5092\n",
      "Epoch 27/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0676 - accuracy: 0.2051 - val_loss: 1.8399 - val_accuracy: 0.5042\n",
      "Epoch 28/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0807 - accuracy: 0.1943 - val_loss: 1.8309 - val_accuracy: 0.5208\n",
      "Epoch 29/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0374 - accuracy: 0.2130 - val_loss: 1.8218 - val_accuracy: 0.5058\n",
      "Epoch 30/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0606 - accuracy: 0.2105 - val_loss: 1.8121 - val_accuracy: 0.5358\n",
      "Epoch 31/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0597 - accuracy: 0.2076 - val_loss: 1.8022 - val_accuracy: 0.5208\n",
      "Epoch 32/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0259 - accuracy: 0.2292 - val_loss: 1.7926 - val_accuracy: 0.5324\n",
      "Epoch 33/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0178 - accuracy: 0.2200 - val_loss: 1.7840 - val_accuracy: 0.5524\n",
      "Epoch 34/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 2.0218 - accuracy: 0.2225 - val_loss: 1.7760 - val_accuracy: 0.5674\n",
      "Epoch 35/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0133 - accuracy: 0.2167 - val_loss: 1.7642 - val_accuracy: 0.5491\n",
      "Epoch 36/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0151 - accuracy: 0.2292 - val_loss: 1.7531 - val_accuracy: 0.5657\n",
      "Epoch 37/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0028 - accuracy: 0.2309 - val_loss: 1.7430 - val_accuracy: 0.5707\n",
      "Epoch 38/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9749 - accuracy: 0.2479 - val_loss: 1.7321 - val_accuracy: 0.5807\n",
      "Epoch 39/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.9779 - accuracy: 0.2450 - val_loss: 1.7213 - val_accuracy: 0.5757\n",
      "Epoch 40/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.9724 - accuracy: 0.2446 - val_loss: 1.7104 - val_accuracy: 0.5840\n",
      "Epoch 41/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.9358 - accuracy: 0.2716 - val_loss: 1.6982 - val_accuracy: 0.5790\n",
      "Epoch 42/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.9504 - accuracy: 0.2629 - val_loss: 1.6856 - val_accuracy: 0.5824\n",
      "Epoch 43/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.9274 - accuracy: 0.2733 - val_loss: 1.6729 - val_accuracy: 0.5874\n",
      "Epoch 44/200\n",
      "2404/2404 [==============================] - 2s 653us/sample - loss: 1.9403 - accuracy: 0.2571 - val_loss: 1.6617 - val_accuracy: 0.5940\n",
      "Epoch 45/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8943 - accuracy: 0.3032 - val_loss: 1.6491 - val_accuracy: 0.6023\n",
      "Epoch 46/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.8850 - accuracy: 0.2708 - val_loss: 1.6377 - val_accuracy: 0.5923\n",
      "Epoch 47/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.8980 - accuracy: 0.2779 - val_loss: 1.6235 - val_accuracy: 0.5890\n",
      "Epoch 48/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8866 - accuracy: 0.2899 - val_loss: 1.6116 - val_accuracy: 0.5940\n",
      "Epoch 49/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8789 - accuracy: 0.2837 - val_loss: 1.5973 - val_accuracy: 0.6090\n",
      "Epoch 50/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8485 - accuracy: 0.3049 - val_loss: 1.5844 - val_accuracy: 0.5940\n",
      "Epoch 51/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8630 - accuracy: 0.3032 - val_loss: 1.5702 - val_accuracy: 0.6073\n",
      "Epoch 52/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8038 - accuracy: 0.3299 - val_loss: 1.5564 - val_accuracy: 0.6090\n",
      "Epoch 53/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8270 - accuracy: 0.3224 - val_loss: 1.5415 - val_accuracy: 0.6106\n",
      "Epoch 54/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8359 - accuracy: 0.3132 - val_loss: 1.5271 - val_accuracy: 0.6123\n",
      "Epoch 55/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8006 - accuracy: 0.3315 - val_loss: 1.5124 - val_accuracy: 0.6123\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7752 - accuracy: 0.3557 - val_loss: 1.4983 - val_accuracy: 0.6073\n",
      "Epoch 57/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7629 - accuracy: 0.3473 - val_loss: 1.4833 - val_accuracy: 0.6123\n",
      "Epoch 58/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7473 - accuracy: 0.3623 - val_loss: 1.4688 - val_accuracy: 0.6206\n",
      "Epoch 59/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7494 - accuracy: 0.3619 - val_loss: 1.4548 - val_accuracy: 0.6156\n",
      "Epoch 60/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7315 - accuracy: 0.3669 - val_loss: 1.4399 - val_accuracy: 0.6173\n",
      "Epoch 61/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7065 - accuracy: 0.3802 - val_loss: 1.4248 - val_accuracy: 0.6206\n",
      "Epoch 62/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7120 - accuracy: 0.3702 - val_loss: 1.4101 - val_accuracy: 0.6223\n",
      "Epoch 63/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.6907 - accuracy: 0.3827 - val_loss: 1.3956 - val_accuracy: 0.6223\n",
      "Epoch 64/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.7008 - accuracy: 0.3640 - val_loss: 1.3814 - val_accuracy: 0.6156\n",
      "Epoch 65/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6684 - accuracy: 0.3939 - val_loss: 1.3669 - val_accuracy: 0.6173\n",
      "Epoch 66/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.6538 - accuracy: 0.3844 - val_loss: 1.3510 - val_accuracy: 0.6273\n",
      "Epoch 67/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.6417 - accuracy: 0.4060 - val_loss: 1.3371 - val_accuracy: 0.6290\n",
      "Epoch 68/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.6376 - accuracy: 0.4106 - val_loss: 1.3224 - val_accuracy: 0.6323\n",
      "Epoch 69/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.6073 - accuracy: 0.4176 - val_loss: 1.3086 - val_accuracy: 0.6306\n",
      "Epoch 70/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.5904 - accuracy: 0.4226 - val_loss: 1.2947 - val_accuracy: 0.6389\n",
      "Epoch 71/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5851 - accuracy: 0.4305 - val_loss: 1.2794 - val_accuracy: 0.6356\n",
      "Epoch 72/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5663 - accuracy: 0.4430 - val_loss: 1.2660 - val_accuracy: 0.6389\n",
      "Epoch 73/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5396 - accuracy: 0.4555 - val_loss: 1.2522 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5233 - accuracy: 0.4472 - val_loss: 1.2390 - val_accuracy: 0.6389\n",
      "Epoch 75/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5199 - accuracy: 0.4576 - val_loss: 1.2256 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4887 - accuracy: 0.4767 - val_loss: 1.2123 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4803 - accuracy: 0.4742 - val_loss: 1.1996 - val_accuracy: 0.6423\n",
      "Epoch 78/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4600 - accuracy: 0.4775 - val_loss: 1.1878 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4577 - accuracy: 0.4759 - val_loss: 1.1745 - val_accuracy: 0.6473\n",
      "Epoch 80/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.4601 - accuracy: 0.4750 - val_loss: 1.1632 - val_accuracy: 0.6506\n",
      "Epoch 81/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4228 - accuracy: 0.4854 - val_loss: 1.1514 - val_accuracy: 0.6456\n",
      "Epoch 82/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.4123 - accuracy: 0.4975 - val_loss: 1.1407 - val_accuracy: 0.6456\n",
      "Epoch 83/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4085 - accuracy: 0.5075 - val_loss: 1.1302 - val_accuracy: 0.6439\n",
      "Epoch 84/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3837 - accuracy: 0.5033 - val_loss: 1.1188 - val_accuracy: 0.6539\n",
      "Epoch 85/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3667 - accuracy: 0.5183 - val_loss: 1.1072 - val_accuracy: 0.6506\n",
      "Epoch 86/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.3466 - accuracy: 0.5196 - val_loss: 1.0972 - val_accuracy: 0.6489\n",
      "Epoch 87/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.3470 - accuracy: 0.5262 - val_loss: 1.0853 - val_accuracy: 0.6522\n",
      "Epoch 88/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3276 - accuracy: 0.5295 - val_loss: 1.0746 - val_accuracy: 0.6556\n",
      "Epoch 89/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3149 - accuracy: 0.5354 - val_loss: 1.0648 - val_accuracy: 0.6589\n",
      "Epoch 90/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2993 - accuracy: 0.5532 - val_loss: 1.0545 - val_accuracy: 0.6539\n",
      "Epoch 91/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2938 - accuracy: 0.5566 - val_loss: 1.0453 - val_accuracy: 0.6606\n",
      "Epoch 92/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2715 - accuracy: 0.5528 - val_loss: 1.0347 - val_accuracy: 0.6672\n",
      "Epoch 93/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2574 - accuracy: 0.5670 - val_loss: 1.0268 - val_accuracy: 0.6689\n",
      "Epoch 94/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2538 - accuracy: 0.5516 - val_loss: 1.0166 - val_accuracy: 0.6689\n",
      "Epoch 95/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2526 - accuracy: 0.5532 - val_loss: 1.0073 - val_accuracy: 0.6705\n",
      "Epoch 96/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.2350 - accuracy: 0.5595 - val_loss: 1.0005 - val_accuracy: 0.6672\n",
      "Epoch 97/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2208 - accuracy: 0.5666 - val_loss: 0.9914 - val_accuracy: 0.6755\n",
      "Epoch 98/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2051 - accuracy: 0.5865 - val_loss: 0.9839 - val_accuracy: 0.6739\n",
      "Epoch 99/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.1926 - accuracy: 0.5882 - val_loss: 0.9756 - val_accuracy: 0.6839\n",
      "Epoch 100/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.1858 - accuracy: 0.5695 - val_loss: 0.9659 - val_accuracy: 0.6839\n",
      "Epoch 101/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1755 - accuracy: 0.5815 - val_loss: 0.9598 - val_accuracy: 0.6839\n",
      "Epoch 102/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1616 - accuracy: 0.5944 - val_loss: 0.9522 - val_accuracy: 0.6872\n",
      "Epoch 103/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1358 - accuracy: 0.6061 - val_loss: 0.9459 - val_accuracy: 0.6889\n",
      "Epoch 104/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1339 - accuracy: 0.5961 - val_loss: 0.9370 - val_accuracy: 0.6889\n",
      "Epoch 105/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.1138 - accuracy: 0.6144 - val_loss: 0.9279 - val_accuracy: 0.6905\n",
      "Epoch 106/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.1214 - accuracy: 0.5990 - val_loss: 0.9215 - val_accuracy: 0.7005\n",
      "Epoch 107/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0989 - accuracy: 0.6136 - val_loss: 0.9164 - val_accuracy: 0.6988\n",
      "Epoch 108/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.0880 - accuracy: 0.6102 - val_loss: 0.9089 - val_accuracy: 0.7005\n",
      "Epoch 109/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.0814 - accuracy: 0.6248 - val_loss: 0.9018 - val_accuracy: 0.7022\n",
      "Epoch 110/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.0674 - accuracy: 0.6140 - val_loss: 0.8961 - val_accuracy: 0.7072\n",
      "Epoch 111/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.0611 - accuracy: 0.6265 - val_loss: 0.8875 - val_accuracy: 0.7055\n",
      "Epoch 112/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0557 - accuracy: 0.6290 - val_loss: 0.8817 - val_accuracy: 0.7121\n",
      "Epoch 113/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.0535 - accuracy: 0.6377 - val_loss: 0.8758 - val_accuracy: 0.7138\n",
      "Epoch 114/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0431 - accuracy: 0.6360 - val_loss: 0.8711 - val_accuracy: 0.7088\n",
      "Epoch 115/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0136 - accuracy: 0.6394 - val_loss: 0.8643 - val_accuracy: 0.7138\n",
      "Epoch 116/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0191 - accuracy: 0.6364 - val_loss: 0.8581 - val_accuracy: 0.7072\n",
      "Epoch 117/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0183 - accuracy: 0.6414 - val_loss: 0.8517 - val_accuracy: 0.7105\n",
      "Epoch 118/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9951 - accuracy: 0.6489 - val_loss: 0.8463 - val_accuracy: 0.7155\n",
      "Epoch 119/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9829 - accuracy: 0.6635 - val_loss: 0.8403 - val_accuracy: 0.7105\n",
      "Epoch 120/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9799 - accuracy: 0.6572 - val_loss: 0.8346 - val_accuracy: 0.7205\n",
      "Epoch 121/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9828 - accuracy: 0.6572 - val_loss: 0.8294 - val_accuracy: 0.7221\n",
      "Epoch 122/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9427 - accuracy: 0.6718 - val_loss: 0.8242 - val_accuracy: 0.7188\n",
      "Epoch 123/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9578 - accuracy: 0.6693 - val_loss: 0.8187 - val_accuracy: 0.7221\n",
      "Epoch 124/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9335 - accuracy: 0.6735 - val_loss: 0.8133 - val_accuracy: 0.7221\n",
      "Epoch 125/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9420 - accuracy: 0.6626 - val_loss: 0.8078 - val_accuracy: 0.7255\n",
      "Epoch 126/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9266 - accuracy: 0.6789 - val_loss: 0.8027 - val_accuracy: 0.7271\n",
      "Epoch 127/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9180 - accuracy: 0.6801 - val_loss: 0.7980 - val_accuracy: 0.7321\n",
      "Epoch 128/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9036 - accuracy: 0.6905 - val_loss: 0.7924 - val_accuracy: 0.7304\n",
      "Epoch 129/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.9016 - accuracy: 0.6872 - val_loss: 0.7882 - val_accuracy: 0.7304\n",
      "Epoch 130/200\n",
      "2404/2404 [==============================] - 5s 2ms/sample - loss: 0.9132 - accuracy: 0.6785 - val_loss: 0.7831 - val_accuracy: 0.7321\n",
      "Epoch 131/200\n",
      "2404/2404 [==============================] - 6s 2ms/sample - loss: 0.8848 - accuracy: 0.6789 - val_loss: 0.7787 - val_accuracy: 0.7338\n",
      "Epoch 132/200\n",
      "2404/2404 [==============================] - 5s 2ms/sample - loss: 0.8943 - accuracy: 0.6855 - val_loss: 0.7735 - val_accuracy: 0.7404\n",
      "Epoch 133/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8952 - accuracy: 0.6851 - val_loss: 0.7688 - val_accuracy: 0.7404\n",
      "Epoch 134/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.8708 - accuracy: 0.7059 - val_loss: 0.7651 - val_accuracy: 0.7421\n",
      "Epoch 135/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8902 - accuracy: 0.6905 - val_loss: 0.7610 - val_accuracy: 0.7421\n",
      "Epoch 136/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8479 - accuracy: 0.7109 - val_loss: 0.7562 - val_accuracy: 0.7421\n",
      "Epoch 137/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8386 - accuracy: 0.6984 - val_loss: 0.7521 - val_accuracy: 0.7438\n",
      "Epoch 138/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8225 - accuracy: 0.7134 - val_loss: 0.7474 - val_accuracy: 0.7438\n",
      "Epoch 139/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8317 - accuracy: 0.7126 - val_loss: 0.7444 - val_accuracy: 0.7504\n",
      "Epoch 140/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8095 - accuracy: 0.7271 - val_loss: 0.7394 - val_accuracy: 0.7537\n",
      "Epoch 141/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8264 - accuracy: 0.7063 - val_loss: 0.7362 - val_accuracy: 0.7521\n",
      "Epoch 142/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8162 - accuracy: 0.7092 - val_loss: 0.7320 - val_accuracy: 0.7521\n",
      "Epoch 143/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7827 - accuracy: 0.7363 - val_loss: 0.7268 - val_accuracy: 0.7537\n",
      "Epoch 144/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8071 - accuracy: 0.7159 - val_loss: 0.7230 - val_accuracy: 0.7571\n",
      "Epoch 145/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7995 - accuracy: 0.7246 - val_loss: 0.7197 - val_accuracy: 0.7604\n",
      "Epoch 146/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7890 - accuracy: 0.7313 - val_loss: 0.7151 - val_accuracy: 0.7604\n",
      "Epoch 147/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7784 - accuracy: 0.7280 - val_loss: 0.7126 - val_accuracy: 0.7587\n",
      "Epoch 148/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7694 - accuracy: 0.7292 - val_loss: 0.7072 - val_accuracy: 0.7604\n",
      "Epoch 149/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7898 - accuracy: 0.7205 - val_loss: 0.7032 - val_accuracy: 0.7671\n",
      "Epoch 150/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7562 - accuracy: 0.7384 - val_loss: 0.6987 - val_accuracy: 0.7671\n",
      "Epoch 151/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7502 - accuracy: 0.7492 - val_loss: 0.6950 - val_accuracy: 0.7671\n",
      "Epoch 152/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7473 - accuracy: 0.7425 - val_loss: 0.6939 - val_accuracy: 0.7671\n",
      "Epoch 153/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7408 - accuracy: 0.7479 - val_loss: 0.6899 - val_accuracy: 0.7671\n",
      "Epoch 154/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7367 - accuracy: 0.7396 - val_loss: 0.6856 - val_accuracy: 0.7687\n",
      "Epoch 155/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7326 - accuracy: 0.7483 - val_loss: 0.6818 - val_accuracy: 0.7687\n",
      "Epoch 156/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7298 - accuracy: 0.7354 - val_loss: 0.6786 - val_accuracy: 0.7704\n",
      "Epoch 157/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7277 - accuracy: 0.7492 - val_loss: 0.6754 - val_accuracy: 0.7737\n",
      "Epoch 158/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7273 - accuracy: 0.7504 - val_loss: 0.6720 - val_accuracy: 0.7737\n",
      "Epoch 159/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7100 - accuracy: 0.7558 - val_loss: 0.6681 - val_accuracy: 0.7720\n",
      "Epoch 160/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7000 - accuracy: 0.7596 - val_loss: 0.6652 - val_accuracy: 0.7754\n",
      "Epoch 161/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7029 - accuracy: 0.7600 - val_loss: 0.6616 - val_accuracy: 0.7820\n",
      "Epoch 162/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6819 - accuracy: 0.7696 - val_loss: 0.6594 - val_accuracy: 0.7837\n",
      "Epoch 163/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6757 - accuracy: 0.7708 - val_loss: 0.6556 - val_accuracy: 0.7770\n",
      "Epoch 164/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6914 - accuracy: 0.7671 - val_loss: 0.6540 - val_accuracy: 0.7720\n",
      "Epoch 165/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6678 - accuracy: 0.7716 - val_loss: 0.6510 - val_accuracy: 0.7770\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6676 - accuracy: 0.7704 - val_loss: 0.6473 - val_accuracy: 0.7754\n",
      "Epoch 167/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6784 - accuracy: 0.7646 - val_loss: 0.6439 - val_accuracy: 0.7787\n",
      "Epoch 168/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6484 - accuracy: 0.7870 - val_loss: 0.6414 - val_accuracy: 0.7787\n",
      "Epoch 169/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6609 - accuracy: 0.7779 - val_loss: 0.6396 - val_accuracy: 0.7770\n",
      "Epoch 170/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6483 - accuracy: 0.7762 - val_loss: 0.6340 - val_accuracy: 0.7937\n",
      "Epoch 171/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6474 - accuracy: 0.7750 - val_loss: 0.6300 - val_accuracy: 0.7920\n",
      "Epoch 172/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6238 - accuracy: 0.7845 - val_loss: 0.6292 - val_accuracy: 0.7903\n",
      "Epoch 173/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6422 - accuracy: 0.7779 - val_loss: 0.6257 - val_accuracy: 0.7920\n",
      "Epoch 174/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6308 - accuracy: 0.7928 - val_loss: 0.6232 - val_accuracy: 0.7937\n",
      "Epoch 175/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6206 - accuracy: 0.7874 - val_loss: 0.6197 - val_accuracy: 0.7903\n",
      "Epoch 176/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6111 - accuracy: 0.7862 - val_loss: 0.6169 - val_accuracy: 0.7953\n",
      "Epoch 177/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6163 - accuracy: 0.7887 - val_loss: 0.6123 - val_accuracy: 0.7970\n",
      "Epoch 178/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6164 - accuracy: 0.7829 - val_loss: 0.6094 - val_accuracy: 0.7987\n",
      "Epoch 179/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6089 - accuracy: 0.8028 - val_loss: 0.6088 - val_accuracy: 0.7987\n",
      "Epoch 180/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5954 - accuracy: 0.7970 - val_loss: 0.6057 - val_accuracy: 0.7987\n",
      "Epoch 181/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5919 - accuracy: 0.7978 - val_loss: 0.6041 - val_accuracy: 0.7987\n",
      "Epoch 182/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5930 - accuracy: 0.7928 - val_loss: 0.5999 - val_accuracy: 0.8020\n",
      "Epoch 183/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5821 - accuracy: 0.7941 - val_loss: 0.5958 - val_accuracy: 0.8053\n",
      "Epoch 184/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5812 - accuracy: 0.7999 - val_loss: 0.5941 - val_accuracy: 0.8070\n",
      "Epoch 185/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5660 - accuracy: 0.8082 - val_loss: 0.5920 - val_accuracy: 0.8070\n",
      "Epoch 186/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5668 - accuracy: 0.8153 - val_loss: 0.5900 - val_accuracy: 0.8070\n",
      "Epoch 187/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5681 - accuracy: 0.8091 - val_loss: 0.5868 - val_accuracy: 0.8020\n",
      "Epoch 188/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5727 - accuracy: 0.8128 - val_loss: 0.5832 - val_accuracy: 0.8087\n",
      "Epoch 189/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5552 - accuracy: 0.8007 - val_loss: 0.5819 - val_accuracy: 0.8070\n",
      "Epoch 190/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5360 - accuracy: 0.8232 - val_loss: 0.5792 - val_accuracy: 0.8053\n",
      "Epoch 191/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5455 - accuracy: 0.8141 - val_loss: 0.5777 - val_accuracy: 0.8070\n",
      "Epoch 192/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5421 - accuracy: 0.8236 - val_loss: 0.5743 - val_accuracy: 0.8120\n",
      "Epoch 193/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5575 - accuracy: 0.8099 - val_loss: 0.5710 - val_accuracy: 0.8103\n",
      "Epoch 194/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5319 - accuracy: 0.8195 - val_loss: 0.5682 - val_accuracy: 0.8136\n",
      "Epoch 195/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5331 - accuracy: 0.8303 - val_loss: 0.5662 - val_accuracy: 0.8120\n",
      "Epoch 196/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5365 - accuracy: 0.8132 - val_loss: 0.5645 - val_accuracy: 0.8103\n",
      "Epoch 197/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5235 - accuracy: 0.8261 - val_loss: 0.5628 - val_accuracy: 0.8087\n",
      "Epoch 198/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5246 - accuracy: 0.8274 - val_loss: 0.5606 - val_accuracy: 0.8153\n",
      "Epoch 199/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5192 - accuracy: 0.8307 - val_loss: 0.5585 - val_accuracy: 0.8136\n",
      "Epoch 200/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5332 - accuracy: 0.8257 - val_loss: 0.5558 - val_accuracy: 0.8120\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,  batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da2b362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb022d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 89.97504159733776\n",
      "Validation: 81.19800332778702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "yhat = model.predict(X_train)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_train_actual = np.argmax(y_train, axis=1)\n",
    "print('Train:', accuracy_score(y_train_actual, yhat)*100)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_test_actual = np.argmax(y_test, axis=1)\n",
    "print('Validation:', accuracy_score(y_test_actual, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9431b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cfa6b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12.8,4.8))\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "folds = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "y_actual = np.argmax(y, axis=1)\n",
    "for index, (train_indices, val_indices) in enumerate(folds.split(X, y_actual)):\n",
    "    model = get_combined_model()\n",
    "    # TODO: move this to the model def.\n",
    "    model.compile(optimizer=Adam(learning_rate=0.000001, beta_1=0.99, beta_2=0.999),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X[train_indices], y[train_indices],\n",
    "                        validation_data=(X[val_indices], y[val_indices]),\n",
    "                        epochs=175,  batch_size=10, verbose=False)\n",
    "    yhat = model.predict(X[train_indices])\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    y_train_actual = np.argmax(y[train_indices], axis=1)\n",
    "    print(f\"Fold {index}\")\n",
    "    print('Train:', accuracy_score(y_train_actual, yhat)*100)\n",
    "\n",
    "    yhat = model.predict(X[val_indices])\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    y_test_actual = np.argmax(y[val_indices], axis=1)\n",
    "    print('Validation:', accuracy_score(y_test_actual, yhat)*100)\n",
    "    \n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6661c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.90521680312774"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Change this to be saved from above.\n",
    "\n",
    "vals = np.array([77.3635153129161, 74.30093209054593, 79.22769640479362, 76.72872340425532])\n",
    "np.mean(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07f4e4",
   "metadata": {},
   "source": [
    "# Lets play with making a multi modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "625edad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acw_X_0', 'acw_Y_0', 'acw_Z_0', 'acw_X_1', 'acw_Y_1', 'acw_Z_1',\n",
       "       'acw_X_2', 'acw_Y_2', 'acw_Z_2', 'acw_X_3',\n",
       "       ...\n",
       "       'act_X_297', 'act_Y_297', 'act_Z_297', 'act_X_298', 'act_Y_298',\n",
       "       'act_Z_298', 'act_X_299', 'act_Y_299', 'act_Z_299', 'action'],\n",
       "      dtype='object', length=33481)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d9ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23040"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 300 different x,y,z's for each acc\n",
    "\n",
    "#wrist data\n",
    "acw_X_cols_batched = []\n",
    "for j in range(0, samples100):\n",
    "    acw_X_cols_batched += [f\"acw_{val}_{j}\" for val in acw_X_cols]\n",
    "X_acw_batched = df_batched[acw_X_cols_batched].to_numpy()\n",
    "\n",
    "# thigh data\n",
    "act_X_cols_batched = []\n",
    "for j in range(0, samples100):\n",
    "    act_X_cols_batched += [f\"act_{val}_{j}\" for val in acw_X_cols]\n",
    "X_act_batched = df_batched[acw_X_cols_batched].to_numpy()\n",
    "\n",
    "# Depth Camera data\n",
    "dc_X_cols_batched = []\n",
    "for j in range(0, samples15):\n",
    "    dc_X_cols_batched += [f\"dc_{val}_{j}\" for val in dc_X_cols]\n",
    "X_dc_batched = df_batched[dc_X_cols_batched].to_numpy()\n",
    "    \n",
    "# Pressure Mat data\n",
    "pm_X_cols_batched = []\n",
    "for j in range(0, samples15):\n",
    "    pm_X_cols_batched += [f\"pm_{val}_{j}\" for val in pm_X_cols]\n",
    "X_pm_batched = df_batched[pm_X_cols_batched].to_numpy()\n",
    "len(pm_X_cols_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05b7d2",
   "metadata": {},
   "source": [
    "## split for tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cee7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2404, 900)\n",
      "(601, 900)\n",
      "(2404, 900)\n",
      "(601, 900)\n",
      "(2404, 8640)\n",
      "(601, 8640)\n",
      "(2404, 23040)\n",
      "(601, 23040)\n",
      "(2404, 8)\n",
      "(601, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "X_act_batched_train, X_act_batched_test, \\\n",
    "X_acw_batched_train, X_acw_batched_test, \\\n",
    "X_dc_batched_train, X_dc_batched_test, \\\n",
    "X_pm_batched_train, X_pm_batched_test, \\\n",
    "y_train, y_test = \\\n",
    "train_test_split(X_act_batched, X_acw_batched, X_dc_batched, X_pm_batched, y, \n",
    "                 test_size=0.2, shuffle=True)\n",
    "\n",
    "print(X_act_batched_train.shape)\n",
    "print(X_act_batched_test.shape)\n",
    "print(X_acw_batched_train.shape)\n",
    "print(X_acw_batched_test.shape)\n",
    "print(X_dc_batched_train.shape)\n",
    "print(X_dc_batched_test.shape)\n",
    "print(X_pm_batched_train.shape)\n",
    "print(X_pm_batched_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c284b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6, skip=0, step=1):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row *2))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[(i * step) + skip],cmap='bone')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914bf7c",
   "metadata": {},
   "source": [
    "### Reshape the pressure mat back into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2da4c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2404, 45, 32, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 734.4x331.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_pm_batched_train.shape)\n",
    "X_pm_batched_train = X_pm_batched_train.reshape(X_pm_batched_train.shape[0],45,32,16)\n",
    "X_pm_batched_test = X_pm_batched_test.reshape(X_pm_batched_test.shape[0],45,32,16)\n",
    "\n",
    "plot_gallery(X_pm_batched_test[16], [1,2,3],32,16,1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eebdb56",
   "metadata": {},
   "source": [
    "### Reshape the depth camera back into images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "23174a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2404, 45, 32, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 734.4x331.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_pm_batched_train.shape)\n",
    "X_dc_batched_train = X_dc_batched_train.reshape(X_dc_batched_train.shape[0],45,12,16)\n",
    "X_dc_batched_test = X_dc_batched_test.reshape(X_dc_batched_test.shape[0],45,12,16)\n",
    "\n",
    "plot_gallery(X_dc_batched_test[16], [1,2,3],16,12,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b031d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c29b8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "input_thigh = Input(shape=(X_act_batched.shape[1],))\n",
    "input_wrist = Input(shape=(X_acw_batched.shape[1],))\n",
    "input_dc = Input(shape=(X_dc_batched_train.shape[1],\n",
    "                        X_dc_batched_train.shape[2],\n",
    "                        X_dc_batched_train.shape[3],))\n",
    "input_pm = Input(shape=(X_pm_batched_train.shape[1],\n",
    "                        X_pm_batched_train.shape[2],\n",
    "                        X_pm_batched_train.shape[3],))\n",
    "\n",
    "# Build some layers for the thigh\n",
    "thigh = Dense(512, activation=\"sigmoid\")(input_thigh)\n",
    "thigh = Dense(256, activation=\"sigmoid\")(thigh)\n",
    "thigh = Dropout(0.1)(thigh)\n",
    "thigh = Dense(128)(thigh)\n",
    "thigh = Model(inputs=input_thigh, outputs=thigh)\n",
    "\n",
    "# Build some layers for the wrist\n",
    "wrist = Dense(512, activation=\"sigmoid\")(input_wrist)\n",
    "wrist = Dense(256, activation=\"sigmoid\")(wrist)\n",
    "wrist = Dropout(0.1)(wrist)\n",
    "wrist = Dense(128)(wrist)\n",
    "wrist = Model(inputs=input_wrist, outputs=wrist)\n",
    "\n",
    "# Build some layers for the depth camera\n",
    "# but this time we will use conv2D\n",
    "dc_tens = Conv2D(filters=filt_layers[0], \n",
    "                            kernel_size=(3,3), \n",
    "                            padding='same', \n",
    "                            activation='relu',\n",
    "                            data_format=\"channels_first\",\n",
    "                            input_shape=(X_dc_batched_train.shape[1],\n",
    "                                         X_dc_batched_train.shape[2],\n",
    "                                         X_dc_batched_train.shape[3]))(input_dc)\n",
    "dc_tens = Conv2D(filters=filt_layers[1], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(dc_tens)\n",
    "\n",
    "dc_tens = Conv2D(filters=filt_layers[2], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(dc_tens)\n",
    "dc_tens = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")(dc_tens)\n",
    "dc_tens = Dropout(0.4) (dc_tens)\n",
    "dc_tens = Flatten()(dc_tens)\n",
    "dc_tens = Dense(256)(dc_tens)\n",
    "dc_tens = Dropout(0.2) (dc_tens)\n",
    "dc_tens = Model(inputs=input_dc, outputs=dc_tens)\n",
    "\n",
    "\n",
    "# Build some layers for the pressure mat\n",
    "filt_layers = [64, 32, 16]\n",
    "pm_tens = Conv2D(filters=filt_layers[0], \n",
    "                            kernel_size=(3,3), \n",
    "                            padding='same', \n",
    "                            activation='relu',\n",
    "                            data_format=\"channels_first\",\n",
    "                            input_shape=(X_pm_batched_train.shape[1],\n",
    "                                         X_pm_batched_train.shape[2],\n",
    "                                         X_pm_batched_train.shape[3]))(input_pm)\n",
    "pm_tens = Conv2D(filters=filt_layers[1], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(pm_tens)\n",
    "\n",
    "pm_tens = Conv2D(filters=filt_layers[2], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(pm_tens)\n",
    "pm_tens = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")(pm_tens)\n",
    "pm_tens = Dropout(0.4) (pm_tens)\n",
    "pm_tens = Flatten()(pm_tens)\n",
    "pm_tens = Dense(256)(pm_tens)\n",
    "pm_tens = Dropout(0.2) (pm_tens)\n",
    "pm_tens = Model(inputs=input_pm, outputs=pm_tens)\n",
    "\n",
    "\n",
    "combined = concatenate([thigh.output, wrist.output, dc_tens.output, pm_tens.output])\n",
    "\n",
    "# Now lets run some more dense layers\n",
    "last = Dense(128, activation=\"tanh\")(combined)\n",
    "last = Dropout(0.3)(last)\n",
    "last = Dense(64, activation=\"tanh\")(combined)\n",
    "prediction = Dense(units=8, activation='softmax')(last)\n",
    "\n",
    "model = Model(inputs=[thigh.input, wrist.input, dc_tens.input, pm_tens.input], outputs=prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "752fe86d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_93\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_100 (InputLayer)          [(None, 45, 12, 16)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_101 (InputLayer)          [(None, 45, 32, 16)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 12, 16)   25984       input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 64, 32, 16)   25984       input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 12, 16)   18464       conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 16)   18464       conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 12, 16)   4624        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 32, 16)   4624        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_98 (InputLayer)           [(None, 900)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_99 (InputLayer)           [(None, 900)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 16, 6, 8)     0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 8)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 512)          461312      input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 512)          461312      input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 16, 6, 8)     0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 16, 16, 8)    0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 256)          131328      dense_255[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_259 (Dense)               (None, 256)          131328      dense_258[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 768)          0           dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 2048)         0           dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 256)          0           dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 256)          0           dense_259[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_261 (Dense)               (None, 256)          196864      flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_262 (Dense)               (None, 256)          524544      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 128)          32896       dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_260 (Dense)               (None, 128)          32896       dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 256)          0           dense_261[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 256)          0           dense_262[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 768)          0           dense_257[0][0]                  \n",
      "                                                                 dense_260[0][0]                  \n",
      "                                                                 dropout_114[0][0]                \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_264 (Dense)               (None, 64)           49216       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_265 (Dense)               (None, 8)            520         dense_264[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,120,360\n",
      "Trainable params: 2,120,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "03ca648e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601, 45, 32, 16)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pm_batched_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6a2ede5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2404 samples, validate on 601 samples\n",
      "Epoch 1/300\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.5428 - accuracy: 0.1601 - val_loss: 2.2936 - val_accuracy: 0.2097\n",
      "Epoch 2/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 2.2956 - accuracy: 0.2176 - val_loss: 2.0448 - val_accuracy: 0.2879\n",
      "Epoch 3/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 2.1462 - accuracy: 0.2554 - val_loss: 1.8380 - val_accuracy: 0.3161\n",
      "Epoch 4/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 2.0527 - accuracy: 0.2770 - val_loss: 1.7303 - val_accuracy: 0.3478\n",
      "Epoch 5/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 1.9320 - accuracy: 0.3174 - val_loss: 1.6415 - val_accuracy: 0.3943\n",
      "Epoch 6/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 1.8635 - accuracy: 0.3473 - val_loss: 1.5916 - val_accuracy: 0.4160\n",
      "Epoch 7/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 1.8048 - accuracy: 0.3557 - val_loss: 1.5235 - val_accuracy: 0.4526\n",
      "Epoch 8/300\n",
      "2404/2404 [==============================] - 2s 639us/sample - loss: 1.6952 - accuracy: 0.4052 - val_loss: 1.4810 - val_accuracy: 0.4958\n",
      "Epoch 9/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 1.6384 - accuracy: 0.4276 - val_loss: 1.4339 - val_accuracy: 0.4958\n",
      "Epoch 10/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 1.6053 - accuracy: 0.4176 - val_loss: 1.3607 - val_accuracy: 0.5141\n",
      "Epoch 11/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 1.5684 - accuracy: 0.4405 - val_loss: 1.3033 - val_accuracy: 0.5424\n",
      "Epoch 12/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 1.5201 - accuracy: 0.4634 - val_loss: 1.2742 - val_accuracy: 0.5607\n",
      "Epoch 13/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 1.5071 - accuracy: 0.4696 - val_loss: 1.2127 - val_accuracy: 0.5857\n",
      "Epoch 14/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 1.4601 - accuracy: 0.4817 - val_loss: 1.2156 - val_accuracy: 0.5957\n",
      "Epoch 15/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 1.4465 - accuracy: 0.4775 - val_loss: 1.1845 - val_accuracy: 0.5940\n",
      "Epoch 16/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 1.4172 - accuracy: 0.5037 - val_loss: 1.1490 - val_accuracy: 0.6023\n",
      "Epoch 17/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 1.3849 - accuracy: 0.5171 - val_loss: 1.1264 - val_accuracy: 0.6373\n",
      "Epoch 18/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 1.3430 - accuracy: 0.5266 - val_loss: 1.1033 - val_accuracy: 0.6273\n",
      "Epoch 19/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 1.3371 - accuracy: 0.5191 - val_loss: 1.0846 - val_accuracy: 0.6339\n",
      "Epoch 20/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 1.3011 - accuracy: 0.5387 - val_loss: 1.0769 - val_accuracy: 0.6356\n",
      "Epoch 21/300\n",
      "2404/2404 [==============================] - 2s 640us/sample - loss: 1.2597 - accuracy: 0.5453 - val_loss: 1.0405 - val_accuracy: 0.6539\n",
      "Epoch 22/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 1.2789 - accuracy: 0.5412 - val_loss: 1.0587 - val_accuracy: 0.6456\n",
      "Epoch 23/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 1.2728 - accuracy: 0.5433 - val_loss: 1.0370 - val_accuracy: 0.6522\n",
      "Epoch 24/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 1.2436 - accuracy: 0.5566 - val_loss: 1.0421 - val_accuracy: 0.6589\n",
      "Epoch 25/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 1.2323 - accuracy: 0.5670 - val_loss: 1.0409 - val_accuracy: 0.6556\n",
      "Epoch 26/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 1.2055 - accuracy: 0.5857 - val_loss: 1.0229 - val_accuracy: 0.6639\n",
      "Epoch 27/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 1.1980 - accuracy: 0.5807 - val_loss: 1.0079 - val_accuracy: 0.6572\n",
      "Epoch 28/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 1.1955 - accuracy: 0.5878 - val_loss: 1.0045 - val_accuracy: 0.6656\n",
      "Epoch 29/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 1.1582 - accuracy: 0.5957 - val_loss: 0.9656 - val_accuracy: 0.6839\n",
      "Epoch 30/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 1.1458 - accuracy: 0.6002 - val_loss: 0.9411 - val_accuracy: 0.6872\n",
      "Epoch 31/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 1.1401 - accuracy: 0.5919 - val_loss: 0.9448 - val_accuracy: 0.6839\n",
      "Epoch 32/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 1.1097 - accuracy: 0.6011 - val_loss: 0.9394 - val_accuracy: 0.6822\n",
      "Epoch 33/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 1.1267 - accuracy: 0.5973 - val_loss: 0.9023 - val_accuracy: 0.7022\n",
      "Epoch 34/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 1.0851 - accuracy: 0.6019 - val_loss: 0.8966 - val_accuracy: 0.7005\n",
      "Epoch 35/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 1.0603 - accuracy: 0.6206 - val_loss: 0.9003 - val_accuracy: 0.6905\n",
      "Epoch 36/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 1.0567 - accuracy: 0.6302 - val_loss: 0.8882 - val_accuracy: 0.6889\n",
      "Epoch 37/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 1.0516 - accuracy: 0.6290 - val_loss: 0.8662 - val_accuracy: 0.6972\n",
      "Epoch 38/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 1.0568 - accuracy: 0.6169 - val_loss: 0.8462 - val_accuracy: 0.7271\n",
      "Epoch 39/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 1.0195 - accuracy: 0.6460 - val_loss: 0.8195 - val_accuracy: 0.7255\n",
      "Epoch 40/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 1.0099 - accuracy: 0.6581 - val_loss: 0.8169 - val_accuracy: 0.7205\n",
      "Epoch 41/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 1.0007 - accuracy: 0.6439 - val_loss: 0.8162 - val_accuracy: 0.7138\n",
      "Epoch 42/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 1.0165 - accuracy: 0.6468 - val_loss: 0.8115 - val_accuracy: 0.7072\n",
      "Epoch 43/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.9998 - accuracy: 0.6473 - val_loss: 0.8030 - val_accuracy: 0.7155\n",
      "Epoch 44/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.9924 - accuracy: 0.6568 - val_loss: 0.7910 - val_accuracy: 0.7171\n",
      "Epoch 45/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.9748 - accuracy: 0.6681 - val_loss: 0.8064 - val_accuracy: 0.7171\n",
      "Epoch 46/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.9944 - accuracy: 0.6473 - val_loss: 0.8000 - val_accuracy: 0.7005\n",
      "Epoch 47/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.9429 - accuracy: 0.6668 - val_loss: 0.7802 - val_accuracy: 0.7288\n",
      "Epoch 48/300\n",
      "2404/2404 [==============================] - 2s 645us/sample - loss: 0.9322 - accuracy: 0.6826 - val_loss: 0.7603 - val_accuracy: 0.7471\n",
      "Epoch 49/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.9135 - accuracy: 0.6780 - val_loss: 0.7590 - val_accuracy: 0.7238\n",
      "Epoch 50/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.9191 - accuracy: 0.6859 - val_loss: 0.7530 - val_accuracy: 0.7421\n",
      "Epoch 51/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.9215 - accuracy: 0.6801 - val_loss: 0.7514 - val_accuracy: 0.7388\n",
      "Epoch 52/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.9126 - accuracy: 0.6772 - val_loss: 0.7416 - val_accuracy: 0.7288\n",
      "Epoch 53/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.8842 - accuracy: 0.6893 - val_loss: 0.7342 - val_accuracy: 0.7338\n",
      "Epoch 54/300\n",
      "2404/2404 [==============================] - 2s 645us/sample - loss: 0.8775 - accuracy: 0.6893 - val_loss: 0.7335 - val_accuracy: 0.7271\n",
      "Epoch 55/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.8829 - accuracy: 0.6843 - val_loss: 0.7274 - val_accuracy: 0.7371\n",
      "Epoch 56/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.8850 - accuracy: 0.6976 - val_loss: 0.7358 - val_accuracy: 0.7338\n",
      "Epoch 57/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.8744 - accuracy: 0.6930 - val_loss: 0.7471 - val_accuracy: 0.7188\n",
      "Epoch 58/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.8929 - accuracy: 0.6809 - val_loss: 0.7435 - val_accuracy: 0.7304\n",
      "Epoch 59/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.8865 - accuracy: 0.6930 - val_loss: 0.7262 - val_accuracy: 0.7421\n",
      "Epoch 60/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.8454 - accuracy: 0.7042 - val_loss: 0.6987 - val_accuracy: 0.7454\n",
      "Epoch 61/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.8409 - accuracy: 0.7013 - val_loss: 0.6980 - val_accuracy: 0.7571\n",
      "Epoch 62/300\n",
      "2404/2404 [==============================] - 2s 646us/sample - loss: 0.8413 - accuracy: 0.7130 - val_loss: 0.6944 - val_accuracy: 0.7671\n",
      "Epoch 63/300\n",
      "2404/2404 [==============================] - 2s 689us/sample - loss: 0.8361 - accuracy: 0.7034 - val_loss: 0.6744 - val_accuracy: 0.7621\n",
      "Epoch 64/300\n",
      "2404/2404 [==============================] - 2s 686us/sample - loss: 0.8101 - accuracy: 0.7280 - val_loss: 0.6765 - val_accuracy: 0.7637\n",
      "Epoch 65/300\n",
      "2404/2404 [==============================] - 2s 665us/sample - loss: 0.8174 - accuracy: 0.7146 - val_loss: 0.6702 - val_accuracy: 0.7521\n",
      "Epoch 66/300\n",
      "2404/2404 [==============================] - 2s 670us/sample - loss: 0.8015 - accuracy: 0.7230 - val_loss: 0.6663 - val_accuracy: 0.7637\n",
      "Epoch 67/300\n",
      "2404/2404 [==============================] - 2s 700us/sample - loss: 0.8005 - accuracy: 0.7255 - val_loss: 0.6550 - val_accuracy: 0.7654\n",
      "Epoch 68/300\n",
      "2404/2404 [==============================] - 2s 681us/sample - loss: 0.8108 - accuracy: 0.7259 - val_loss: 0.6658 - val_accuracy: 0.7654\n",
      "Epoch 69/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.8006 - accuracy: 0.7217 - val_loss: 0.6780 - val_accuracy: 0.7637\n",
      "Epoch 70/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.7977 - accuracy: 0.7238 - val_loss: 0.6666 - val_accuracy: 0.7604\n",
      "Epoch 71/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.7784 - accuracy: 0.7234 - val_loss: 0.6602 - val_accuracy: 0.7720\n",
      "Epoch 72/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.7913 - accuracy: 0.7267 - val_loss: 0.6586 - val_accuracy: 0.7837\n",
      "Epoch 73/300\n",
      "2404/2404 [==============================] - 1s 624us/sample - loss: 0.7775 - accuracy: 0.7309 - val_loss: 0.6695 - val_accuracy: 0.7787\n",
      "Epoch 74/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.7990 - accuracy: 0.7284 - val_loss: 0.6719 - val_accuracy: 0.7604\n",
      "Epoch 75/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.7559 - accuracy: 0.7442 - val_loss: 0.6717 - val_accuracy: 0.7687\n",
      "Epoch 76/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.7716 - accuracy: 0.7438 - val_loss: 0.6374 - val_accuracy: 0.7820\n",
      "Epoch 77/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.7588 - accuracy: 0.7396 - val_loss: 0.6319 - val_accuracy: 0.7787\n",
      "Epoch 78/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.7384 - accuracy: 0.7354 - val_loss: 0.6379 - val_accuracy: 0.7903\n",
      "Epoch 79/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.7376 - accuracy: 0.7463 - val_loss: 0.6202 - val_accuracy: 0.7903\n",
      "Epoch 80/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.7409 - accuracy: 0.7413 - val_loss: 0.6201 - val_accuracy: 0.7953\n",
      "Epoch 81/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.7277 - accuracy: 0.7500 - val_loss: 0.6149 - val_accuracy: 0.7987\n",
      "Epoch 82/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.7348 - accuracy: 0.7471 - val_loss: 0.6043 - val_accuracy: 0.8003\n",
      "Epoch 83/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.7354 - accuracy: 0.7467 - val_loss: 0.5900 - val_accuracy: 0.8053\n",
      "Epoch 84/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.7108 - accuracy: 0.7579 - val_loss: 0.5914 - val_accuracy: 0.8003\n",
      "Epoch 85/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.7336 - accuracy: 0.7517 - val_loss: 0.5914 - val_accuracy: 0.7920\n",
      "Epoch 86/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.7085 - accuracy: 0.7521 - val_loss: 0.5859 - val_accuracy: 0.8070\n",
      "Epoch 87/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.7182 - accuracy: 0.7608 - val_loss: 0.5747 - val_accuracy: 0.8120\n",
      "Epoch 88/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.7242 - accuracy: 0.7521 - val_loss: 0.5712 - val_accuracy: 0.8053\n",
      "Epoch 89/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.7117 - accuracy: 0.7571 - val_loss: 0.5682 - val_accuracy: 0.8153\n",
      "Epoch 90/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.7029 - accuracy: 0.7616 - val_loss: 0.5744 - val_accuracy: 0.8120\n",
      "Epoch 91/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.6841 - accuracy: 0.7725 - val_loss: 0.5691 - val_accuracy: 0.8153\n",
      "Epoch 92/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.6802 - accuracy: 0.7696 - val_loss: 0.5529 - val_accuracy: 0.8103\n",
      "Epoch 93/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.6924 - accuracy: 0.7696 - val_loss: 0.5579 - val_accuracy: 0.8037\n",
      "Epoch 94/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.6725 - accuracy: 0.7600 - val_loss: 0.5479 - val_accuracy: 0.8136\n",
      "Epoch 95/300\n",
      "2404/2404 [==============================] - 2s 625us/sample - loss: 0.6712 - accuracy: 0.7629 - val_loss: 0.5640 - val_accuracy: 0.7987\n",
      "Epoch 96/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.6508 - accuracy: 0.7808 - val_loss: 0.5552 - val_accuracy: 0.8186\n",
      "Epoch 97/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.6464 - accuracy: 0.7816 - val_loss: 0.5506 - val_accuracy: 0.8120\n",
      "Epoch 98/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.6538 - accuracy: 0.7783 - val_loss: 0.5409 - val_accuracy: 0.8103\n",
      "Epoch 99/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.6555 - accuracy: 0.7741 - val_loss: 0.5465 - val_accuracy: 0.8203\n",
      "Epoch 100/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.6444 - accuracy: 0.7804 - val_loss: 0.5425 - val_accuracy: 0.8103\n",
      "Epoch 101/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.6378 - accuracy: 0.7854 - val_loss: 0.5285 - val_accuracy: 0.8186\n",
      "Epoch 102/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.6344 - accuracy: 0.7858 - val_loss: 0.5254 - val_accuracy: 0.8220\n",
      "Epoch 103/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.6329 - accuracy: 0.7816 - val_loss: 0.5231 - val_accuracy: 0.8103\n",
      "Epoch 104/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.6285 - accuracy: 0.7824 - val_loss: 0.5313 - val_accuracy: 0.8136\n",
      "Epoch 105/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.6228 - accuracy: 0.7837 - val_loss: 0.5144 - val_accuracy: 0.8186\n",
      "Epoch 106/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.6216 - accuracy: 0.7891 - val_loss: 0.5073 - val_accuracy: 0.8203\n",
      "Epoch 107/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.6270 - accuracy: 0.7829 - val_loss: 0.5058 - val_accuracy: 0.8186\n",
      "Epoch 108/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.6232 - accuracy: 0.7858 - val_loss: 0.4939 - val_accuracy: 0.8286\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.6147 - accuracy: 0.7941 - val_loss: 0.4884 - val_accuracy: 0.8253\n",
      "Epoch 110/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.6083 - accuracy: 0.7920 - val_loss: 0.4868 - val_accuracy: 0.8220\n",
      "Epoch 111/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.6187 - accuracy: 0.7824 - val_loss: 0.4980 - val_accuracy: 0.8220\n",
      "Epoch 112/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.6063 - accuracy: 0.7858 - val_loss: 0.4943 - val_accuracy: 0.8270\n",
      "Epoch 113/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.5979 - accuracy: 0.7999 - val_loss: 0.4884 - val_accuracy: 0.8386\n",
      "Epoch 114/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.6008 - accuracy: 0.7983 - val_loss: 0.4931 - val_accuracy: 0.8369\n",
      "Epoch 115/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.5992 - accuracy: 0.7945 - val_loss: 0.4919 - val_accuracy: 0.8369\n",
      "Epoch 116/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.5879 - accuracy: 0.8057 - val_loss: 0.4933 - val_accuracy: 0.8319\n",
      "Epoch 117/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.5880 - accuracy: 0.7966 - val_loss: 0.4859 - val_accuracy: 0.8403\n",
      "Epoch 118/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.5884 - accuracy: 0.8024 - val_loss: 0.4771 - val_accuracy: 0.8369\n",
      "Epoch 119/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.5804 - accuracy: 0.8099 - val_loss: 0.4892 - val_accuracy: 0.8319\n",
      "Epoch 120/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.5582 - accuracy: 0.8157 - val_loss: 0.4753 - val_accuracy: 0.8369\n",
      "Epoch 121/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.5726 - accuracy: 0.8095 - val_loss: 0.4809 - val_accuracy: 0.8419\n",
      "Epoch 122/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.5584 - accuracy: 0.8070 - val_loss: 0.4853 - val_accuracy: 0.8386\n",
      "Epoch 123/300\n",
      "2404/2404 [==============================] - 1s 623us/sample - loss: 0.5641 - accuracy: 0.8099 - val_loss: 0.4794 - val_accuracy: 0.8436\n",
      "Epoch 124/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.5688 - accuracy: 0.7974 - val_loss: 0.4714 - val_accuracy: 0.8486\n",
      "Epoch 125/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.5576 - accuracy: 0.8157 - val_loss: 0.4652 - val_accuracy: 0.8519\n",
      "Epoch 126/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.5546 - accuracy: 0.8111 - val_loss: 0.4625 - val_accuracy: 0.8569\n",
      "Epoch 127/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.5516 - accuracy: 0.8107 - val_loss: 0.4520 - val_accuracy: 0.8386\n",
      "Epoch 128/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.5477 - accuracy: 0.8153 - val_loss: 0.4557 - val_accuracy: 0.8386\n",
      "Epoch 129/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.5609 - accuracy: 0.8087 - val_loss: 0.4558 - val_accuracy: 0.8319\n",
      "Epoch 130/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.5528 - accuracy: 0.8116 - val_loss: 0.4397 - val_accuracy: 0.8436\n",
      "Epoch 131/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.5454 - accuracy: 0.8141 - val_loss: 0.4663 - val_accuracy: 0.8270\n",
      "Epoch 132/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.5463 - accuracy: 0.8141 - val_loss: 0.4501 - val_accuracy: 0.8419\n",
      "Epoch 133/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.5366 - accuracy: 0.8174 - val_loss: 0.4505 - val_accuracy: 0.8386\n",
      "Epoch 134/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.5220 - accuracy: 0.8199 - val_loss: 0.4578 - val_accuracy: 0.8469\n",
      "Epoch 135/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.5434 - accuracy: 0.8228 - val_loss: 0.4519 - val_accuracy: 0.8419\n",
      "Epoch 136/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.5351 - accuracy: 0.8228 - val_loss: 0.4417 - val_accuracy: 0.8403\n",
      "Epoch 137/300\n",
      "2404/2404 [==============================] - 1s 623us/sample - loss: 0.5293 - accuracy: 0.8174 - val_loss: 0.4430 - val_accuracy: 0.8419\n",
      "Epoch 138/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.4996 - accuracy: 0.8332 - val_loss: 0.4349 - val_accuracy: 0.8436\n",
      "Epoch 139/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.5345 - accuracy: 0.8124 - val_loss: 0.4283 - val_accuracy: 0.8519\n",
      "Epoch 140/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.5167 - accuracy: 0.8307 - val_loss: 0.4287 - val_accuracy: 0.8519\n",
      "Epoch 141/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.5180 - accuracy: 0.8278 - val_loss: 0.4143 - val_accuracy: 0.8602\n",
      "Epoch 142/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.5101 - accuracy: 0.8240 - val_loss: 0.4093 - val_accuracy: 0.8586\n",
      "Epoch 143/300\n",
      "2404/2404 [==============================] - 1s 623us/sample - loss: 0.4974 - accuracy: 0.8436 - val_loss: 0.4202 - val_accuracy: 0.8536\n",
      "Epoch 144/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.5014 - accuracy: 0.8270 - val_loss: 0.4185 - val_accuracy: 0.8602\n",
      "Epoch 145/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.4958 - accuracy: 0.8295 - val_loss: 0.4098 - val_accuracy: 0.8686\n",
      "Epoch 146/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.5124 - accuracy: 0.8240 - val_loss: 0.4054 - val_accuracy: 0.8669\n",
      "Epoch 147/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.5009 - accuracy: 0.8282 - val_loss: 0.4106 - val_accuracy: 0.8586\n",
      "Epoch 148/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.4899 - accuracy: 0.8274 - val_loss: 0.4001 - val_accuracy: 0.8686\n",
      "Epoch 149/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.4817 - accuracy: 0.8453 - val_loss: 0.3937 - val_accuracy: 0.8619\n",
      "Epoch 150/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.4919 - accuracy: 0.8303 - val_loss: 0.3925 - val_accuracy: 0.8569\n",
      "Epoch 151/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.4712 - accuracy: 0.8440 - val_loss: 0.3892 - val_accuracy: 0.8619\n",
      "Epoch 152/300\n",
      "2404/2404 [==============================] - 2s 648us/sample - loss: 0.4889 - accuracy: 0.8415 - val_loss: 0.3936 - val_accuracy: 0.8619\n",
      "Epoch 153/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.4806 - accuracy: 0.8378 - val_loss: 0.3951 - val_accuracy: 0.8619\n",
      "Epoch 154/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.4674 - accuracy: 0.8478 - val_loss: 0.3869 - val_accuracy: 0.8702\n",
      "Epoch 155/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.4686 - accuracy: 0.8419 - val_loss: 0.3860 - val_accuracy: 0.8636\n",
      "Epoch 156/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.4623 - accuracy: 0.8478 - val_loss: 0.3750 - val_accuracy: 0.8652\n",
      "Epoch 157/300\n",
      "2404/2404 [==============================] - 2s 625us/sample - loss: 0.4621 - accuracy: 0.8369 - val_loss: 0.3820 - val_accuracy: 0.8636\n",
      "Epoch 158/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.4610 - accuracy: 0.8448 - val_loss: 0.3748 - val_accuracy: 0.8702\n",
      "Epoch 159/300\n",
      "2404/2404 [==============================] - 2s 647us/sample - loss: 0.4519 - accuracy: 0.8423 - val_loss: 0.3780 - val_accuracy: 0.8719\n",
      "Epoch 160/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.4510 - accuracy: 0.8482 - val_loss: 0.3725 - val_accuracy: 0.8785\n",
      "Epoch 161/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.4483 - accuracy: 0.8482 - val_loss: 0.3788 - val_accuracy: 0.8752\n",
      "Epoch 162/300\n",
      "2404/2404 [==============================] - 2s 653us/sample - loss: 0.4441 - accuracy: 0.8515 - val_loss: 0.3712 - val_accuracy: 0.8802\n",
      "Epoch 163/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.4462 - accuracy: 0.8465 - val_loss: 0.3616 - val_accuracy: 0.8852\n",
      "Epoch 164/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.4407 - accuracy: 0.8565 - val_loss: 0.3610 - val_accuracy: 0.8852\n",
      "Epoch 165/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.4362 - accuracy: 0.8544 - val_loss: 0.3546 - val_accuracy: 0.8869\n",
      "Epoch 166/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.4455 - accuracy: 0.8436 - val_loss: 0.3559 - val_accuracy: 0.8885\n",
      "Epoch 167/300\n",
      "2404/2404 [==============================] - 2s 642us/sample - loss: 0.4440 - accuracy: 0.8544 - val_loss: 0.3572 - val_accuracy: 0.8819\n",
      "Epoch 168/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.4314 - accuracy: 0.8606 - val_loss: 0.3531 - val_accuracy: 0.8819\n",
      "Epoch 169/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.4192 - accuracy: 0.8590 - val_loss: 0.3567 - val_accuracy: 0.8835\n",
      "Epoch 170/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.4248 - accuracy: 0.8519 - val_loss: 0.3497 - val_accuracy: 0.8752\n",
      "Epoch 171/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.4174 - accuracy: 0.8569 - val_loss: 0.3443 - val_accuracy: 0.8752\n",
      "Epoch 172/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.4093 - accuracy: 0.8623 - val_loss: 0.3409 - val_accuracy: 0.8802\n",
      "Epoch 173/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.4253 - accuracy: 0.8636 - val_loss: 0.3328 - val_accuracy: 0.8852\n",
      "Epoch 174/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.4192 - accuracy: 0.8631 - val_loss: 0.3381 - val_accuracy: 0.8902\n",
      "Epoch 175/300\n",
      "2404/2404 [==============================] - 2s 686us/sample - loss: 0.4025 - accuracy: 0.8719 - val_loss: 0.3420 - val_accuracy: 0.8852\n",
      "Epoch 176/300\n",
      "2404/2404 [==============================] - 2s 642us/sample - loss: 0.4113 - accuracy: 0.8661 - val_loss: 0.3390 - val_accuracy: 0.8752\n",
      "Epoch 177/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.4007 - accuracy: 0.8669 - val_loss: 0.3287 - val_accuracy: 0.8819\n",
      "Epoch 178/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.4087 - accuracy: 0.8627 - val_loss: 0.3387 - val_accuracy: 0.8835\n",
      "Epoch 179/300\n",
      "2404/2404 [==============================] - 2s 653us/sample - loss: 0.4018 - accuracy: 0.8636 - val_loss: 0.3357 - val_accuracy: 0.8835\n",
      "Epoch 180/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.3918 - accuracy: 0.8665 - val_loss: 0.3330 - val_accuracy: 0.8852\n",
      "Epoch 181/300\n",
      "2404/2404 [==============================] - 2s 640us/sample - loss: 0.3953 - accuracy: 0.8723 - val_loss: 0.3358 - val_accuracy: 0.8852\n",
      "Epoch 182/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.4011 - accuracy: 0.8690 - val_loss: 0.3340 - val_accuracy: 0.8869\n",
      "Epoch 183/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.3941 - accuracy: 0.8631 - val_loss: 0.3269 - val_accuracy: 0.8952\n",
      "Epoch 184/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.3790 - accuracy: 0.8769 - val_loss: 0.3232 - val_accuracy: 0.8952\n",
      "Epoch 185/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.4106 - accuracy: 0.8615 - val_loss: 0.3251 - val_accuracy: 0.8902\n",
      "Epoch 186/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.3775 - accuracy: 0.8773 - val_loss: 0.3084 - val_accuracy: 0.8902\n",
      "Epoch 187/300\n",
      "2404/2404 [==============================] - 2s 639us/sample - loss: 0.3800 - accuracy: 0.8710 - val_loss: 0.3034 - val_accuracy: 0.8935\n",
      "Epoch 188/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.3840 - accuracy: 0.8735 - val_loss: 0.3006 - val_accuracy: 0.8952\n",
      "Epoch 189/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.3794 - accuracy: 0.8719 - val_loss: 0.3024 - val_accuracy: 0.8885\n",
      "Epoch 190/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.3746 - accuracy: 0.8790 - val_loss: 0.3017 - val_accuracy: 0.8952\n",
      "Epoch 191/300\n",
      "2404/2404 [==============================] - 2s 648us/sample - loss: 0.3826 - accuracy: 0.8661 - val_loss: 0.3084 - val_accuracy: 0.8835\n",
      "Epoch 192/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.3746 - accuracy: 0.8744 - val_loss: 0.3071 - val_accuracy: 0.8935\n",
      "Epoch 193/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.3815 - accuracy: 0.8681 - val_loss: 0.3005 - val_accuracy: 0.8952\n",
      "Epoch 194/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.3639 - accuracy: 0.8740 - val_loss: 0.3077 - val_accuracy: 0.8902\n",
      "Epoch 195/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.3650 - accuracy: 0.8769 - val_loss: 0.2967 - val_accuracy: 0.8885\n",
      "Epoch 196/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.3595 - accuracy: 0.8765 - val_loss: 0.2882 - val_accuracy: 0.8852\n",
      "Epoch 197/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.3636 - accuracy: 0.8760 - val_loss: 0.2902 - val_accuracy: 0.8885\n",
      "Epoch 198/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.3507 - accuracy: 0.8898 - val_loss: 0.2980 - val_accuracy: 0.8918\n",
      "Epoch 199/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.3701 - accuracy: 0.8802 - val_loss: 0.2973 - val_accuracy: 0.8902\n",
      "Epoch 200/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.3626 - accuracy: 0.8760 - val_loss: 0.2953 - val_accuracy: 0.8968\n",
      "Epoch 201/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.3528 - accuracy: 0.8810 - val_loss: 0.2970 - val_accuracy: 0.8952\n",
      "Epoch 202/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.3499 - accuracy: 0.8814 - val_loss: 0.3052 - val_accuracy: 0.8918\n",
      "Epoch 203/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.3547 - accuracy: 0.8810 - val_loss: 0.2942 - val_accuracy: 0.8935\n",
      "Epoch 204/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.3478 - accuracy: 0.8864 - val_loss: 0.2879 - val_accuracy: 0.8985\n",
      "Epoch 205/300\n",
      "2404/2404 [==============================] - 2s 648us/sample - loss: 0.3413 - accuracy: 0.8835 - val_loss: 0.2913 - val_accuracy: 0.8935\n",
      "Epoch 206/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.3415 - accuracy: 0.8910 - val_loss: 0.2844 - val_accuracy: 0.9002\n",
      "Epoch 207/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.3338 - accuracy: 0.8852 - val_loss: 0.2788 - val_accuracy: 0.9018\n",
      "Epoch 208/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.3320 - accuracy: 0.8931 - val_loss: 0.2816 - val_accuracy: 0.9035\n",
      "Epoch 209/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.3212 - accuracy: 0.9014 - val_loss: 0.2838 - val_accuracy: 0.9018\n",
      "Epoch 210/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.3546 - accuracy: 0.8831 - val_loss: 0.2807 - val_accuracy: 0.8968\n",
      "Epoch 211/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.3389 - accuracy: 0.8860 - val_loss: 0.2759 - val_accuracy: 0.9002\n",
      "Epoch 212/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.3237 - accuracy: 0.8956 - val_loss: 0.2812 - val_accuracy: 0.8952\n",
      "Epoch 213/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.3278 - accuracy: 0.8906 - val_loss: 0.2852 - val_accuracy: 0.8935\n",
      "Epoch 214/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.3410 - accuracy: 0.8848 - val_loss: 0.2734 - val_accuracy: 0.9052\n",
      "Epoch 215/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.3216 - accuracy: 0.8918 - val_loss: 0.2814 - val_accuracy: 0.9002\n",
      "Epoch 216/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.3196 - accuracy: 0.8902 - val_loss: 0.2782 - val_accuracy: 0.9002\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.3271 - accuracy: 0.8910 - val_loss: 0.2791 - val_accuracy: 0.8918\n",
      "Epoch 218/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.3216 - accuracy: 0.8993 - val_loss: 0.2798 - val_accuracy: 0.8985\n",
      "Epoch 219/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.3130 - accuracy: 0.9006 - val_loss: 0.2794 - val_accuracy: 0.8918\n",
      "Epoch 220/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.3180 - accuracy: 0.8973 - val_loss: 0.2826 - val_accuracy: 0.8935\n",
      "Epoch 221/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.3207 - accuracy: 0.8968 - val_loss: 0.2701 - val_accuracy: 0.9002\n",
      "Epoch 222/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.3053 - accuracy: 0.8943 - val_loss: 0.2770 - val_accuracy: 0.8952\n",
      "Epoch 223/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.3132 - accuracy: 0.8918 - val_loss: 0.2766 - val_accuracy: 0.8935\n",
      "Epoch 224/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.3064 - accuracy: 0.9060 - val_loss: 0.2692 - val_accuracy: 0.9018\n",
      "Epoch 225/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.3198 - accuracy: 0.8977 - val_loss: 0.2653 - val_accuracy: 0.9052\n",
      "Epoch 226/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.3007 - accuracy: 0.9022 - val_loss: 0.2603 - val_accuracy: 0.8935\n",
      "Epoch 227/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.3112 - accuracy: 0.8998 - val_loss: 0.2566 - val_accuracy: 0.8968\n",
      "Epoch 228/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2972 - accuracy: 0.9060 - val_loss: 0.2571 - val_accuracy: 0.8968\n",
      "Epoch 229/300\n",
      "2404/2404 [==============================] - 2s 625us/sample - loss: 0.2963 - accuracy: 0.9056 - val_loss: 0.2651 - val_accuracy: 0.9018\n",
      "Epoch 230/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.2929 - accuracy: 0.9010 - val_loss: 0.2570 - val_accuracy: 0.9035\n",
      "Epoch 231/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.3002 - accuracy: 0.9014 - val_loss: 0.2558 - val_accuracy: 0.9068\n",
      "Epoch 232/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2853 - accuracy: 0.9097 - val_loss: 0.2435 - val_accuracy: 0.9035\n",
      "Epoch 233/300\n",
      "2404/2404 [==============================] - 2s 644us/sample - loss: 0.3050 - accuracy: 0.9002 - val_loss: 0.2529 - val_accuracy: 0.9035\n",
      "Epoch 234/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.2972 - accuracy: 0.9002 - val_loss: 0.2499 - val_accuracy: 0.9018\n",
      "Epoch 235/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.2973 - accuracy: 0.9060 - val_loss: 0.2359 - val_accuracy: 0.9052\n",
      "Epoch 236/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.2722 - accuracy: 0.9147 - val_loss: 0.2339 - val_accuracy: 0.9101\n",
      "Epoch 237/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.2830 - accuracy: 0.9043 - val_loss: 0.2429 - val_accuracy: 0.9101\n",
      "Epoch 238/300\n",
      "2404/2404 [==============================] - 2s 625us/sample - loss: 0.2883 - accuracy: 0.9002 - val_loss: 0.2429 - val_accuracy: 0.9101\n",
      "Epoch 239/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.2804 - accuracy: 0.9068 - val_loss: 0.2436 - val_accuracy: 0.9068\n",
      "Epoch 240/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.2795 - accuracy: 0.9081 - val_loss: 0.2400 - val_accuracy: 0.9151\n",
      "Epoch 241/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.2737 - accuracy: 0.9101 - val_loss: 0.2451 - val_accuracy: 0.9101\n",
      "Epoch 242/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2790 - accuracy: 0.9106 - val_loss: 0.2419 - val_accuracy: 0.9151\n",
      "Epoch 243/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.2750 - accuracy: 0.9097 - val_loss: 0.2368 - val_accuracy: 0.9135\n",
      "Epoch 244/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.2837 - accuracy: 0.9039 - val_loss: 0.2373 - val_accuracy: 0.9135\n",
      "Epoch 245/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.2701 - accuracy: 0.9093 - val_loss: 0.2379 - val_accuracy: 0.9185\n",
      "Epoch 246/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2696 - accuracy: 0.9143 - val_loss: 0.2338 - val_accuracy: 0.9135\n",
      "Epoch 247/300\n",
      "2404/2404 [==============================] - 2s 642us/sample - loss: 0.2825 - accuracy: 0.9106 - val_loss: 0.2459 - val_accuracy: 0.9135\n",
      "Epoch 248/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.2695 - accuracy: 0.9106 - val_loss: 0.2414 - val_accuracy: 0.9151\n",
      "Epoch 249/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.2724 - accuracy: 0.9089 - val_loss: 0.2426 - val_accuracy: 0.9118\n",
      "Epoch 250/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.2571 - accuracy: 0.9114 - val_loss: 0.2447 - val_accuracy: 0.9052\n",
      "Epoch 251/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.2686 - accuracy: 0.9072 - val_loss: 0.2357 - val_accuracy: 0.9135\n",
      "Epoch 252/300\n",
      "2404/2404 [==============================] - 2s 625us/sample - loss: 0.2579 - accuracy: 0.9139 - val_loss: 0.2342 - val_accuracy: 0.9052\n",
      "Epoch 253/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.2482 - accuracy: 0.9205 - val_loss: 0.2344 - val_accuracy: 0.9085\n",
      "Epoch 254/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.2575 - accuracy: 0.9193 - val_loss: 0.2309 - val_accuracy: 0.9101\n",
      "Epoch 255/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2468 - accuracy: 0.9185 - val_loss: 0.2210 - val_accuracy: 0.9168\n",
      "Epoch 256/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.2652 - accuracy: 0.9131 - val_loss: 0.2330 - val_accuracy: 0.9118\n",
      "Epoch 257/300\n",
      "2404/2404 [==============================] - 2s 630us/sample - loss: 0.2492 - accuracy: 0.9201 - val_loss: 0.2273 - val_accuracy: 0.9218\n",
      "Epoch 258/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.2568 - accuracy: 0.9168 - val_loss: 0.2341 - val_accuracy: 0.9118\n",
      "Epoch 259/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2495 - accuracy: 0.9222 - val_loss: 0.2289 - val_accuracy: 0.9135\n",
      "Epoch 260/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.2343 - accuracy: 0.9226 - val_loss: 0.2298 - val_accuracy: 0.9185\n",
      "Epoch 261/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.2343 - accuracy: 0.9239 - val_loss: 0.2228 - val_accuracy: 0.9218\n",
      "Epoch 262/300\n",
      "2404/2404 [==============================] - 2s 629us/sample - loss: 0.2466 - accuracy: 0.9226 - val_loss: 0.2224 - val_accuracy: 0.9218\n",
      "Epoch 263/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.2414 - accuracy: 0.9189 - val_loss: 0.2160 - val_accuracy: 0.9285\n",
      "Epoch 264/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.2405 - accuracy: 0.9172 - val_loss: 0.2228 - val_accuracy: 0.9168\n",
      "Epoch 265/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.2234 - accuracy: 0.9280 - val_loss: 0.2224 - val_accuracy: 0.9135\n",
      "Epoch 266/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.2299 - accuracy: 0.9322 - val_loss: 0.2318 - val_accuracy: 0.9085\n",
      "Epoch 267/300\n",
      "2404/2404 [==============================] - 2s 653us/sample - loss: 0.2322 - accuracy: 0.9214 - val_loss: 0.2210 - val_accuracy: 0.9218\n",
      "Epoch 268/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.2389 - accuracy: 0.9268 - val_loss: 0.2310 - val_accuracy: 0.9118\n",
      "Epoch 269/300\n",
      "2404/2404 [==============================] - 2s 641us/sample - loss: 0.2270 - accuracy: 0.9343 - val_loss: 0.2255 - val_accuracy: 0.9168\n",
      "Epoch 270/300\n",
      "2404/2404 [==============================] - 2s 632us/sample - loss: 0.2222 - accuracy: 0.9343 - val_loss: 0.2287 - val_accuracy: 0.9185\n",
      "Epoch 271/300\n",
      "2404/2404 [==============================] - 2s 628us/sample - loss: 0.2285 - accuracy: 0.9280 - val_loss: 0.2278 - val_accuracy: 0.9268\n",
      "Epoch 272/300\n",
      "2404/2404 [==============================] - 2s 624us/sample - loss: 0.2243 - accuracy: 0.9334 - val_loss: 0.2296 - val_accuracy: 0.9168\n",
      "Epoch 273/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.2315 - accuracy: 0.9309 - val_loss: 0.2270 - val_accuracy: 0.9151\n",
      "Epoch 274/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.2172 - accuracy: 0.9305 - val_loss: 0.2136 - val_accuracy: 0.9135\n",
      "Epoch 275/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.2241 - accuracy: 0.9293 - val_loss: 0.2256 - val_accuracy: 0.9085\n",
      "Epoch 276/300\n",
      "2404/2404 [==============================] - 2s 627us/sample - loss: 0.2272 - accuracy: 0.9243 - val_loss: 0.2140 - val_accuracy: 0.9168\n",
      "Epoch 277/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.2109 - accuracy: 0.9343 - val_loss: 0.2143 - val_accuracy: 0.9085\n",
      "Epoch 278/300\n",
      "2404/2404 [==============================] - 2s 631us/sample - loss: 0.2145 - accuracy: 0.9314 - val_loss: 0.2118 - val_accuracy: 0.9101\n",
      "Epoch 279/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.2250 - accuracy: 0.9251 - val_loss: 0.2148 - val_accuracy: 0.9118\n",
      "Epoch 280/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.2162 - accuracy: 0.9285 - val_loss: 0.2087 - val_accuracy: 0.9151\n",
      "Epoch 281/300\n",
      "2404/2404 [==============================] - 2s 633us/sample - loss: 0.2193 - accuracy: 0.9314 - val_loss: 0.2124 - val_accuracy: 0.9002\n",
      "Epoch 282/300\n",
      "2404/2404 [==============================] - 2s 626us/sample - loss: 0.2141 - accuracy: 0.9326 - val_loss: 0.2057 - val_accuracy: 0.9151\n",
      "Epoch 283/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.2142 - accuracy: 0.9368 - val_loss: 0.2131 - val_accuracy: 0.9135\n",
      "Epoch 284/300\n",
      "2404/2404 [==============================] - 2s 675us/sample - loss: 0.2063 - accuracy: 0.9309 - val_loss: 0.2088 - val_accuracy: 0.9151\n",
      "Epoch 285/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.2062 - accuracy: 0.9368 - val_loss: 0.2075 - val_accuracy: 0.9151\n",
      "Epoch 286/300\n",
      "2404/2404 [==============================] - 2s 665us/sample - loss: 0.2068 - accuracy: 0.9322 - val_loss: 0.2056 - val_accuracy: 0.9251\n",
      "Epoch 287/300\n",
      "2404/2404 [==============================] - 2s 634us/sample - loss: 0.2004 - accuracy: 0.9380 - val_loss: 0.2071 - val_accuracy: 0.9101\n",
      "Epoch 288/300\n",
      "2404/2404 [==============================] - 2s 639us/sample - loss: 0.1996 - accuracy: 0.9364 - val_loss: 0.2017 - val_accuracy: 0.9218\n",
      "Epoch 289/300\n",
      "2404/2404 [==============================] - 2s 655us/sample - loss: 0.2008 - accuracy: 0.9397 - val_loss: 0.1954 - val_accuracy: 0.9201\n",
      "Epoch 290/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.2047 - accuracy: 0.9339 - val_loss: 0.1971 - val_accuracy: 0.9168\n",
      "Epoch 291/300\n",
      "2404/2404 [==============================] - 2s 636us/sample - loss: 0.1997 - accuracy: 0.9384 - val_loss: 0.1958 - val_accuracy: 0.9151\n",
      "Epoch 292/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.2005 - accuracy: 0.9347 - val_loss: 0.1951 - val_accuracy: 0.9135\n",
      "Epoch 293/300\n",
      "2404/2404 [==============================] - 2s 643us/sample - loss: 0.1950 - accuracy: 0.9380 - val_loss: 0.1988 - val_accuracy: 0.9201\n",
      "Epoch 294/300\n",
      "2404/2404 [==============================] - 2s 648us/sample - loss: 0.1941 - accuracy: 0.9426 - val_loss: 0.1997 - val_accuracy: 0.9201\n",
      "Epoch 295/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.1955 - accuracy: 0.9364 - val_loss: 0.1930 - val_accuracy: 0.9185\n",
      "Epoch 296/300\n",
      "2404/2404 [==============================] - 2s 635us/sample - loss: 0.1830 - accuracy: 0.9413 - val_loss: 0.1994 - val_accuracy: 0.9285\n",
      "Epoch 297/300\n",
      "2404/2404 [==============================] - 2s 638us/sample - loss: 0.1872 - accuracy: 0.9438 - val_loss: 0.1993 - val_accuracy: 0.9301\n",
      "Epoch 298/300\n",
      "2404/2404 [==============================] - 2s 637us/sample - loss: 0.1893 - accuracy: 0.9389 - val_loss: 0.2012 - val_accuracy: 0.9218\n",
      "Epoch 299/300\n",
      "2404/2404 [==============================] - 2s 642us/sample - loss: 0.1919 - accuracy: 0.9418 - val_loss: 0.1914 - val_accuracy: 0.9251\n",
      "Epoch 300/300\n",
      "2404/2404 [==============================] - 2s 645us/sample - loss: 0.1848 - accuracy: 0.9430 - val_loss: 0.1934 - val_accuracy: 0.9218\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x=[X_act_batched_train, X_acw_batched_train, X_dc_batched_train, X_pm_batched_train],\n",
    "                    y=y_train, \n",
    "                    validation_data=(\n",
    "                        [X_act_batched_test,\n",
    "                         X_acw_batched_test,X_dc_batched_test, X_pm_batched_test], y_test),\n",
    "                    epochs=300,  batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "43e8c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 92.17970049916805\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x345.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = model.predict([X_act_batched_test, X_acw_batched_test, X_dc_batched_test, X_pm_batched_test])\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_test_actual = np.argmax(y_test, axis=1)\n",
    "print('Validation:', accuracy_score(y_test_actual, yhat)*100)\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv2022] *",
   "language": "python",
   "name": "conda-env-mlenv2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
