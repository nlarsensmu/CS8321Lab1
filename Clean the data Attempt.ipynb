{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945615d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c74c07",
   "metadata": {},
   "source": [
    "# Read in the data to on dictionary of each Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211b6bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On act\n",
      "On acw\n",
      "On dc\n",
      "On pm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, '1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "# Test out the read in helper function\n",
    "def get_subject_action(sensor, full_path):\n",
    "    index = full_path.find(sensor)\n",
    "    index += len(sensor)\n",
    "    subject = int(full_path[index+1:index+3])\n",
    "    action = int(full_path[index+4:index+6])\n",
    "    if action == 4:\n",
    "        if full_path.find(f\"{sensor}_1\") > 0:\n",
    "            action = '4-1'\n",
    "        else:\n",
    "            action = '4-2'\n",
    "        \n",
    "    return (subject, str(action))\n",
    "\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                #print(full_path, get_subject_action(sensor, full_path))\n",
    "                \n",
    "test_str = '.\\\\data\\\\act\\\\01\\\\01_act_1.csv'\n",
    "get_subject_action('act', test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5528178f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98232e201d64c728206a7acd93c0524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data:   0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_data = {\n",
    "    'act': None,\n",
    "    'acw': None,\n",
    "    'dc': None,\n",
    "    'pm': None,\n",
    "}\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'act': ['times', 'X', 'Y', 'Z'],\n",
    "    'acw': ['times', 'X', 'Y', 'Z'],\n",
    "    'dc': ['times'],\n",
    "    'pm': ['times']\n",
    "}\n",
    "for i in range(1,513):\n",
    "    headers['pm'].append(f\"sensor_{i}\")\n",
    "for i in range(1,193):\n",
    "    headers['dc'].append(f\"sensor_{i}\")\n",
    "\n",
    "actions = ['1', '2', '3', '4-1', '4-2', '5', '6', '7']\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "#sensor_list = ['acw']\n",
    "\n",
    "# there are 956 files in our dataset\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(desc=\"load data\", total=956)\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        #print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                df_tmp = pd.read_csv(full_path, names=headers[sensor])\n",
    "                i+=1\n",
    "                pbar.update(1)\n",
    "                subject, action = get_subject_action(sensor, full_path)\n",
    "                # add one to make it match the given format\n",
    "                df_tmp['subject'] = subject\n",
    "                df_tmp['action'] = action\n",
    "                if total_data[sensor] is None:\n",
    "                    total_data[sensor] = df_tmp\n",
    "                else:\n",
    "                    total_data[sensor] = pd.concat([total_data[sensor], df_tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36329390",
   "metadata": {},
   "source": [
    "## Show what is in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ccb4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1400856 entries, 0 to 6418\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1400856 non-null  object \n",
      " 1   X        1400856 non-null  float64\n",
      " 2   Y        1400856 non-null  float64\n",
      " 3   Z        1400856 non-null  float64\n",
      " 4   subject  1400856 non-null  int64  \n",
      " 5   action   1400856 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 74.8+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "acw\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1313695 entries, 0 to 6013\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1313695 non-null  object \n",
      " 1   X        1313695 non-null  float64\n",
      " 2   Y        1313695 non-null  float64\n",
      " 3   Z        1313695 non-null  float64\n",
      " 4   subject  1313695 non-null  int64  \n",
      " 5   action   1313695 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 70.2+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "dc\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140694 entries, 0 to 624\n",
      "Columns: 195 entries, times to action\n",
      "dtypes: float64(192), int64(1), object(2)\n",
      "memory usage: 210.4+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "pm\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 202682 entries, 0 to 927\n",
      "Columns: 515 entries, times to action\n",
      "dtypes: float64(512), int64(1), object(2)\n",
      "memory usage: 797.9+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in total_data.keys():\n",
    "    if total_data[key] is not None:\n",
    "        print(key)\n",
    "        print(total_data[key]['action'].unique())\n",
    "        print(total_data[key]['subject'].unique())\n",
    "        for header in headers[key]:\n",
    "            if(total_data[key][header].isnull().values.any()):\n",
    "                print(f\"{header} has Null data\")\n",
    "        print(total_data[key].info())\n",
    "        print('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "012efc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>2018-11-08 11:35:56.373000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>2018-11-08 11:35:56.383000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>2018-11-08 11:35:56.394000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>2018-11-08 11:35:56.404000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>2018-11-08 11:35:56.414000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           times         X         Y        Z  subject action\n",
       "0     2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1     2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2     2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3     2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4     2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1\n",
       "...                          ...       ...       ...      ...      ...    ...\n",
       "6269  2018-11-08 11:35:56.373000  0.093750 -0.265625  0.87500        1      1\n",
       "6270  2018-11-08 11:35:56.383000  0.093750 -0.281250  0.87500        1      1\n",
       "6271  2018-11-08 11:35:56.394000  0.093750 -0.265625  0.87500        1      1\n",
       "6272  2018-11-08 11:35:56.404000  0.093750 -0.265625  0.87500        1      1\n",
       "6273  2018-11-08 11:35:56.414000  0.093750 -0.265625  0.87500        1      1\n",
       "\n",
       "[6274 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acw = total_data['acw']\n",
    "subject = 1\n",
    "action = '1'\n",
    "df_acw[(df_acw.subject == subject) & (df_acw.action == action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "675590d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_505</th>\n",
       "      <th>sensor_506</th>\n",
       "      <th>sensor_507</th>\n",
       "      <th>sensor_508</th>\n",
       "      <th>sensor_509</th>\n",
       "      <th>sensor_510</th>\n",
       "      <th>sensor_511</th>\n",
       "      <th>sensor_512</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.468000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.535000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.602000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.669000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.737000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0  2018-11-08 11:34:51.468000      20.0       3.0       2.0       0.0   \n",
       "1  2018-11-08 11:34:51.535000      20.0       3.0       2.0       0.0   \n",
       "2  2018-11-08 11:34:51.602000      20.0       3.0       2.0       0.0   \n",
       "3  2018-11-08 11:34:51.669000      20.0       3.0       2.0       0.0   \n",
       "4  2018-11-08 11:34:51.737000      20.0       3.0       2.0       0.0   \n",
       "\n",
       "   sensor_5  sensor_6  sensor_7  sensor_8  sensor_9  ...  sensor_505  \\\n",
       "0       0.0       0.0      72.0    1493.0    1949.0  ...        68.0   \n",
       "1       0.0       0.0      72.0    1493.0    1949.0  ...        58.0   \n",
       "2       0.0       0.0      72.0    1493.0    1949.0  ...        64.0   \n",
       "3       0.0       0.0      72.0    1493.0    1949.0  ...        66.0   \n",
       "4       0.0       0.0      72.0    1493.0    1949.0  ...        64.0   \n",
       "\n",
       "   sensor_506  sensor_507  sensor_508  sensor_509  sensor_510  sensor_511  \\\n",
       "0        77.0        55.0       193.0       387.0       331.0       125.0   \n",
       "1        78.0        53.0       192.0       388.0       330.0       123.0   \n",
       "2        78.0        53.0       195.0       390.0       330.0       119.0   \n",
       "3        79.0        55.0       196.0       391.0       324.0       106.0   \n",
       "4        79.0        55.0       194.0       391.0       321.0       114.0   \n",
       "\n",
       "   sensor_512  subject  action  \n",
       "0         6.0        1       1  \n",
       "1         6.0        1       1  \n",
       "2         7.0        1       1  \n",
       "3         5.0        1       1  \n",
       "4         6.0        1       1  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data['pm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d5407a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  4],\n",
       "       [ 4,  5,  6,  4,  5,  6,  7,  5,  6,  7,  8,  9],\n",
       "       [ 7,  8,  9,  8,  9, 10, 11, 10, 11, 12, 13, 14],\n",
       "       [10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19],\n",
       "       [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
       "       [16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show reshape is doing what we think\n",
    "x = np.array([[1,2,3],\n",
    "          [4,5,6],\n",
    "          [7,8,9],\n",
    "          [10,11,12],\n",
    "          [13,14,15],\n",
    "          [16,17,18]])\n",
    "y = np.array(range(0,24))\n",
    "y = np.reshape(y, (6,4))\n",
    "\n",
    "z = np.array(range(0,30))\n",
    "z = np.reshape(z, (6, 5))\n",
    "\n",
    "\n",
    "np.hstack((x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc5cba4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7ac1f252154ec8bdc96c73bb4c4b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch data:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acw_X_0</th>\n",
       "      <th>acw_Y_0</th>\n",
       "      <th>acw_Z_0</th>\n",
       "      <th>acw_X_1</th>\n",
       "      <th>acw_Y_1</th>\n",
       "      <th>acw_Z_1</th>\n",
       "      <th>acw_X_2</th>\n",
       "      <th>acw_Y_2</th>\n",
       "      <th>acw_Z_2</th>\n",
       "      <th>acw_X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>act_X_297</th>\n",
       "      <th>act_Y_297</th>\n",
       "      <th>act_Z_297</th>\n",
       "      <th>act_X_298</th>\n",
       "      <th>act_Y_298</th>\n",
       "      <th>act_Z_298</th>\n",
       "      <th>act_X_299</th>\n",
       "      <th>act_Y_299</th>\n",
       "      <th>act_Z_299</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640625</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>-0.656250</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.671875</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.796875</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acw_X_0   acw_Y_0   acw_Z_0   acw_X_1   acw_Y_1   acw_Z_1   acw_X_2  \\\n",
       "0  0.125000 -0.046875  0.906250  0.109375 -0.062500  0.906250  0.109375   \n",
       "1  0.156250 -0.062500  0.906250  0.156250 -0.062500  0.890625  0.156250   \n",
       "2  0.218750 -0.078125  0.890625  0.218750 -0.078125  0.875000  0.234375   \n",
       "3  0.281250 -0.093750  0.859375  0.281250 -0.093750  0.875000  0.281250   \n",
       "4  0.359375 -0.062500  0.843750  0.359375 -0.062500  0.843750  0.359375   \n",
       "\n",
       "    acw_Y_2   acw_Z_2   acw_X_3  ...  act_X_297  act_Y_297  act_Z_297  \\\n",
       "0 -0.062500  0.906250  0.125000  ...  -0.640625  -0.562500   0.437500   \n",
       "1 -0.062500  0.890625  0.156250  ...  -0.625000  -0.796875   0.171875   \n",
       "2 -0.078125  0.890625  0.234375  ...  -0.593750  -0.750000   0.281250   \n",
       "3 -0.093750  0.859375  0.281250  ...  -0.593750  -0.734375   0.296875   \n",
       "4 -0.078125  0.843750  0.359375  ...  -0.593750  -0.734375   0.312500   \n",
       "\n",
       "   act_X_298  act_Y_298  act_Z_298  act_X_299  act_Y_299  act_Z_299  action  \n",
       "0  -0.656250  -0.562500   0.468750  -0.671875  -0.578125   0.468750       1  \n",
       "1  -0.625000  -0.781250   0.171875  -0.625000  -0.781250   0.171875       1  \n",
       "2  -0.609375  -0.750000   0.296875  -0.609375  -0.750000   0.296875       1  \n",
       "3  -0.593750  -0.734375   0.296875  -0.593750  -0.734375   0.296875       1  \n",
       "4  -0.578125  -0.734375   0.312500  -0.593750  -0.734375   0.296875       1  \n",
       "\n",
       "[5 rows x 33481 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# take the total dfs and make batches for each action each subject completed\n",
    "# samples100 is how many samples should be in the 100HZ (the two accleromter data)\n",
    "# samples15 is how many samples from the images should be take\n",
    "subjects = range(1,31)\n",
    "dc_X_cols = [f\"sensor_{i}\" for i in range(1,193)]\n",
    "pm_X_cols = [f\"sensor_{i}\" for i in range(1,513)]\n",
    "acw_X_cols = [\"X\", \"Y\", \"Z\"]\n",
    "\n",
    "def batch_data(total_dfs, seconds=5):\n",
    "    samples100 = 100*seconds\n",
    "    samples15 = 15*seconds\n",
    "    df_acw = total_dfs['acw']\n",
    "    df_act = total_dfs['act']\n",
    "    df_dc = total_dfs['dc']\n",
    "    df_pm = total_dfs['pm']\n",
    "    \n",
    "    all_cols = []\n",
    "    for i in range(0, samples100):\n",
    "        all_cols += [f\"acw_{val}_{i}\" for val in acw_X_cols]\n",
    "    for i in range(0, samples15):\n",
    "        all_cols += [f\"dc_{val}_{i}\" for val in dc_X_cols]\n",
    "    for i in range(0, samples15):\n",
    "        all_cols += [f\"pm_{val}_{i}\" for val in pm_X_cols]\n",
    "    for i in range(0, samples100):\n",
    "        all_cols += [f\"act_{val}_{i}\" for val in acw_X_cols]\n",
    "    \n",
    "    \n",
    "    df_all = pd.DataFrame(columns=all_cols+['action'])\n",
    "    \n",
    "    actions = df_acw['action'].unique()\n",
    "    pbar = tqdm(desc=\"batch data\", total=len(subjects)*len(actions))\n",
    "    for subject in subjects:\n",
    "        actions = df_acw['action'].unique()\n",
    "        for action in actions:\n",
    "            X_acw = df_acw[(df_acw.subject == subject) & (df_acw.action == action)][acw_X_cols].to_numpy()\n",
    "            X_acw = X_acw[range(0, (X_acw.shape[0]//samples100)*samples100)] # cut off records that don't fit in the window\n",
    "            X_acw = np.reshape(X_acw, (X_acw.shape[0]//samples100, samples100*len(acw_X_cols)))\n",
    "            \n",
    "            X_dc = df_dc[(df_dc.subject == subject) & (df_dc.action == action)][dc_X_cols].to_numpy()\n",
    "            X_dc = X_dc[range(0, (X_dc.shape[0]//samples15)*samples15)]\n",
    "            X_dc = np.reshape(X_dc, (X_dc.shape[0]//samples15, samples15*len(dc_X_cols)))\n",
    "            \n",
    "            X_pm = df_pm[(df_pm.subject == subject) & (df_pm.action == action)][pm_X_cols].to_numpy()\n",
    "            X_pm = X_pm[range(0, (X_pm.shape[0]//samples15)*samples15)]\n",
    "            X_pm = np.reshape(X_pm, (X_pm.shape[0]//samples15, samples15*len(pm_X_cols)))\n",
    "            \n",
    "            X_act = df_act[(df_act.subject == subject) & (df_act.action == action)][acw_X_cols].to_numpy()\n",
    "            X_act = X_act[range(0, (X_act.shape[0]//samples100)*samples100)]\n",
    "            X_act = np.reshape(X_act, (X_act.shape[0]//samples100, samples100*len(acw_X_cols)))\n",
    "            \n",
    "            # trim to the smallest one of these 4\n",
    "            num_records = min(X_acw.shape[0], X_act.shape[0], X_pm.shape[0], X_dc.shape[0])\n",
    "            X_acw = X_acw[range(0,num_records)]\n",
    "            X_dc = X_dc[range(0,num_records)]\n",
    "            X_pm = X_pm[range(0,num_records)]\n",
    "            X_act = X_act[range(0,num_records)]\n",
    "            \n",
    "            X_total = np.hstack((X_acw, X_dc, X_pm, X_act))\n",
    "            \n",
    "            df_tmp = pd.DataFrame(X_total, columns=all_cols)\n",
    "            df_tmp['action'] = action\n",
    "            df_all = pd.concat([df_all, df_tmp])\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "    return df_all\n",
    "\n",
    "df_batched = batch_data(total_data, seconds=3)\n",
    "df_batched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16d5b7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acw_X_0</th>\n",
       "      <th>acw_Y_0</th>\n",
       "      <th>acw_Z_0</th>\n",
       "      <th>acw_X_1</th>\n",
       "      <th>acw_Y_1</th>\n",
       "      <th>acw_Z_1</th>\n",
       "      <th>acw_X_2</th>\n",
       "      <th>acw_Y_2</th>\n",
       "      <th>acw_Z_2</th>\n",
       "      <th>acw_X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>act_Z_296</th>\n",
       "      <th>act_X_297</th>\n",
       "      <th>act_Y_297</th>\n",
       "      <th>act_Z_297</th>\n",
       "      <th>act_X_298</th>\n",
       "      <th>act_Y_298</th>\n",
       "      <th>act_Z_298</th>\n",
       "      <th>act_X_299</th>\n",
       "      <th>act_Y_299</th>\n",
       "      <th>act_Z_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>...</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>...</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>...</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-1</th>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>...</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>...</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>...</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acw_X_0  acw_Y_0  acw_Z_0  acw_X_1  acw_Y_1  acw_Z_1  acw_X_2  \\\n",
       "action                                                                  \n",
       "1           419      419      419      419      419      419      419   \n",
       "2           447      447      447      447      447      447      447   \n",
       "3           449      449      449      449      449      449      449   \n",
       "4-1         226      226      226      226      226      226      226   \n",
       "4-2         198      198      198      198      198      198      198   \n",
       "5           427      427      427      427      427      427      427   \n",
       "6           398      398      398      398      398      398      398   \n",
       "7           441      441      441      441      441      441      441   \n",
       "\n",
       "        acw_Y_2  acw_Z_2  acw_X_3  ...  act_Z_296  act_X_297  act_Y_297  \\\n",
       "action                             ...                                    \n",
       "1           419      419      419  ...        419        419        419   \n",
       "2           447      447      447  ...        447        447        447   \n",
       "3           449      449      449  ...        449        449        449   \n",
       "4-1         226      226      226  ...        226        226        226   \n",
       "4-2         198      198      198  ...        198        198        198   \n",
       "5           427      427      427  ...        427        427        427   \n",
       "6           398      398      398  ...        398        398        398   \n",
       "7           441      441      441  ...        441        441        441   \n",
       "\n",
       "        act_Z_297  act_X_298  act_Y_298  act_Z_298  act_X_299  act_Y_299  \\\n",
       "action                                                                     \n",
       "1             419        419        419        419        419        419   \n",
       "2             447        447        447        447        447        447   \n",
       "3             449        449        449        449        449        449   \n",
       "4-1           226        226        226        226        226        226   \n",
       "4-2           198        198        198        198        198        198   \n",
       "5             427        427        427        427        427        427   \n",
       "6             398        398        398        398        398        398   \n",
       "7             441        441        441        441        441        441   \n",
       "\n",
       "        act_Z_299  \n",
       "action             \n",
       "1             419  \n",
       "2             447  \n",
       "3             449  \n",
       "4-1           226  \n",
       "4-2           198  \n",
       "5             427  \n",
       "6             398  \n",
       "7             441  \n",
       "\n",
       "[8 rows x 33480 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batched.groupby('action').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5af438a",
   "metadata": {},
   "source": [
    "# Stick the data into a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "173075f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = 3\n",
    "samples100 = 100*seconds\n",
    "samples15 = 15*seconds\n",
    "\n",
    "all_cols = []\n",
    "for i in range(0, samples100):\n",
    "    all_cols += [f\"acw_{val}_{i}\" for val in acw_X_cols]\n",
    "for i in range(0, samples15):\n",
    "    all_cols += [f\"dc_{val}_{i}\" for val in dc_X_cols]\n",
    "for i in range(0, samples15):\n",
    "    all_cols += [f\"pm_{val}_{i}\" for val in pm_X_cols]\n",
    "for i in range(0, samples100):\n",
    "    all_cols += [f\"act_{val}_{i}\" for val in acw_X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269cafe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3005, 33480)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_batched[all_cols].to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de038f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.get_dummies(df_batched.action, prefix='action_ohe')\n",
    "y = df_y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786e852",
   "metadata": {},
   "source": [
    "### Train test split real quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d12ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a3c5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Input, GRU, SimpleRNN, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "input_all = Input(shape=(X.shape[1],))\n",
    "x = Dense(units=2048, activation='sigmoid',kernel_initializer='random_normal')(input_all)\n",
    "x = Dense(units=1024, activation='sigmoid',kernel_initializer='random_normal')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(units=512, activation='sigmoid',kernel_initializer='random_normal')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "prediction = Dense(units=8, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_all, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "460197b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 33480)]           0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2048)              68569088  \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 71,984,136\n",
      "Trainable params: 71,984,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.000001, beta_1=0.99, beta_2=0.999),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11cc859c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2404 samples, validate on 601 samples\n",
      "Epoch 1/100\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 2.2215 - accuracy: 0.1423 - val_loss: 2.0410 - val_accuracy: 0.1531\n",
      "Epoch 2/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2405 - accuracy: 0.1381 - val_loss: 2.0308 - val_accuracy: 0.1880\n",
      "Epoch 3/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2371 - accuracy: 0.1285 - val_loss: 2.0271 - val_accuracy: 0.1614\n",
      "Epoch 4/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1941 - accuracy: 0.1589 - val_loss: 2.0194 - val_accuracy: 0.1597\n",
      "Epoch 5/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2071 - accuracy: 0.1510 - val_loss: 2.0127 - val_accuracy: 0.1631\n",
      "Epoch 6/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1930 - accuracy: 0.1485 - val_loss: 2.0038 - val_accuracy: 0.1631\n",
      "Epoch 7/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1976 - accuracy: 0.1581 - val_loss: 1.9962 - val_accuracy: 0.1697\n",
      "Epoch 8/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1823 - accuracy: 0.1539 - val_loss: 1.9872 - val_accuracy: 0.1697\n",
      "Epoch 9/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1773 - accuracy: 0.1664 - val_loss: 1.9787 - val_accuracy: 0.1880\n",
      "Epoch 10/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1661 - accuracy: 0.1560 - val_loss: 1.9732 - val_accuracy: 0.1814\n",
      "Epoch 11/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1669 - accuracy: 0.1672 - val_loss: 1.9637 - val_accuracy: 0.1847\n",
      "Epoch 12/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1738 - accuracy: 0.1606 - val_loss: 1.9550 - val_accuracy: 0.2013\n",
      "Epoch 13/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1507 - accuracy: 0.1776 - val_loss: 1.9485 - val_accuracy: 0.2097\n",
      "Epoch 14/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1747 - accuracy: 0.1635 - val_loss: 1.9407 - val_accuracy: 0.2296\n",
      "Epoch 15/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1560 - accuracy: 0.1710 - val_loss: 1.9302 - val_accuracy: 0.2829\n",
      "Epoch 16/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1479 - accuracy: 0.1626 - val_loss: 1.9216 - val_accuracy: 0.2879\n",
      "Epoch 17/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1103 - accuracy: 0.1880 - val_loss: 1.9145 - val_accuracy: 0.3028\n",
      "Epoch 18/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1138 - accuracy: 0.2076 - val_loss: 1.9092 - val_accuracy: 0.2612\n",
      "Epoch 19/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1285 - accuracy: 0.1843 - val_loss: 1.8990 - val_accuracy: 0.3195\n",
      "Epoch 20/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0980 - accuracy: 0.1976 - val_loss: 1.8947 - val_accuracy: 0.2945\n",
      "Epoch 21/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1064 - accuracy: 0.1830 - val_loss: 1.8862 - val_accuracy: 0.2845\n",
      "Epoch 22/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0833 - accuracy: 0.2038 - val_loss: 1.8775 - val_accuracy: 0.2912\n",
      "Epoch 23/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0934 - accuracy: 0.1922 - val_loss: 1.8676 - val_accuracy: 0.3611\n",
      "Epoch 24/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0824 - accuracy: 0.2013 - val_loss: 1.8599 - val_accuracy: 0.3760\n",
      "Epoch 25/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0712 - accuracy: 0.2067 - val_loss: 1.8508 - val_accuracy: 0.3860\n",
      "Epoch 26/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0825 - accuracy: 0.1930 - val_loss: 1.8409 - val_accuracy: 0.4226\n",
      "Epoch 27/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0707 - accuracy: 0.2084 - val_loss: 1.8308 - val_accuracy: 0.4260\n",
      "Epoch 28/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0879 - accuracy: 0.1951 - val_loss: 1.8222 - val_accuracy: 0.4559\n",
      "Epoch 29/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0686 - accuracy: 0.1997 - val_loss: 1.8123 - val_accuracy: 0.4626\n",
      "Epoch 30/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0377 - accuracy: 0.2080 - val_loss: 1.8034 - val_accuracy: 0.4659\n",
      "Epoch 31/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0632 - accuracy: 0.2047 - val_loss: 1.7928 - val_accuracy: 0.4809\n",
      "Epoch 32/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0185 - accuracy: 0.2163 - val_loss: 1.7843 - val_accuracy: 0.4775\n",
      "Epoch 33/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0303 - accuracy: 0.2163 - val_loss: 1.7721 - val_accuracy: 0.5191\n",
      "Epoch 34/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0197 - accuracy: 0.2292 - val_loss: 1.7612 - val_accuracy: 0.5191\n",
      "Epoch 35/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9975 - accuracy: 0.2267 - val_loss: 1.7498 - val_accuracy: 0.5441\n",
      "Epoch 36/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9892 - accuracy: 0.2400 - val_loss: 1.7394 - val_accuracy: 0.5208\n",
      "Epoch 37/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9867 - accuracy: 0.2342 - val_loss: 1.7276 - val_accuracy: 0.5507\n",
      "Epoch 38/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9879 - accuracy: 0.2442 - val_loss: 1.7144 - val_accuracy: 0.5807\n",
      "Epoch 39/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9518 - accuracy: 0.2554 - val_loss: 1.7045 - val_accuracy: 0.5607\n",
      "Epoch 40/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9625 - accuracy: 0.2550 - val_loss: 1.6935 - val_accuracy: 0.5641\n",
      "Epoch 41/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9633 - accuracy: 0.2475 - val_loss: 1.6815 - val_accuracy: 0.5424\n",
      "Epoch 42/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9379 - accuracy: 0.2621 - val_loss: 1.6680 - val_accuracy: 0.5607\n",
      "Epoch 43/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9356 - accuracy: 0.2496 - val_loss: 1.6558 - val_accuracy: 0.5591\n",
      "Epoch 44/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9275 - accuracy: 0.2621 - val_loss: 1.6450 - val_accuracy: 0.5724\n",
      "Epoch 45/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8956 - accuracy: 0.2908 - val_loss: 1.6312 - val_accuracy: 0.5790\n",
      "Epoch 46/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8906 - accuracy: 0.2887 - val_loss: 1.6169 - val_accuracy: 0.5957\n",
      "Epoch 47/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8740 - accuracy: 0.2854 - val_loss: 1.6016 - val_accuracy: 0.6023\n",
      "Epoch 48/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8803 - accuracy: 0.2779 - val_loss: 1.5871 - val_accuracy: 0.6023\n",
      "Epoch 49/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8741 - accuracy: 0.3045 - val_loss: 1.5756 - val_accuracy: 0.5940\n",
      "Epoch 50/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8459 - accuracy: 0.2945 - val_loss: 1.5601 - val_accuracy: 0.6057\n",
      "Epoch 51/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8377 - accuracy: 0.3066 - val_loss: 1.5434 - val_accuracy: 0.6073\n",
      "Epoch 52/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8096 - accuracy: 0.3332 - val_loss: 1.5311 - val_accuracy: 0.6073\n",
      "Epoch 53/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8159 - accuracy: 0.3128 - val_loss: 1.5131 - val_accuracy: 0.6273\n",
      "Epoch 54/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8139 - accuracy: 0.3315 - val_loss: 1.5006 - val_accuracy: 0.6140\n",
      "Epoch 55/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8138 - accuracy: 0.3178 - val_loss: 1.4843 - val_accuracy: 0.6323\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7624 - accuracy: 0.3498 - val_loss: 1.4684 - val_accuracy: 0.6256\n",
      "Epoch 57/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7748 - accuracy: 0.3349 - val_loss: 1.4546 - val_accuracy: 0.6273\n",
      "Epoch 58/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7575 - accuracy: 0.3436 - val_loss: 1.4394 - val_accuracy: 0.6406\n",
      "Epoch 59/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7396 - accuracy: 0.3552 - val_loss: 1.4226 - val_accuracy: 0.6439\n",
      "Epoch 60/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7225 - accuracy: 0.3582 - val_loss: 1.4073 - val_accuracy: 0.6339\n",
      "Epoch 61/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7091 - accuracy: 0.3644 - val_loss: 1.3919 - val_accuracy: 0.6439\n",
      "Epoch 62/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7104 - accuracy: 0.3740 - val_loss: 1.3765 - val_accuracy: 0.6456\n",
      "Epoch 63/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7043 - accuracy: 0.3827 - val_loss: 1.3598 - val_accuracy: 0.6456\n",
      "Epoch 64/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6790 - accuracy: 0.3898 - val_loss: 1.3410 - val_accuracy: 0.6456\n",
      "Epoch 65/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6340 - accuracy: 0.4072 - val_loss: 1.3278 - val_accuracy: 0.6489\n",
      "Epoch 66/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6324 - accuracy: 0.4052 - val_loss: 1.3125 - val_accuracy: 0.6473\n",
      "Epoch 67/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6240 - accuracy: 0.4168 - val_loss: 1.2983 - val_accuracy: 0.6489\n",
      "Epoch 68/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6196 - accuracy: 0.4201 - val_loss: 1.2834 - val_accuracy: 0.6522\n",
      "Epoch 69/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5933 - accuracy: 0.4135 - val_loss: 1.2685 - val_accuracy: 0.6539\n",
      "Epoch 70/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5899 - accuracy: 0.4264 - val_loss: 1.2548 - val_accuracy: 0.6539\n",
      "Epoch 71/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5525 - accuracy: 0.4538 - val_loss: 1.2410 - val_accuracy: 0.6539\n",
      "Epoch 72/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5293 - accuracy: 0.4588 - val_loss: 1.2270 - val_accuracy: 0.6506\n",
      "Epoch 73/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5342 - accuracy: 0.4542 - val_loss: 1.2118 - val_accuracy: 0.6522\n",
      "Epoch 74/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5129 - accuracy: 0.4601 - val_loss: 1.1981 - val_accuracy: 0.6539\n",
      "Epoch 75/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.5073 - accuracy: 0.4563 - val_loss: 1.1840 - val_accuracy: 0.6539\n",
      "Epoch 76/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4972 - accuracy: 0.4597 - val_loss: 1.1700 - val_accuracy: 0.6539\n",
      "Epoch 77/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4798 - accuracy: 0.4688 - val_loss: 1.1560 - val_accuracy: 0.6572\n",
      "Epoch 78/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4624 - accuracy: 0.4734 - val_loss: 1.1429 - val_accuracy: 0.6539\n",
      "Epoch 79/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4521 - accuracy: 0.4829 - val_loss: 1.1303 - val_accuracy: 0.6589\n",
      "Epoch 80/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4398 - accuracy: 0.4813 - val_loss: 1.1169 - val_accuracy: 0.6589\n",
      "Epoch 81/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4133 - accuracy: 0.5025 - val_loss: 1.1048 - val_accuracy: 0.6589\n",
      "Epoch 82/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3932 - accuracy: 0.5112 - val_loss: 1.0941 - val_accuracy: 0.6589\n",
      "Epoch 83/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3891 - accuracy: 0.5137 - val_loss: 1.0807 - val_accuracy: 0.6606\n",
      "Epoch 84/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3786 - accuracy: 0.5046 - val_loss: 1.0678 - val_accuracy: 0.6639\n",
      "Epoch 85/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3736 - accuracy: 0.5150 - val_loss: 1.0577 - val_accuracy: 0.6639\n",
      "Epoch 86/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3445 - accuracy: 0.5291 - val_loss: 1.0454 - val_accuracy: 0.6656\n",
      "Epoch 87/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3089 - accuracy: 0.5453 - val_loss: 1.0319 - val_accuracy: 0.6672\n",
      "Epoch 88/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3280 - accuracy: 0.5233 - val_loss: 1.0210 - val_accuracy: 0.6689\n",
      "Epoch 89/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2911 - accuracy: 0.5449 - val_loss: 1.0101 - val_accuracy: 0.6672\n",
      "Epoch 90/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2970 - accuracy: 0.5437 - val_loss: 1.0022 - val_accuracy: 0.6689\n",
      "Epoch 91/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2845 - accuracy: 0.5545 - val_loss: 0.9934 - val_accuracy: 0.6689\n",
      "Epoch 92/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2457 - accuracy: 0.5720 - val_loss: 0.9821 - val_accuracy: 0.6705\n",
      "Epoch 93/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2588 - accuracy: 0.5445 - val_loss: 0.9730 - val_accuracy: 0.6722\n",
      "Epoch 94/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2376 - accuracy: 0.5620 - val_loss: 0.9652 - val_accuracy: 0.6672\n",
      "Epoch 95/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2170 - accuracy: 0.5836 - val_loss: 0.9560 - val_accuracy: 0.6689\n",
      "Epoch 96/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.1995 - accuracy: 0.5832 - val_loss: 0.9425 - val_accuracy: 0.6789\n",
      "Epoch 97/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2052 - accuracy: 0.5874 - val_loss: 0.9349 - val_accuracy: 0.6805\n",
      "Epoch 98/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.1865 - accuracy: 0.5874 - val_loss: 0.9270 - val_accuracy: 0.6805\n",
      "Epoch 99/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.1862 - accuracy: 0.5782 - val_loss: 0.9202 - val_accuracy: 0.6822\n",
      "Epoch 100/100\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.1783 - accuracy: 0.5948 - val_loss: 0.9116 - val_accuracy: 0.6839\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,  batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aaa1520d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a7a5ac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7016/3798557023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_actual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "yhat = np.argmax(model.predict(X_train), axis=1)\n",
    "y_actual = np.argmax(y_train, axis=1)\n",
    "print(np.count_nonzero(yhat != y_actual)/len(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76b325f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55ab5a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 6, 2, 3, 3, 7, 7, 5, 6, 2, 4, 5, 3, 1, 2, 7, 1, 5, 6, 2,\n",
       "       2, 7, 1, 0, 7, 6, 1, 5, 2, 6, 2, 6, 1, 2, 6, 7, 7, 7, 2, 2, 7, 7,\n",
       "       6, 0, 2, 6, 5, 0, 1, 0, 5, 3, 2, 2, 5, 6, 7, 7, 7, 7, 2, 6, 3, 6,\n",
       "       5, 5, 3, 3, 0, 2, 0, 4, 7, 0, 2, 0, 0, 2, 1, 2, 7, 5, 0, 5, 2, 1,\n",
       "       1, 3, 3, 4, 1, 0, 6, 7, 6, 2, 5, 3, 1, 2, 1, 1, 2, 7, 6, 7, 6, 6,\n",
       "       7, 2, 7, 2, 6, 0, 2, 2, 6, 2, 2, 3, 2, 6, 0, 7, 0, 2, 5, 6, 7, 1,\n",
       "       5, 6, 6, 5, 2, 2, 4, 6, 7, 5, 2, 2, 0, 2, 5, 1, 7, 2, 2, 6, 5, 5,\n",
       "       5, 0, 6, 3, 4, 7, 7, 4, 6, 5, 5, 1, 1, 6, 4, 0, 3, 1, 5, 1, 5, 7,\n",
       "       7, 6, 1, 1, 3, 7, 7, 1, 3, 0, 7, 5, 5, 0, 0, 2, 6, 2, 1, 1, 4, 3,\n",
       "       2, 5, 2, 7, 2, 0, 6, 7, 7, 1, 2, 5, 5, 6, 0, 4, 2, 6, 3, 0, 3, 1,\n",
       "       4, 6, 2, 7, 1, 1, 0, 6, 5, 6, 4, 5, 7, 5, 1, 5, 6, 0, 2, 6, 0, 0,\n",
       "       6, 2, 0, 5, 2, 5, 3, 5, 1, 6, 5, 5, 2, 6, 2, 4, 2, 0, 1, 3, 2, 7,\n",
       "       3, 3, 6, 5, 1, 7, 5, 1, 4, 0, 7, 0, 7, 7, 2, 0, 5, 1, 4, 4, 2, 6,\n",
       "       0, 0, 4, 5, 0, 2, 2, 0, 4, 1, 3, 0, 1, 1, 6, 7, 1, 6, 5, 7, 0, 6,\n",
       "       5, 1, 0, 7, 7, 0, 2, 3, 6, 5, 0, 5, 6, 2, 3, 1, 6, 2, 6, 7, 2, 2,\n",
       "       2, 7, 0, 5, 2, 2, 4, 0, 6, 6, 0, 4, 2, 6, 6, 1, 2, 6, 0, 2, 6, 2,\n",
       "       4, 5, 1, 1, 7, 1, 0, 1, 1, 2, 1, 6, 2, 7, 0, 2, 3, 7, 7, 6, 5, 7,\n",
       "       4, 2, 6, 6, 7, 3, 1, 1, 3, 1, 4, 6, 7, 1, 3, 5, 4, 5, 6, 0, 4, 2,\n",
       "       1, 2, 4, 3, 0, 1, 1, 7, 1, 1, 2, 6, 1, 3, 5, 1, 7, 1, 6, 1, 6, 3,\n",
       "       0, 5, 6, 1, 1, 7, 1, 1, 2, 0, 5, 5, 0, 6, 0, 2, 5, 5, 2, 0, 4, 3,\n",
       "       2, 0, 5, 7, 7, 1, 2, 7, 7, 2, 2, 3, 2, 0, 2, 6, 6, 5, 5, 6, 5, 5,\n",
       "       7, 5, 1, 7, 2, 2, 6, 1, 7, 3, 1, 7, 6, 5, 4, 7, 5, 1, 3, 2, 6, 0,\n",
       "       7, 3, 7, 1, 7, 6, 4, 0, 7, 2, 5, 0, 6, 0, 2, 5, 6, 5, 2, 7, 3, 7,\n",
       "       0, 1, 7, 3, 3, 3, 3, 2, 3, 3, 2, 2, 7, 6, 4, 1, 0, 0, 7, 2, 7, 0,\n",
       "       5, 7, 5, 7, 5, 6, 5, 1, 7, 6, 1, 7, 2, 1, 1, 5, 7, 5, 0, 1, 4, 5,\n",
       "       2, 5, 2, 3, 0, 7, 5, 5, 0, 6, 7, 6, 1, 5, 7, 6, 5, 1, 2, 2, 6, 5,\n",
       "       4, 2, 6, 7, 7, 6, 1, 3, 5, 7, 5, 2, 6, 7, 6, 4, 5, 6, 3, 7, 5, 3,\n",
       "       6, 1, 6, 6, 2, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_test_actual = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "962820a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "y_pred = [0, 2, 1, 3, 5]\n",
    "y_true = [0, 1, 2, 3, 5]\n",
    "print(accuracy_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9afb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv2022] *",
   "language": "python",
   "name": "conda-env-mlenv2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
