{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77419fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27c4fc",
   "metadata": {},
   "source": [
    "# Read in the data to on dictionary of each Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426f416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On act\n",
      "On acw\n",
      "On dc\n",
      "On pm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, '1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "# Test out the read in helper function\n",
    "def get_subject_action(sensor, full_path):\n",
    "    index = full_path.find(sensor)\n",
    "    index += len(sensor)\n",
    "    subject = int(full_path[index+1:index+3])\n",
    "    action = int(full_path[index+4:index+6])\n",
    "    if action == 4:\n",
    "        if full_path.find(f\"{sensor}_1\") > 0:\n",
    "            action = '4-1'\n",
    "        else:\n",
    "            action = '4-2'\n",
    "        \n",
    "    return (subject, str(action))\n",
    "\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                #print(full_path, get_subject_action(sensor, full_path))\n",
    "                \n",
    "test_str = '.\\\\data\\\\act\\\\01\\\\01_act_1.csv'\n",
    "get_subject_action('act', test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5b8e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d54df7fd843dd9f726e6de5bd6bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data:   0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_data = {\n",
    "    'act': None,\n",
    "    'acw': None,\n",
    "    'dc': None,\n",
    "    'pm': None,\n",
    "}\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'act': ['times', 'X', 'Y', 'Z'],\n",
    "    'acw': ['times', 'X', 'Y', 'Z'],\n",
    "    'dc': ['times'],\n",
    "    'pm': ['times']\n",
    "}\n",
    "for i in range(1,513):\n",
    "    headers['pm'].append(f\"sensor_{i}\")\n",
    "for i in range(1,193):\n",
    "    headers['dc'].append(f\"sensor_{i}\")\n",
    "\n",
    "actions = ['1', '2', '3', '4-1', '4-2', '5', '6', '7']\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "#sensor_list = ['acw']\n",
    "\n",
    "# there are 956 files in our dataset\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(desc=\"load data\", total=956)\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        #print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                df_tmp = pd.read_csv(full_path, names=headers[sensor])\n",
    "                i+=1\n",
    "                pbar.update(1)\n",
    "                subject, action = get_subject_action(sensor, full_path)\n",
    "                # add one to make it match the given format\n",
    "                df_tmp['subject'] = subject\n",
    "                df_tmp['action'] = action\n",
    "                if total_data[sensor] is None:\n",
    "                    total_data[sensor] = df_tmp\n",
    "                else:\n",
    "                    total_data[sensor] = pd.concat([total_data[sensor], df_tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b125061",
   "metadata": {},
   "source": [
    "## Show what is in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a129e3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1400856 entries, 0 to 6418\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1400856 non-null  object \n",
      " 1   X        1400856 non-null  float64\n",
      " 2   Y        1400856 non-null  float64\n",
      " 3   Z        1400856 non-null  float64\n",
      " 4   subject  1400856 non-null  int64  \n",
      " 5   action   1400856 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 74.8+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "acw\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1313695 entries, 0 to 6013\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1313695 non-null  object \n",
      " 1   X        1313695 non-null  float64\n",
      " 2   Y        1313695 non-null  float64\n",
      " 3   Z        1313695 non-null  float64\n",
      " 4   subject  1313695 non-null  int64  \n",
      " 5   action   1313695 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 70.2+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "dc\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140694 entries, 0 to 624\n",
      "Columns: 195 entries, times to action\n",
      "dtypes: float64(192), int64(1), object(2)\n",
      "memory usage: 210.4+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n",
      "pm\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 202682 entries, 0 to 927\n",
      "Columns: 515 entries, times to action\n",
      "dtypes: float64(512), int64(1), object(2)\n",
      "memory usage: 797.9+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in total_data.keys():\n",
    "    if total_data[key] is not None:\n",
    "        print(key)\n",
    "        print(total_data[key]['action'].unique())\n",
    "        print(total_data[key]['subject'].unique())\n",
    "        for header in headers[key]:\n",
    "            if(total_data[key][header].isnull().values.any()):\n",
    "                print(f\"{header} has Null data\")\n",
    "        print(total_data[key].info())\n",
    "        print('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83bc0733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>2018-11-08 11:35:56.373000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>2018-11-08 11:35:56.383000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>2018-11-08 11:35:56.394000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>2018-11-08 11:35:56.404000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>2018-11-08 11:35:56.414000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           times         X         Y        Z  subject action\n",
       "0     2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1     2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2     2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3     2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4     2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1\n",
       "...                          ...       ...       ...      ...      ...    ...\n",
       "6269  2018-11-08 11:35:56.373000  0.093750 -0.265625  0.87500        1      1\n",
       "6270  2018-11-08 11:35:56.383000  0.093750 -0.281250  0.87500        1      1\n",
       "6271  2018-11-08 11:35:56.394000  0.093750 -0.265625  0.87500        1      1\n",
       "6272  2018-11-08 11:35:56.404000  0.093750 -0.265625  0.87500        1      1\n",
       "6273  2018-11-08 11:35:56.414000  0.093750 -0.265625  0.87500        1      1\n",
       "\n",
       "[6274 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acw = total_data['acw']\n",
    "subject = 1\n",
    "action = '1'\n",
    "df_acw[(df_acw.subject == subject) & (df_acw.action == action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e445b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_505</th>\n",
       "      <th>sensor_506</th>\n",
       "      <th>sensor_507</th>\n",
       "      <th>sensor_508</th>\n",
       "      <th>sensor_509</th>\n",
       "      <th>sensor_510</th>\n",
       "      <th>sensor_511</th>\n",
       "      <th>sensor_512</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.468000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.535000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.602000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.669000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.737000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0  2018-11-08 11:34:51.468000      20.0       3.0       2.0       0.0   \n",
       "1  2018-11-08 11:34:51.535000      20.0       3.0       2.0       0.0   \n",
       "2  2018-11-08 11:34:51.602000      20.0       3.0       2.0       0.0   \n",
       "3  2018-11-08 11:34:51.669000      20.0       3.0       2.0       0.0   \n",
       "4  2018-11-08 11:34:51.737000      20.0       3.0       2.0       0.0   \n",
       "\n",
       "   sensor_5  sensor_6  sensor_7  sensor_8  sensor_9  ...  sensor_505  \\\n",
       "0       0.0       0.0      72.0    1493.0    1949.0  ...        68.0   \n",
       "1       0.0       0.0      72.0    1493.0    1949.0  ...        58.0   \n",
       "2       0.0       0.0      72.0    1493.0    1949.0  ...        64.0   \n",
       "3       0.0       0.0      72.0    1493.0    1949.0  ...        66.0   \n",
       "4       0.0       0.0      72.0    1493.0    1949.0  ...        64.0   \n",
       "\n",
       "   sensor_506  sensor_507  sensor_508  sensor_509  sensor_510  sensor_511  \\\n",
       "0        77.0        55.0       193.0       387.0       331.0       125.0   \n",
       "1        78.0        53.0       192.0       388.0       330.0       123.0   \n",
       "2        78.0        53.0       195.0       390.0       330.0       119.0   \n",
       "3        79.0        55.0       196.0       391.0       324.0       106.0   \n",
       "4        79.0        55.0       194.0       391.0       321.0       114.0   \n",
       "\n",
       "   sensor_512  subject  action  \n",
       "0         6.0        1       1  \n",
       "1         6.0        1       1  \n",
       "2         7.0        1       1  \n",
       "3         5.0        1       1  \n",
       "4         6.0        1       1  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data['pm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91052a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  0,  1,  2,  3,  0,  1,  2,  3,  4],\n",
       "       [ 4,  5,  6,  4,  5,  6,  7,  5,  6,  7,  8,  9],\n",
       "       [ 7,  8,  9,  8,  9, 10, 11, 10, 11, 12, 13, 14],\n",
       "       [10, 11, 12, 12, 13, 14, 15, 15, 16, 17, 18, 19],\n",
       "       [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
       "       [16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show reshape is doing what we think\n",
    "x = np.array([[1,2,3],\n",
    "          [4,5,6],\n",
    "          [7,8,9],\n",
    "          [10,11,12],\n",
    "          [13,14,15],\n",
    "          [16,17,18]])\n",
    "y = np.array(range(0,24))\n",
    "y = np.reshape(y, (6,4))\n",
    "\n",
    "z = np.array(range(0,30))\n",
    "z = np.reshape(z, (6, 5))\n",
    "\n",
    "\n",
    "np.hstack((x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe597356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c88b6d0119408fa3d97e2486fb8d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch data:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acw_X_0</th>\n",
       "      <th>acw_Y_0</th>\n",
       "      <th>acw_Z_0</th>\n",
       "      <th>acw_X_1</th>\n",
       "      <th>acw_Y_1</th>\n",
       "      <th>acw_Z_1</th>\n",
       "      <th>acw_X_2</th>\n",
       "      <th>acw_Y_2</th>\n",
       "      <th>acw_Z_2</th>\n",
       "      <th>acw_X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>act_X_297</th>\n",
       "      <th>act_Y_297</th>\n",
       "      <th>act_Z_297</th>\n",
       "      <th>act_X_298</th>\n",
       "      <th>act_Y_298</th>\n",
       "      <th>act_Z_298</th>\n",
       "      <th>act_X_299</th>\n",
       "      <th>act_Y_299</th>\n",
       "      <th>act_Z_299</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640625</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>-0.656250</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-0.671875</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.796875</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.781250</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.609375</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.578125</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.593750</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    acw_X_0   acw_Y_0   acw_Z_0   acw_X_1   acw_Y_1   acw_Z_1   acw_X_2  \\\n",
       "0  0.125000 -0.046875  0.906250  0.109375 -0.062500  0.906250  0.109375   \n",
       "1  0.156250 -0.062500  0.906250  0.156250 -0.062500  0.890625  0.156250   \n",
       "2  0.218750 -0.078125  0.890625  0.218750 -0.078125  0.875000  0.234375   \n",
       "3  0.281250 -0.093750  0.859375  0.281250 -0.093750  0.875000  0.281250   \n",
       "4  0.359375 -0.062500  0.843750  0.359375 -0.062500  0.843750  0.359375   \n",
       "\n",
       "    acw_Y_2   acw_Z_2   acw_X_3  ...  act_X_297  act_Y_297  act_Z_297  \\\n",
       "0 -0.062500  0.906250  0.125000  ...  -0.640625  -0.562500   0.437500   \n",
       "1 -0.062500  0.890625  0.156250  ...  -0.625000  -0.796875   0.171875   \n",
       "2 -0.078125  0.890625  0.234375  ...  -0.593750  -0.750000   0.281250   \n",
       "3 -0.093750  0.859375  0.281250  ...  -0.593750  -0.734375   0.296875   \n",
       "4 -0.078125  0.843750  0.359375  ...  -0.593750  -0.734375   0.312500   \n",
       "\n",
       "   act_X_298  act_Y_298  act_Z_298  act_X_299  act_Y_299  act_Z_299  action  \n",
       "0  -0.656250  -0.562500   0.468750  -0.671875  -0.578125   0.468750       1  \n",
       "1  -0.625000  -0.781250   0.171875  -0.625000  -0.781250   0.171875       1  \n",
       "2  -0.609375  -0.750000   0.296875  -0.609375  -0.750000   0.296875       1  \n",
       "3  -0.593750  -0.734375   0.296875  -0.593750  -0.734375   0.296875       1  \n",
       "4  -0.578125  -0.734375   0.312500  -0.593750  -0.734375   0.296875       1  \n",
       "\n",
       "[5 rows x 33481 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# take the total dfs and make batches for each action each subject completed\n",
    "# samples100 is how many samples should be in the 100HZ (the two accleromter data)\n",
    "# samples15 is how many samples from the images should be take\n",
    "subjects = range(1,31)\n",
    "dc_X_cols = [f\"sensor_{i}\" for i in range(1,193)]\n",
    "pm_X_cols = [f\"sensor_{i}\" for i in range(1,513)]\n",
    "acw_X_cols = [\"X\", \"Y\", \"Z\"]\n",
    "\n",
    "def batch_data(total_dfs, seconds=5):\n",
    "    samples100 = 100*seconds\n",
    "    samples15 = 15*seconds\n",
    "    df_acw = total_dfs['acw']\n",
    "    df_act = total_dfs['act']\n",
    "    df_dc = total_dfs['dc']\n",
    "    df_pm = total_dfs['pm']\n",
    "    \n",
    "    all_cols = []\n",
    "    for i in range(0, samples100):\n",
    "        all_cols += [f\"acw_{val}_{i}\" for val in acw_X_cols]\n",
    "    for i in range(0, samples15):\n",
    "        all_cols += [f\"dc_{val}_{i}\" for val in dc_X_cols]\n",
    "    for i in range(0, samples15):\n",
    "        all_cols += [f\"pm_{val}_{i}\" for val in pm_X_cols]\n",
    "    for i in range(0, samples100):\n",
    "        all_cols += [f\"act_{val}_{i}\" for val in acw_X_cols]\n",
    "    \n",
    "    \n",
    "    df_all = pd.DataFrame(columns=all_cols+['action'])\n",
    "    \n",
    "    actions = df_acw['action'].unique()\n",
    "    pbar = tqdm(desc=\"batch data\", total=len(subjects)*len(actions))\n",
    "    for subject in subjects:\n",
    "        actions = df_acw['action'].unique()\n",
    "        for action in actions:\n",
    "            X_acw = df_acw[(df_acw.subject == subject) & (df_acw.action == action)][acw_X_cols].to_numpy()\n",
    "            X_acw = X_acw[range(0, (X_acw.shape[0]//samples100)*samples100)] # cut off records that don't fit in the window\n",
    "            X_acw = np.reshape(X_acw, (X_acw.shape[0]//samples100, samples100*len(acw_X_cols)))\n",
    "            \n",
    "            X_dc = df_dc[(df_dc.subject == subject) & (df_dc.action == action)][dc_X_cols].to_numpy()\n",
    "            X_dc = X_dc[range(0, (X_dc.shape[0]//samples15)*samples15)]\n",
    "            X_dc = np.reshape(X_dc, (X_dc.shape[0]//samples15, samples15*len(dc_X_cols)))\n",
    "            \n",
    "            X_pm = df_pm[(df_pm.subject == subject) & (df_pm.action == action)][pm_X_cols].to_numpy()\n",
    "            X_pm = X_pm[range(0, (X_pm.shape[0]//samples15)*samples15)]\n",
    "            X_pm = np.reshape(X_pm, (X_pm.shape[0]//samples15, samples15*len(pm_X_cols)))\n",
    "            \n",
    "            X_act = df_act[(df_act.subject == subject) & (df_act.action == action)][acw_X_cols].to_numpy()\n",
    "            X_act = X_act[range(0, (X_act.shape[0]//samples100)*samples100)]\n",
    "            X_act = np.reshape(X_act, (X_act.shape[0]//samples100, samples100*len(acw_X_cols)))\n",
    "            \n",
    "            # trim to the smallest one of these 4\n",
    "            num_records = min(X_acw.shape[0], X_act.shape[0], X_pm.shape[0], X_dc.shape[0])\n",
    "            X_acw = X_acw[range(0,num_records)]\n",
    "            X_dc = X_dc[range(0,num_records)]\n",
    "            X_pm = X_pm[range(0,num_records)]\n",
    "            X_act = X_act[range(0,num_records)]\n",
    "            \n",
    "            X_total = np.hstack((X_acw, X_dc, X_pm, X_act))\n",
    "            \n",
    "            df_tmp = pd.DataFrame(X_total, columns=all_cols)\n",
    "            df_tmp['action'] = action\n",
    "            df_all = pd.concat([df_all, df_tmp])\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "    return df_all\n",
    "\n",
    "df_batched = batch_data(total_data, seconds=3)\n",
    "df_batched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e15e1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acw_X_0</th>\n",
       "      <th>acw_Y_0</th>\n",
       "      <th>acw_Z_0</th>\n",
       "      <th>acw_X_1</th>\n",
       "      <th>acw_Y_1</th>\n",
       "      <th>acw_Z_1</th>\n",
       "      <th>acw_X_2</th>\n",
       "      <th>acw_Y_2</th>\n",
       "      <th>acw_Z_2</th>\n",
       "      <th>acw_X_3</th>\n",
       "      <th>...</th>\n",
       "      <th>act_Z_296</th>\n",
       "      <th>act_X_297</th>\n",
       "      <th>act_Y_297</th>\n",
       "      <th>act_Z_297</th>\n",
       "      <th>act_X_298</th>\n",
       "      <th>act_Y_298</th>\n",
       "      <th>act_Z_298</th>\n",
       "      <th>act_X_299</th>\n",
       "      <th>act_Y_299</th>\n",
       "      <th>act_Z_299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>...</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>...</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>...</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-1</th>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>...</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>...</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>...</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33480 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acw_X_0  acw_Y_0  acw_Z_0  acw_X_1  acw_Y_1  acw_Z_1  acw_X_2  \\\n",
       "action                                                                  \n",
       "1           419      419      419      419      419      419      419   \n",
       "2           447      447      447      447      447      447      447   \n",
       "3           449      449      449      449      449      449      449   \n",
       "4-1         226      226      226      226      226      226      226   \n",
       "4-2         198      198      198      198      198      198      198   \n",
       "5           427      427      427      427      427      427      427   \n",
       "6           398      398      398      398      398      398      398   \n",
       "7           441      441      441      441      441      441      441   \n",
       "\n",
       "        acw_Y_2  acw_Z_2  acw_X_3  ...  act_Z_296  act_X_297  act_Y_297  \\\n",
       "action                             ...                                    \n",
       "1           419      419      419  ...        419        419        419   \n",
       "2           447      447      447  ...        447        447        447   \n",
       "3           449      449      449  ...        449        449        449   \n",
       "4-1         226      226      226  ...        226        226        226   \n",
       "4-2         198      198      198  ...        198        198        198   \n",
       "5           427      427      427  ...        427        427        427   \n",
       "6           398      398      398  ...        398        398        398   \n",
       "7           441      441      441  ...        441        441        441   \n",
       "\n",
       "        act_Z_297  act_X_298  act_Y_298  act_Z_298  act_X_299  act_Y_299  \\\n",
       "action                                                                     \n",
       "1             419        419        419        419        419        419   \n",
       "2             447        447        447        447        447        447   \n",
       "3             449        449        449        449        449        449   \n",
       "4-1           226        226        226        226        226        226   \n",
       "4-2           198        198        198        198        198        198   \n",
       "5             427        427        427        427        427        427   \n",
       "6             398        398        398        398        398        398   \n",
       "7             441        441        441        441        441        441   \n",
       "\n",
       "        act_Z_299  \n",
       "action             \n",
       "1             419  \n",
       "2             447  \n",
       "3             449  \n",
       "4-1           226  \n",
       "4-2           198  \n",
       "5             427  \n",
       "6             398  \n",
       "7             441  \n",
       "\n",
       "[8 rows x 33480 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batched.groupby('action').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72df9b6",
   "metadata": {},
   "source": [
    "# Stick the data into a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4218b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = 3\n",
    "samples100 = 100*seconds\n",
    "samples15 = 15*seconds\n",
    "\n",
    "all_cols = []\n",
    "for i in range(0, samples100):\n",
    "    all_cols += [f\"acw_{val}_{i}\" for val in acw_X_cols]\n",
    "for i in range(0, samples15):\n",
    "    all_cols += [f\"dc_{val}_{i}\" for val in dc_X_cols]\n",
    "for i in range(0, samples15):\n",
    "    all_cols += [f\"pm_{val}_{i}\" for val in pm_X_cols]\n",
    "for i in range(0, samples100):\n",
    "    all_cols += [f\"act_{val}_{i}\" for val in acw_X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72132f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3005, 33480)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_batched[all_cols].to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9cb0aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.get_dummies(df_batched.action, prefix='action_ohe')\n",
    "y = df_y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2baead",
   "metadata": {},
   "source": [
    "### Train test split real quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1302b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17b02d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Input, GRU, SimpleRNN, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "def get_combined_model():\n",
    "    input_all = Input(shape=(X.shape[1],))\n",
    "    x = Dense(units=2048, activation='sigmoid',kernel_initializer='random_normal')(input_all)\n",
    "    x = Dense(units=1024, activation='sigmoid',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(units=512, activation='sigmoid',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(units=512, activation='tanh',kernel_initializer='random_normal')(x)\n",
    "    prediction = Dense(units=8, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_all, outputs=prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba4a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 33480)]           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              68569088  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 71,984,136\n",
      "Trainable params: 71,984,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model = get_combined_model()\n",
    "model.compile(optimizer=Adam(learning_rate=0.000001, beta_1=0.99, beta_2=0.999),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0c56351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2404 samples, validate on 601 samples\n",
      "Epoch 1/200\n",
      "2404/2404 [==============================] - 5s 2ms/sample - loss: 2.2838 - accuracy: 0.1331 - val_loss: 2.0574 - val_accuracy: 0.1464\n",
      "Epoch 2/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2493 - accuracy: 0.1485 - val_loss: 2.0255 - val_accuracy: 0.1597\n",
      "Epoch 3/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2334 - accuracy: 0.1402 - val_loss: 2.0164 - val_accuracy: 0.1614\n",
      "Epoch 4/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.2151 - accuracy: 0.1498 - val_loss: 2.0080 - val_accuracy: 0.2246\n",
      "Epoch 5/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1825 - accuracy: 0.1577 - val_loss: 2.0022 - val_accuracy: 0.2579\n",
      "Epoch 6/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 2.1848 - accuracy: 0.1585 - val_loss: 1.9948 - val_accuracy: 0.3028\n",
      "Epoch 7/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 2.1971 - accuracy: 0.1593 - val_loss: 1.9878 - val_accuracy: 0.3228\n",
      "Epoch 8/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 2.1872 - accuracy: 0.1514 - val_loss: 1.9816 - val_accuracy: 0.3261\n",
      "Epoch 9/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1932 - accuracy: 0.1443 - val_loss: 1.9753 - val_accuracy: 0.3311\n",
      "Epoch 10/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1679 - accuracy: 0.1664 - val_loss: 1.9689 - val_accuracy: 0.3627\n",
      "Epoch 11/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1929 - accuracy: 0.1531 - val_loss: 1.9610 - val_accuracy: 0.3727\n",
      "Epoch 12/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1719 - accuracy: 0.1651 - val_loss: 1.9549 - val_accuracy: 0.3894\n",
      "Epoch 13/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1413 - accuracy: 0.1701 - val_loss: 1.9483 - val_accuracy: 0.4110\n",
      "Epoch 14/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1585 - accuracy: 0.1668 - val_loss: 1.9419 - val_accuracy: 0.4010\n",
      "Epoch 15/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1453 - accuracy: 0.1822 - val_loss: 1.9331 - val_accuracy: 0.4326\n",
      "Epoch 16/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1559 - accuracy: 0.1739 - val_loss: 1.9278 - val_accuracy: 0.4359\n",
      "Epoch 17/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1676 - accuracy: 0.1643 - val_loss: 1.9202 - val_accuracy: 0.4493\n",
      "Epoch 18/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1285 - accuracy: 0.1789 - val_loss: 1.9105 - val_accuracy: 0.4559\n",
      "Epoch 19/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1405 - accuracy: 0.1893 - val_loss: 1.9055 - val_accuracy: 0.4476\n",
      "Epoch 20/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1208 - accuracy: 0.1780 - val_loss: 1.8974 - val_accuracy: 0.4692\n",
      "Epoch 21/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0849 - accuracy: 0.1963 - val_loss: 1.8902 - val_accuracy: 0.4642\n",
      "Epoch 22/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0992 - accuracy: 0.1905 - val_loss: 1.8822 - val_accuracy: 0.4908\n",
      "Epoch 23/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1198 - accuracy: 0.1872 - val_loss: 1.8742 - val_accuracy: 0.4908\n",
      "Epoch 24/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0820 - accuracy: 0.2047 - val_loss: 1.8644 - val_accuracy: 0.4942\n",
      "Epoch 25/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.1038 - accuracy: 0.1901 - val_loss: 1.8564 - val_accuracy: 0.5075\n",
      "Epoch 26/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0747 - accuracy: 0.2009 - val_loss: 1.8468 - val_accuracy: 0.5092\n",
      "Epoch 27/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0676 - accuracy: 0.2051 - val_loss: 1.8399 - val_accuracy: 0.5042\n",
      "Epoch 28/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0807 - accuracy: 0.1943 - val_loss: 1.8309 - val_accuracy: 0.5208\n",
      "Epoch 29/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0374 - accuracy: 0.2130 - val_loss: 1.8218 - val_accuracy: 0.5058\n",
      "Epoch 30/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0606 - accuracy: 0.2105 - val_loss: 1.8121 - val_accuracy: 0.5358\n",
      "Epoch 31/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0597 - accuracy: 0.2076 - val_loss: 1.8022 - val_accuracy: 0.5208\n",
      "Epoch 32/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0259 - accuracy: 0.2292 - val_loss: 1.7926 - val_accuracy: 0.5324\n",
      "Epoch 33/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0178 - accuracy: 0.2200 - val_loss: 1.7840 - val_accuracy: 0.5524\n",
      "Epoch 34/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 2.0218 - accuracy: 0.2225 - val_loss: 1.7760 - val_accuracy: 0.5674\n",
      "Epoch 35/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0133 - accuracy: 0.2167 - val_loss: 1.7642 - val_accuracy: 0.5491\n",
      "Epoch 36/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0151 - accuracy: 0.2292 - val_loss: 1.7531 - val_accuracy: 0.5657\n",
      "Epoch 37/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.0028 - accuracy: 0.2309 - val_loss: 1.7430 - val_accuracy: 0.5707\n",
      "Epoch 38/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.9749 - accuracy: 0.2479 - val_loss: 1.7321 - val_accuracy: 0.5807\n",
      "Epoch 39/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.9779 - accuracy: 0.2450 - val_loss: 1.7213 - val_accuracy: 0.5757\n",
      "Epoch 40/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.9724 - accuracy: 0.2446 - val_loss: 1.7104 - val_accuracy: 0.5840\n",
      "Epoch 41/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.9358 - accuracy: 0.2716 - val_loss: 1.6982 - val_accuracy: 0.5790\n",
      "Epoch 42/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.9504 - accuracy: 0.2629 - val_loss: 1.6856 - val_accuracy: 0.5824\n",
      "Epoch 43/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.9274 - accuracy: 0.2733 - val_loss: 1.6729 - val_accuracy: 0.5874\n",
      "Epoch 44/200\n",
      "2404/2404 [==============================] - 2s 653us/sample - loss: 1.9403 - accuracy: 0.2571 - val_loss: 1.6617 - val_accuracy: 0.5940\n",
      "Epoch 45/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8943 - accuracy: 0.3032 - val_loss: 1.6491 - val_accuracy: 0.6023\n",
      "Epoch 46/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.8850 - accuracy: 0.2708 - val_loss: 1.6377 - val_accuracy: 0.5923\n",
      "Epoch 47/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.8980 - accuracy: 0.2779 - val_loss: 1.6235 - val_accuracy: 0.5890\n",
      "Epoch 48/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8866 - accuracy: 0.2899 - val_loss: 1.6116 - val_accuracy: 0.5940\n",
      "Epoch 49/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8789 - accuracy: 0.2837 - val_loss: 1.5973 - val_accuracy: 0.6090\n",
      "Epoch 50/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8485 - accuracy: 0.3049 - val_loss: 1.5844 - val_accuracy: 0.5940\n",
      "Epoch 51/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8630 - accuracy: 0.3032 - val_loss: 1.5702 - val_accuracy: 0.6073\n",
      "Epoch 52/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8038 - accuracy: 0.3299 - val_loss: 1.5564 - val_accuracy: 0.6090\n",
      "Epoch 53/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8270 - accuracy: 0.3224 - val_loss: 1.5415 - val_accuracy: 0.6106\n",
      "Epoch 54/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8359 - accuracy: 0.3132 - val_loss: 1.5271 - val_accuracy: 0.6123\n",
      "Epoch 55/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.8006 - accuracy: 0.3315 - val_loss: 1.5124 - val_accuracy: 0.6123\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7752 - accuracy: 0.3557 - val_loss: 1.4983 - val_accuracy: 0.6073\n",
      "Epoch 57/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7629 - accuracy: 0.3473 - val_loss: 1.4833 - val_accuracy: 0.6123\n",
      "Epoch 58/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.7473 - accuracy: 0.3623 - val_loss: 1.4688 - val_accuracy: 0.6206\n",
      "Epoch 59/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7494 - accuracy: 0.3619 - val_loss: 1.4548 - val_accuracy: 0.6156\n",
      "Epoch 60/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7315 - accuracy: 0.3669 - val_loss: 1.4399 - val_accuracy: 0.6173\n",
      "Epoch 61/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7065 - accuracy: 0.3802 - val_loss: 1.4248 - val_accuracy: 0.6206\n",
      "Epoch 62/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.7120 - accuracy: 0.3702 - val_loss: 1.4101 - val_accuracy: 0.6223\n",
      "Epoch 63/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.6907 - accuracy: 0.3827 - val_loss: 1.3956 - val_accuracy: 0.6223\n",
      "Epoch 64/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.7008 - accuracy: 0.3640 - val_loss: 1.3814 - val_accuracy: 0.6156\n",
      "Epoch 65/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.6684 - accuracy: 0.3939 - val_loss: 1.3669 - val_accuracy: 0.6173\n",
      "Epoch 66/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.6538 - accuracy: 0.3844 - val_loss: 1.3510 - val_accuracy: 0.6273\n",
      "Epoch 67/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.6417 - accuracy: 0.4060 - val_loss: 1.3371 - val_accuracy: 0.6290\n",
      "Epoch 68/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.6376 - accuracy: 0.4106 - val_loss: 1.3224 - val_accuracy: 0.6323\n",
      "Epoch 69/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.6073 - accuracy: 0.4176 - val_loss: 1.3086 - val_accuracy: 0.6306\n",
      "Epoch 70/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.5904 - accuracy: 0.4226 - val_loss: 1.2947 - val_accuracy: 0.6389\n",
      "Epoch 71/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5851 - accuracy: 0.4305 - val_loss: 1.2794 - val_accuracy: 0.6356\n",
      "Epoch 72/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5663 - accuracy: 0.4430 - val_loss: 1.2660 - val_accuracy: 0.6389\n",
      "Epoch 73/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5396 - accuracy: 0.4555 - val_loss: 1.2522 - val_accuracy: 0.6406\n",
      "Epoch 74/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5233 - accuracy: 0.4472 - val_loss: 1.2390 - val_accuracy: 0.6389\n",
      "Epoch 75/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.5199 - accuracy: 0.4576 - val_loss: 1.2256 - val_accuracy: 0.6406\n",
      "Epoch 76/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4887 - accuracy: 0.4767 - val_loss: 1.2123 - val_accuracy: 0.6406\n",
      "Epoch 77/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4803 - accuracy: 0.4742 - val_loss: 1.1996 - val_accuracy: 0.6423\n",
      "Epoch 78/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4600 - accuracy: 0.4775 - val_loss: 1.1878 - val_accuracy: 0.6406\n",
      "Epoch 79/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4577 - accuracy: 0.4759 - val_loss: 1.1745 - val_accuracy: 0.6473\n",
      "Epoch 80/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.4601 - accuracy: 0.4750 - val_loss: 1.1632 - val_accuracy: 0.6506\n",
      "Epoch 81/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.4228 - accuracy: 0.4854 - val_loss: 1.1514 - val_accuracy: 0.6456\n",
      "Epoch 82/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.4123 - accuracy: 0.4975 - val_loss: 1.1407 - val_accuracy: 0.6456\n",
      "Epoch 83/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.4085 - accuracy: 0.5075 - val_loss: 1.1302 - val_accuracy: 0.6439\n",
      "Epoch 84/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3837 - accuracy: 0.5033 - val_loss: 1.1188 - val_accuracy: 0.6539\n",
      "Epoch 85/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3667 - accuracy: 0.5183 - val_loss: 1.1072 - val_accuracy: 0.6506\n",
      "Epoch 86/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.3466 - accuracy: 0.5196 - val_loss: 1.0972 - val_accuracy: 0.6489\n",
      "Epoch 87/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.3470 - accuracy: 0.5262 - val_loss: 1.0853 - val_accuracy: 0.6522\n",
      "Epoch 88/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3276 - accuracy: 0.5295 - val_loss: 1.0746 - val_accuracy: 0.6556\n",
      "Epoch 89/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.3149 - accuracy: 0.5354 - val_loss: 1.0648 - val_accuracy: 0.6589\n",
      "Epoch 90/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2993 - accuracy: 0.5532 - val_loss: 1.0545 - val_accuracy: 0.6539\n",
      "Epoch 91/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2938 - accuracy: 0.5566 - val_loss: 1.0453 - val_accuracy: 0.6606\n",
      "Epoch 92/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2715 - accuracy: 0.5528 - val_loss: 1.0347 - val_accuracy: 0.6672\n",
      "Epoch 93/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2574 - accuracy: 0.5670 - val_loss: 1.0268 - val_accuracy: 0.6689\n",
      "Epoch 94/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.2538 - accuracy: 0.5516 - val_loss: 1.0166 - val_accuracy: 0.6689\n",
      "Epoch 95/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2526 - accuracy: 0.5532 - val_loss: 1.0073 - val_accuracy: 0.6705\n",
      "Epoch 96/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.2350 - accuracy: 0.5595 - val_loss: 1.0005 - val_accuracy: 0.6672\n",
      "Epoch 97/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2208 - accuracy: 0.5666 - val_loss: 0.9914 - val_accuracy: 0.6755\n",
      "Epoch 98/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.2051 - accuracy: 0.5865 - val_loss: 0.9839 - val_accuracy: 0.6739\n",
      "Epoch 99/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.1926 - accuracy: 0.5882 - val_loss: 0.9756 - val_accuracy: 0.6839\n",
      "Epoch 100/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.1858 - accuracy: 0.5695 - val_loss: 0.9659 - val_accuracy: 0.6839\n",
      "Epoch 101/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1755 - accuracy: 0.5815 - val_loss: 0.9598 - val_accuracy: 0.6839\n",
      "Epoch 102/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1616 - accuracy: 0.5944 - val_loss: 0.9522 - val_accuracy: 0.6872\n",
      "Epoch 103/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1358 - accuracy: 0.6061 - val_loss: 0.9459 - val_accuracy: 0.6889\n",
      "Epoch 104/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.1339 - accuracy: 0.5961 - val_loss: 0.9370 - val_accuracy: 0.6889\n",
      "Epoch 105/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.1138 - accuracy: 0.6144 - val_loss: 0.9279 - val_accuracy: 0.6905\n",
      "Epoch 106/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.1214 - accuracy: 0.5990 - val_loss: 0.9215 - val_accuracy: 0.7005\n",
      "Epoch 107/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0989 - accuracy: 0.6136 - val_loss: 0.9164 - val_accuracy: 0.6988\n",
      "Epoch 108/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.0880 - accuracy: 0.6102 - val_loss: 0.9089 - val_accuracy: 0.7005\n",
      "Epoch 109/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.0814 - accuracy: 0.6248 - val_loss: 0.9018 - val_accuracy: 0.7022\n",
      "Epoch 110/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.0674 - accuracy: 0.6140 - val_loss: 0.8961 - val_accuracy: 0.7072\n",
      "Epoch 111/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 1.0611 - accuracy: 0.6265 - val_loss: 0.8875 - val_accuracy: 0.7055\n",
      "Epoch 112/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0557 - accuracy: 0.6290 - val_loss: 0.8817 - val_accuracy: 0.7121\n",
      "Epoch 113/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 1.0535 - accuracy: 0.6377 - val_loss: 0.8758 - val_accuracy: 0.7138\n",
      "Epoch 114/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0431 - accuracy: 0.6360 - val_loss: 0.8711 - val_accuracy: 0.7088\n",
      "Epoch 115/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0136 - accuracy: 0.6394 - val_loss: 0.8643 - val_accuracy: 0.7138\n",
      "Epoch 116/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0191 - accuracy: 0.6364 - val_loss: 0.8581 - val_accuracy: 0.7072\n",
      "Epoch 117/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 1.0183 - accuracy: 0.6414 - val_loss: 0.8517 - val_accuracy: 0.7105\n",
      "Epoch 118/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9951 - accuracy: 0.6489 - val_loss: 0.8463 - val_accuracy: 0.7155\n",
      "Epoch 119/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9829 - accuracy: 0.6635 - val_loss: 0.8403 - val_accuracy: 0.7105\n",
      "Epoch 120/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9799 - accuracy: 0.6572 - val_loss: 0.8346 - val_accuracy: 0.7205\n",
      "Epoch 121/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9828 - accuracy: 0.6572 - val_loss: 0.8294 - val_accuracy: 0.7221\n",
      "Epoch 122/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9427 - accuracy: 0.6718 - val_loss: 0.8242 - val_accuracy: 0.7188\n",
      "Epoch 123/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9578 - accuracy: 0.6693 - val_loss: 0.8187 - val_accuracy: 0.7221\n",
      "Epoch 124/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9335 - accuracy: 0.6735 - val_loss: 0.8133 - val_accuracy: 0.7221\n",
      "Epoch 125/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9420 - accuracy: 0.6626 - val_loss: 0.8078 - val_accuracy: 0.7255\n",
      "Epoch 126/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.9266 - accuracy: 0.6789 - val_loss: 0.8027 - val_accuracy: 0.7271\n",
      "Epoch 127/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9180 - accuracy: 0.6801 - val_loss: 0.7980 - val_accuracy: 0.7321\n",
      "Epoch 128/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.9036 - accuracy: 0.6905 - val_loss: 0.7924 - val_accuracy: 0.7304\n",
      "Epoch 129/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.9016 - accuracy: 0.6872 - val_loss: 0.7882 - val_accuracy: 0.7304\n",
      "Epoch 130/200\n",
      "2404/2404 [==============================] - 5s 2ms/sample - loss: 0.9132 - accuracy: 0.6785 - val_loss: 0.7831 - val_accuracy: 0.7321\n",
      "Epoch 131/200\n",
      "2404/2404 [==============================] - 6s 2ms/sample - loss: 0.8848 - accuracy: 0.6789 - val_loss: 0.7787 - val_accuracy: 0.7338\n",
      "Epoch 132/200\n",
      "2404/2404 [==============================] - 5s 2ms/sample - loss: 0.8943 - accuracy: 0.6855 - val_loss: 0.7735 - val_accuracy: 0.7404\n",
      "Epoch 133/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8952 - accuracy: 0.6851 - val_loss: 0.7688 - val_accuracy: 0.7404\n",
      "Epoch 134/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.8708 - accuracy: 0.7059 - val_loss: 0.7651 - val_accuracy: 0.7421\n",
      "Epoch 135/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8902 - accuracy: 0.6905 - val_loss: 0.7610 - val_accuracy: 0.7421\n",
      "Epoch 136/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8479 - accuracy: 0.7109 - val_loss: 0.7562 - val_accuracy: 0.7421\n",
      "Epoch 137/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8386 - accuracy: 0.6984 - val_loss: 0.7521 - val_accuracy: 0.7438\n",
      "Epoch 138/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8225 - accuracy: 0.7134 - val_loss: 0.7474 - val_accuracy: 0.7438\n",
      "Epoch 139/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8317 - accuracy: 0.7126 - val_loss: 0.7444 - val_accuracy: 0.7504\n",
      "Epoch 140/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8095 - accuracy: 0.7271 - val_loss: 0.7394 - val_accuracy: 0.7537\n",
      "Epoch 141/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.8264 - accuracy: 0.7063 - val_loss: 0.7362 - val_accuracy: 0.7521\n",
      "Epoch 142/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8162 - accuracy: 0.7092 - val_loss: 0.7320 - val_accuracy: 0.7521\n",
      "Epoch 143/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7827 - accuracy: 0.7363 - val_loss: 0.7268 - val_accuracy: 0.7537\n",
      "Epoch 144/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.8071 - accuracy: 0.7159 - val_loss: 0.7230 - val_accuracy: 0.7571\n",
      "Epoch 145/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7995 - accuracy: 0.7246 - val_loss: 0.7197 - val_accuracy: 0.7604\n",
      "Epoch 146/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7890 - accuracy: 0.7313 - val_loss: 0.7151 - val_accuracy: 0.7604\n",
      "Epoch 147/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7784 - accuracy: 0.7280 - val_loss: 0.7126 - val_accuracy: 0.7587\n",
      "Epoch 148/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7694 - accuracy: 0.7292 - val_loss: 0.7072 - val_accuracy: 0.7604\n",
      "Epoch 149/200\n",
      "2404/2404 [==============================] - 4s 2ms/sample - loss: 0.7898 - accuracy: 0.7205 - val_loss: 0.7032 - val_accuracy: 0.7671\n",
      "Epoch 150/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7562 - accuracy: 0.7384 - val_loss: 0.6987 - val_accuracy: 0.7671\n",
      "Epoch 151/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7502 - accuracy: 0.7492 - val_loss: 0.6950 - val_accuracy: 0.7671\n",
      "Epoch 152/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7473 - accuracy: 0.7425 - val_loss: 0.6939 - val_accuracy: 0.7671\n",
      "Epoch 153/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7408 - accuracy: 0.7479 - val_loss: 0.6899 - val_accuracy: 0.7671\n",
      "Epoch 154/200\n",
      "2404/2404 [==============================] - 4s 1ms/sample - loss: 0.7367 - accuracy: 0.7396 - val_loss: 0.6856 - val_accuracy: 0.7687\n",
      "Epoch 155/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7326 - accuracy: 0.7483 - val_loss: 0.6818 - val_accuracy: 0.7687\n",
      "Epoch 156/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7298 - accuracy: 0.7354 - val_loss: 0.6786 - val_accuracy: 0.7704\n",
      "Epoch 157/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7277 - accuracy: 0.7492 - val_loss: 0.6754 - val_accuracy: 0.7737\n",
      "Epoch 158/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7273 - accuracy: 0.7504 - val_loss: 0.6720 - val_accuracy: 0.7737\n",
      "Epoch 159/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7100 - accuracy: 0.7558 - val_loss: 0.6681 - val_accuracy: 0.7720\n",
      "Epoch 160/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7000 - accuracy: 0.7596 - val_loss: 0.6652 - val_accuracy: 0.7754\n",
      "Epoch 161/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.7029 - accuracy: 0.7600 - val_loss: 0.6616 - val_accuracy: 0.7820\n",
      "Epoch 162/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6819 - accuracy: 0.7696 - val_loss: 0.6594 - val_accuracy: 0.7837\n",
      "Epoch 163/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6757 - accuracy: 0.7708 - val_loss: 0.6556 - val_accuracy: 0.7770\n",
      "Epoch 164/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6914 - accuracy: 0.7671 - val_loss: 0.6540 - val_accuracy: 0.7720\n",
      "Epoch 165/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6678 - accuracy: 0.7716 - val_loss: 0.6510 - val_accuracy: 0.7770\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6676 - accuracy: 0.7704 - val_loss: 0.6473 - val_accuracy: 0.7754\n",
      "Epoch 167/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6784 - accuracy: 0.7646 - val_loss: 0.6439 - val_accuracy: 0.7787\n",
      "Epoch 168/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6484 - accuracy: 0.7870 - val_loss: 0.6414 - val_accuracy: 0.7787\n",
      "Epoch 169/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6609 - accuracy: 0.7779 - val_loss: 0.6396 - val_accuracy: 0.7770\n",
      "Epoch 170/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6483 - accuracy: 0.7762 - val_loss: 0.6340 - val_accuracy: 0.7937\n",
      "Epoch 171/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6474 - accuracy: 0.7750 - val_loss: 0.6300 - val_accuracy: 0.7920\n",
      "Epoch 172/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6238 - accuracy: 0.7845 - val_loss: 0.6292 - val_accuracy: 0.7903\n",
      "Epoch 173/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6422 - accuracy: 0.7779 - val_loss: 0.6257 - val_accuracy: 0.7920\n",
      "Epoch 174/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6308 - accuracy: 0.7928 - val_loss: 0.6232 - val_accuracy: 0.7937\n",
      "Epoch 175/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6206 - accuracy: 0.7874 - val_loss: 0.6197 - val_accuracy: 0.7903\n",
      "Epoch 176/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6111 - accuracy: 0.7862 - val_loss: 0.6169 - val_accuracy: 0.7953\n",
      "Epoch 177/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6163 - accuracy: 0.7887 - val_loss: 0.6123 - val_accuracy: 0.7970\n",
      "Epoch 178/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6164 - accuracy: 0.7829 - val_loss: 0.6094 - val_accuracy: 0.7987\n",
      "Epoch 179/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.6089 - accuracy: 0.8028 - val_loss: 0.6088 - val_accuracy: 0.7987\n",
      "Epoch 180/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5954 - accuracy: 0.7970 - val_loss: 0.6057 - val_accuracy: 0.7987\n",
      "Epoch 181/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5919 - accuracy: 0.7978 - val_loss: 0.6041 - val_accuracy: 0.7987\n",
      "Epoch 182/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5930 - accuracy: 0.7928 - val_loss: 0.5999 - val_accuracy: 0.8020\n",
      "Epoch 183/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5821 - accuracy: 0.7941 - val_loss: 0.5958 - val_accuracy: 0.8053\n",
      "Epoch 184/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5812 - accuracy: 0.7999 - val_loss: 0.5941 - val_accuracy: 0.8070\n",
      "Epoch 185/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5660 - accuracy: 0.8082 - val_loss: 0.5920 - val_accuracy: 0.8070\n",
      "Epoch 186/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5668 - accuracy: 0.8153 - val_loss: 0.5900 - val_accuracy: 0.8070\n",
      "Epoch 187/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5681 - accuracy: 0.8091 - val_loss: 0.5868 - val_accuracy: 0.8020\n",
      "Epoch 188/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5727 - accuracy: 0.8128 - val_loss: 0.5832 - val_accuracy: 0.8087\n",
      "Epoch 189/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5552 - accuracy: 0.8007 - val_loss: 0.5819 - val_accuracy: 0.8070\n",
      "Epoch 190/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5360 - accuracy: 0.8232 - val_loss: 0.5792 - val_accuracy: 0.8053\n",
      "Epoch 191/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5455 - accuracy: 0.8141 - val_loss: 0.5777 - val_accuracy: 0.8070\n",
      "Epoch 192/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5421 - accuracy: 0.8236 - val_loss: 0.5743 - val_accuracy: 0.8120\n",
      "Epoch 193/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5575 - accuracy: 0.8099 - val_loss: 0.5710 - val_accuracy: 0.8103\n",
      "Epoch 194/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5319 - accuracy: 0.8195 - val_loss: 0.5682 - val_accuracy: 0.8136\n",
      "Epoch 195/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5331 - accuracy: 0.8303 - val_loss: 0.5662 - val_accuracy: 0.8120\n",
      "Epoch 196/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5365 - accuracy: 0.8132 - val_loss: 0.5645 - val_accuracy: 0.8103\n",
      "Epoch 197/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5235 - accuracy: 0.8261 - val_loss: 0.5628 - val_accuracy: 0.8087\n",
      "Epoch 198/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5246 - accuracy: 0.8274 - val_loss: 0.5606 - val_accuracy: 0.8153\n",
      "Epoch 199/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5192 - accuracy: 0.8307 - val_loss: 0.5585 - val_accuracy: 0.8136\n",
      "Epoch 200/200\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 0.5332 - accuracy: 0.8257 - val_loss: 0.5558 - val_accuracy: 0.8120\n",
      "Wall time: 11min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200,  batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da2b362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbb022d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 89.97504159733776\n",
      "Validation: 81.19800332778702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "yhat = model.predict(X_train)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_train_actual = np.argmax(y_train, axis=1)\n",
    "print('Train:', accuracy_score(y_train_actual, yhat)*100)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_test_actual = np.argmax(y_test, axis=1)\n",
    "print('Validation:', accuracy_score(y_test_actual, yhat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9431b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cfa6b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12.8,4.8))\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "folds = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "y_actual = np.argmax(y, axis=1)\n",
    "for index, (train_indices, val_indices) in enumerate(folds.split(X, y_actual)):\n",
    "    model = get_combined_model()\n",
    "    # TODO: move this to the model def.\n",
    "    model.compile(optimizer=Adam(learning_rate=0.000001, beta_1=0.99, beta_2=0.999),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X[train_indices], y[train_indices],\n",
    "                        validation_data=(X[val_indices], y[val_indices]),\n",
    "                        epochs=175,  batch_size=10, verbose=False)\n",
    "    yhat = model.predict(X[train_indices])\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    y_train_actual = np.argmax(y[train_indices], axis=1)\n",
    "    print(f\"Fold {index}\")\n",
    "    print('Train:', accuracy_score(y_train_actual, yhat)*100)\n",
    "\n",
    "    yhat = model.predict(X[val_indices])\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    y_test_actual = np.argmax(y[val_indices], axis=1)\n",
    "    print('Validation:', accuracy_score(y_test_actual, yhat)*100)\n",
    "    \n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6661c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.90521680312774"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Change this to be saved from above.\n",
    "\n",
    "vals = np.array([77.3635153129161, 74.30093209054593, 79.22769640479362, 76.72872340425532])\n",
    "np.mean(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07f4e4",
   "metadata": {},
   "source": [
    "# Lets play with making a multi modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "625edad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acw_X_0', 'acw_Y_0', 'acw_Z_0', 'acw_X_1', 'acw_Y_1', 'acw_Z_1',\n",
       "       'acw_X_2', 'acw_Y_2', 'acw_Z_2', 'acw_X_3',\n",
       "       ...\n",
       "       'act_X_297', 'act_Y_297', 'act_Z_297', 'act_X_298', 'act_Y_298',\n",
       "       'act_Z_298', 'act_X_299', 'act_Y_299', 'act_Z_299', 'action'],\n",
       "      dtype='object', length=33481)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d9ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23040"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 300 different x,y,z's for each acc\n",
    "\n",
    "#wrist data\n",
    "acw_X_cols_batched = []\n",
    "for j in range(0, samples100):\n",
    "    acw_X_cols_batched += [f\"acw_{val}_{j}\" for val in acw_X_cols]\n",
    "X_acw_batched = df_batched[acw_X_cols_batched].to_numpy()\n",
    "\n",
    "# thigh data\n",
    "act_X_cols_batched = []\n",
    "for j in range(0, samples100):\n",
    "    act_X_cols_batched += [f\"act_{val}_{j}\" for val in acw_X_cols]\n",
    "X_act_batched = df_batched[acw_X_cols_batched].to_numpy()\n",
    "\n",
    "# Depth Camera data\n",
    "dc_X_cols_batched = []\n",
    "for j in range(0, samples15):\n",
    "    dc_X_cols_batched += [f\"dc_{val}_{j}\" for val in dc_X_cols]\n",
    "X_dc_batched = df_batched[dc_X_cols_batched].to_numpy()\n",
    "    \n",
    "# Pressure Mat data\n",
    "pm_X_cols_batched = []\n",
    "for j in range(0, samples15):\n",
    "    pm_X_cols_batched += [f\"pm_{val}_{j}\" for val in pm_X_cols]\n",
    "X_pm_batched = df_batched[pm_X_cols_batched].to_numpy()\n",
    "len(pm_X_cols_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05b7d2",
   "metadata": {},
   "source": [
    "## split for tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cee7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2404, 900)\n",
      "(601, 900)\n",
      "(2404, 900)\n",
      "(601, 900)\n",
      "(2404, 8640)\n",
      "(601, 8640)\n",
      "(2404, 23040)\n",
      "(601, 23040)\n",
      "(2404, 8)\n",
      "(601, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "X_act_batched_train, X_act_batched_test, \\\n",
    "X_acw_batched_train, X_acw_batched_test, \\\n",
    "X_dc_batched_train, X_dc_batched_test, \\\n",
    "X_pm_batched_train, X_pm_batched_test, \\\n",
    "y_train, y_test = \\\n",
    "train_test_split(X_act_batched, X_acw_batched, X_dc_batched, X_pm_batched, y, \n",
    "                 test_size=0.2, shuffle=True)\n",
    "\n",
    "print(X_act_batched_train.shape)\n",
    "print(X_act_batched_test.shape)\n",
    "print(X_acw_batched_train.shape)\n",
    "print(X_acw_batched_test.shape)\n",
    "print(X_dc_batched_train.shape)\n",
    "print(X_dc_batched_test.shape)\n",
    "print(X_pm_batched_train.shape)\n",
    "print(X_pm_batched_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2264f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=6, skip=0, step=1):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row *2))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[(i * step) + skip],cmap='bone')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913072f",
   "metadata": {},
   "source": [
    "### Reshape the pressure mat back into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63a51b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2404, 45, 32, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 734.4x331.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_pm_batched_train.shape)\n",
    "X_pm_batched_train = X_pm_batched_train.reshape(X_pm_batched_train.shape[0],45,32,16)\n",
    "X_pm_batched_test = X_pm_batched_test.reshape(X_pm_batched_test.shape[0],45,32,16)\n",
    "\n",
    "plot_gallery(X_pm_batched_test[16], [1,2,3],32,16,1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994b241",
   "metadata": {},
   "source": [
    "### Reshape the depth camera back into images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7b134ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2404, 45, 32, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 734.4x331.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_pm_batched_train.shape)\n",
    "X_dc_batched_train = X_dc_batched_train.reshape(X_dc_batched_train.shape[0],45,12,16)\n",
    "X_dc_batched_test = X_dc_batched_test.reshape(X_dc_batched_test.shape[0],45,12,16)\n",
    "\n",
    "plot_gallery(X_dc_batched_test[16], [1,2,3],16,12,1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b031d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c29b8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "input_thigh = Input(shape=(X_act_batched.shape[1],))\n",
    "input_wrist = Input(shape=(X_acw_batched.shape[1],))\n",
    "input_dc = Input(shape=(X_dc_batched_train.shape[1],\n",
    "                        X_dc_batched_train.shape[2],\n",
    "                        X_dc_batched_train.shape[3],))\n",
    "input_pm = Input(shape=(X_pm_batched_train.shape[1],\n",
    "                        X_pm_batched_train.shape[2],\n",
    "                        X_pm_batched_train.shape[3],))\n",
    "\n",
    "# Build some layers for the thigh\n",
    "thigh = Dense(1024, activation=\"sigmoid\")(input_thigh)\n",
    "thigh = Dense(512, activation=\"sigmoid\")(thigh)\n",
    "thigh = Dropout(0.1)(thigh)\n",
    "thigh = Dense(256)(thigh)\n",
    "thigh = Dense(128)(thigh)\n",
    "thigh = Dropout(0.1)(thigh)\n",
    "thigh = Dense(128)(thigh)\n",
    "thigh = Model(inputs=input_thigh, outputs=thigh)\n",
    "\n",
    "# Build some layers for the wrist\n",
    "wrist = Dense(1024, activation=\"sigmoid\")(input_wrist)\n",
    "wrist = Dense(512, activation=\"sigmoid\")(wrist)\n",
    "wrist = Dropout(0.1)(wrist)\n",
    "wrist = Dense(256)(wrist)\n",
    "wrist = Dense(128)(wrist)\n",
    "wrist = Dropout(0.1)(wrist)\n",
    "wrist = Dense(128)(wrist)\n",
    "wrist = Model(inputs=input_wrist, outputs=wrist)\n",
    "\n",
    "# Build some layers for the depth camera\n",
    "# but this time we will use conv2D\n",
    "dc_tens = Conv2D(filters=filt_layers[0], \n",
    "                            kernel_size=(3,3), \n",
    "                            padding='same', \n",
    "                            activation='relu',\n",
    "                            data_format=\"channels_first\",\n",
    "                            input_shape=(X_dc_batched_train.shape[1],\n",
    "                                         X_dc_batched_train.shape[2],\n",
    "                                         X_dc_batched_train.shape[3]))(input_dc)\n",
    "dc_tens = Dropout(0.1) (dc_tens)\n",
    "dc_tens = Conv2D(filters=filt_layers[1], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(dc_tens)\n",
    "dc_tens = Dropout(0.1) (dc_tens)\n",
    "\n",
    "dc_tens = Conv2D(filters=filt_layers[2], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(dc_tens)\n",
    "dc_tens = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")(dc_tens)\n",
    "dc_tens = Dropout(0.1) (dc_tens)\n",
    "dc_tens = Flatten()(dc_tens)\n",
    "dc_tens = Dense(512)(dc_tens)\n",
    "dc_tens = Dropout(0.1) (dc_tens)\n",
    "dc_tens = Model(inputs=input_dc, outputs=dc_tens)\n",
    "\n",
    "\n",
    "# Build some layers for the pressure mat\n",
    "filt_layers = [64, 32, 16]\n",
    "pm_tens = Conv2D(filters=filt_layers[0], \n",
    "                            kernel_size=(3,3), \n",
    "                            padding='same', \n",
    "                            activation='relu',\n",
    "                            data_format=\"channels_first\",\n",
    "                            input_shape=(X_pm_batched_train.shape[1],\n",
    "                                         X_pm_batched_train.shape[2],\n",
    "                                         X_pm_batched_train.shape[3]))(input_pm)\n",
    "pm_tens = Dropout(0.1) (pm_tens)\n",
    "pm_tens = Conv2D(filters=filt_layers[1], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(pm_tens)\n",
    "pm_tens = Dropout(0.1) (pm_tens)\n",
    "\n",
    "pm_tens = Conv2D(filters=filt_layers[2], \n",
    "                        kernel_size=(3,3), \n",
    "                        padding='same', \n",
    "                        activation='relu',\n",
    "                        data_format=\"channels_first\")(pm_tens)\n",
    "pm_tens = MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")(pm_tens)\n",
    "pm_tens = Dropout(0.1) (pm_tens)\n",
    "pm_tens = Flatten()(pm_tens)\n",
    "pm_tens = Dense(512)(pm_tens)\n",
    "pm_tens = Dropout(0.2) (pm_tens)\n",
    "pm_tens = Model(inputs=input_pm, outputs=pm_tens)\n",
    "\n",
    "\n",
    "combined = concatenate([thigh.output, wrist.output, dc_tens.output, pm_tens.output])\n",
    "\n",
    "# Now lets run some more dense layers\n",
    "last = Dense(128, activation=\"tanh\")(combined)\n",
    "last = Dropout(0.3)(last)\n",
    "last = Dense(64, activation=\"tanh\")(combined)\n",
    "prediction = Dense(units=8, activation='softmax')(last)\n",
    "\n",
    "model = Model(inputs=[thigh.input, wrist.input, dc_tens.input, pm_tens.input], outputs=prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "752fe86d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_129\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_136 (InputLayer)          [(None, 45, 12, 16)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_137 (InputLayer)          [(None, 45, 32, 16)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 64, 12, 16)   25984       input_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 64, 32, 16)   25984       input_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 64, 12, 16)   0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 64, 32, 16)   0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_134 (InputLayer)          [(None, 900)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_135 (InputLayer)          [(None, 900)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 12, 16)   18464       dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 32, 32, 16)   18464       dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_345 (Dense)               (None, 1024)         922624      input_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_350 (Dense)               (None, 1024)         922624      input_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 32, 12, 16)   0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)           (None, 32, 32, 16)   0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_346 (Dense)               (None, 512)          524800      dense_345[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_351 (Dense)               (None, 512)          524800      dense_350[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 12, 16)   4624        dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 32, 16)   4624        dropout_179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 512)          0           dense_346[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 512)          0           dense_351[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 16, 6, 8)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 16, 16, 8)    0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_347 (Dense)               (None, 256)          131328      dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_352 (Dense)               (None, 256)          131328      dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 16, 6, 8)     0           max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_180 (Dropout)           (None, 16, 16, 8)    0           max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_348 (Dense)               (None, 128)          32896       dense_347[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_353 (Dense)               (None, 128)          32896       dense_352[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 768)          0           dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 2048)         0           dropout_180[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 128)          0           dense_348[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 128)          0           dense_353[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_355 (Dense)               (None, 512)          393728      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_356 (Dense)               (None, 512)          1049088     flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_349 (Dense)               (None, 128)          16512       dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_354 (Dense)               (None, 128)          16512       dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 512)          0           dense_355[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_181 (Dropout)           (None, 512)          0           dense_356[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 1280)         0           dense_349[0][0]                  \n",
      "                                                                 dense_354[0][0]                  \n",
      "                                                                 dropout_177[0][0]                \n",
      "                                                                 dropout_181[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_358 (Dense)               (None, 64)           81984       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_359 (Dense)               (None, 8)            520         dense_358[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,879,784\n",
      "Trainable params: 4,879,784\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4740ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601, 45, 32, 16)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pm_batched_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6a2ede5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2404 samples, validate on 601 samples\n",
      "Epoch 1/300\n",
      "2404/2404 [==============================] - 3s 1ms/sample - loss: 2.4883 - accuracy: 0.1701 - val_loss: 2.0707 - val_accuracy: 0.2596\n",
      "Epoch 2/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 2.0717 - accuracy: 0.2733 - val_loss: 1.7427 - val_accuracy: 0.3710\n",
      "Epoch 3/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 1.8534 - accuracy: 0.3270 - val_loss: 1.5880 - val_accuracy: 0.4110\n",
      "Epoch 4/300\n",
      "2404/2404 [==============================] - 2s 729us/sample - loss: 1.7017 - accuracy: 0.3831 - val_loss: 1.4321 - val_accuracy: 0.4559\n",
      "Epoch 5/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 1.5640 - accuracy: 0.4418 - val_loss: 1.3228 - val_accuracy: 0.5258\n",
      "Epoch 6/300\n",
      "2404/2404 [==============================] - 2s 720us/sample - loss: 1.4724 - accuracy: 0.4563 - val_loss: 1.2642 - val_accuracy: 0.5391\n",
      "Epoch 7/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 1.3957 - accuracy: 0.4867 - val_loss: 1.2180 - val_accuracy: 0.5774\n",
      "Epoch 8/300\n",
      "2404/2404 [==============================] - 2s 726us/sample - loss: 1.3328 - accuracy: 0.5187 - val_loss: 1.1440 - val_accuracy: 0.6190\n",
      "Epoch 9/300\n",
      "2404/2404 [==============================] - 2s 722us/sample - loss: 1.2849 - accuracy: 0.5258 - val_loss: 1.1004 - val_accuracy: 0.6123\n",
      "Epoch 10/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 1.2223 - accuracy: 0.5624 - val_loss: 1.0272 - val_accuracy: 0.6589\n",
      "Epoch 11/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 1.1869 - accuracy: 0.5778 - val_loss: 1.0142 - val_accuracy: 0.6140\n",
      "Epoch 12/300\n",
      "2404/2404 [==============================] - 2s 722us/sample - loss: 1.1481 - accuracy: 0.5786 - val_loss: 0.9599 - val_accuracy: 0.6522\n",
      "Epoch 13/300\n",
      "2404/2404 [==============================] - 2s 752us/sample - loss: 1.1082 - accuracy: 0.5982 - val_loss: 0.9279 - val_accuracy: 0.6772\n",
      "Epoch 14/300\n",
      "2404/2404 [==============================] - 2s 790us/sample - loss: 1.0633 - accuracy: 0.6231 - val_loss: 0.8858 - val_accuracy: 0.7005\n",
      "Epoch 15/300\n",
      "2404/2404 [==============================] - 2s 797us/sample - loss: 1.0506 - accuracy: 0.6394 - val_loss: 0.8949 - val_accuracy: 0.6855\n",
      "Epoch 16/300\n",
      "2404/2404 [==============================] - 2s 781us/sample - loss: 1.0254 - accuracy: 0.6448 - val_loss: 0.8706 - val_accuracy: 0.7038\n",
      "Epoch 17/300\n",
      "2404/2404 [==============================] - 2s 787us/sample - loss: 1.0077 - accuracy: 0.6514 - val_loss: 0.8327 - val_accuracy: 0.7221\n",
      "Epoch 18/300\n",
      "2404/2404 [==============================] - 2s 783us/sample - loss: 0.9920 - accuracy: 0.6427 - val_loss: 0.8109 - val_accuracy: 0.7238\n",
      "Epoch 19/300\n",
      "2404/2404 [==============================] - 2s 788us/sample - loss: 0.9650 - accuracy: 0.6681 - val_loss: 0.7902 - val_accuracy: 0.7438\n",
      "Epoch 20/300\n",
      "2404/2404 [==============================] - 2s 803us/sample - loss: 0.9437 - accuracy: 0.6681 - val_loss: 0.7644 - val_accuracy: 0.7571\n",
      "Epoch 21/300\n",
      "2404/2404 [==============================] - 2s 782us/sample - loss: 0.9182 - accuracy: 0.6847 - val_loss: 0.7539 - val_accuracy: 0.7471\n",
      "Epoch 22/300\n",
      "2404/2404 [==============================] - 2s 786us/sample - loss: 0.9171 - accuracy: 0.6855 - val_loss: 0.7439 - val_accuracy: 0.7770\n",
      "Epoch 23/300\n",
      "2404/2404 [==============================] - 2s 765us/sample - loss: 0.8725 - accuracy: 0.7013 - val_loss: 0.7326 - val_accuracy: 0.7637\n",
      "Epoch 24/300\n",
      "2404/2404 [==============================] - 2s 754us/sample - loss: 0.8721 - accuracy: 0.6988 - val_loss: 0.7414 - val_accuracy: 0.7554\n",
      "Epoch 25/300\n",
      "2404/2404 [==============================] - 2s 800us/sample - loss: 0.8446 - accuracy: 0.7184 - val_loss: 0.7280 - val_accuracy: 0.7671\n",
      "Epoch 26/300\n",
      "2404/2404 [==============================] - 2s 803us/sample - loss: 0.8477 - accuracy: 0.7146 - val_loss: 0.7197 - val_accuracy: 0.7637\n",
      "Epoch 27/300\n",
      "2404/2404 [==============================] - 2s 823us/sample - loss: 0.8382 - accuracy: 0.7146 - val_loss: 0.7332 - val_accuracy: 0.7621\n",
      "Epoch 28/300\n",
      "2404/2404 [==============================] - 2s 807us/sample - loss: 0.8438 - accuracy: 0.7092 - val_loss: 0.7112 - val_accuracy: 0.7637\n",
      "Epoch 29/300\n",
      "2404/2404 [==============================] - 2s 798us/sample - loss: 0.8087 - accuracy: 0.7271 - val_loss: 0.6955 - val_accuracy: 0.7687\n",
      "Epoch 30/300\n",
      "2404/2404 [==============================] - 2s 786us/sample - loss: 0.8013 - accuracy: 0.7230 - val_loss: 0.7002 - val_accuracy: 0.7770\n",
      "Epoch 31/300\n",
      "2404/2404 [==============================] - 2s 793us/sample - loss: 0.7886 - accuracy: 0.7242 - val_loss: 0.6774 - val_accuracy: 0.7820\n",
      "Epoch 32/300\n",
      "2404/2404 [==============================] - 2s 807us/sample - loss: 0.7941 - accuracy: 0.7379 - val_loss: 0.6595 - val_accuracy: 0.7837\n",
      "Epoch 33/300\n",
      "2404/2404 [==============================] - 2s 797us/sample - loss: 0.7745 - accuracy: 0.7317 - val_loss: 0.6468 - val_accuracy: 0.7887\n",
      "Epoch 34/300\n",
      "2404/2404 [==============================] - 2s 725us/sample - loss: 0.7407 - accuracy: 0.7467 - val_loss: 0.6500 - val_accuracy: 0.7887\n",
      "Epoch 35/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.7434 - accuracy: 0.7404 - val_loss: 0.6488 - val_accuracy: 0.7820\n",
      "Epoch 36/300\n",
      "2404/2404 [==============================] - 2s 723us/sample - loss: 0.7377 - accuracy: 0.7421 - val_loss: 0.6156 - val_accuracy: 0.8053\n",
      "Epoch 37/300\n",
      "2404/2404 [==============================] - 2s 719us/sample - loss: 0.7172 - accuracy: 0.7533 - val_loss: 0.6228 - val_accuracy: 0.8020\n",
      "Epoch 38/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.7182 - accuracy: 0.7550 - val_loss: 0.6337 - val_accuracy: 0.7770\n",
      "Epoch 39/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.6910 - accuracy: 0.7654 - val_loss: 0.6160 - val_accuracy: 0.7770\n",
      "Epoch 40/300\n",
      "2404/2404 [==============================] - 2s 769us/sample - loss: 0.6879 - accuracy: 0.7675 - val_loss: 0.6185 - val_accuracy: 0.7820\n",
      "Epoch 41/300\n",
      "2404/2404 [==============================] - 2s 751us/sample - loss: 0.6938 - accuracy: 0.7654 - val_loss: 0.6183 - val_accuracy: 0.7837\n",
      "Epoch 42/300\n",
      "2404/2404 [==============================] - 2s 729us/sample - loss: 0.6973 - accuracy: 0.7608 - val_loss: 0.5916 - val_accuracy: 0.8003\n",
      "Epoch 43/300\n",
      "2404/2404 [==============================] - 2s 725us/sample - loss: 0.6816 - accuracy: 0.7716 - val_loss: 0.5859 - val_accuracy: 0.8003\n",
      "Epoch 44/300\n",
      "2404/2404 [==============================] - 2s 733us/sample - loss: 0.6554 - accuracy: 0.7791 - val_loss: 0.5898 - val_accuracy: 0.7854\n",
      "Epoch 45/300\n",
      "2404/2404 [==============================] - 2s 730us/sample - loss: 0.6534 - accuracy: 0.7770 - val_loss: 0.5823 - val_accuracy: 0.7804\n",
      "Epoch 46/300\n",
      "2404/2404 [==============================] - 2s 741us/sample - loss: 0.6717 - accuracy: 0.7691 - val_loss: 0.5767 - val_accuracy: 0.7870\n",
      "Epoch 47/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.6360 - accuracy: 0.7903 - val_loss: 0.5713 - val_accuracy: 0.8003\n",
      "Epoch 48/300\n",
      "2404/2404 [==============================] - 2s 718us/sample - loss: 0.6488 - accuracy: 0.7750 - val_loss: 0.5759 - val_accuracy: 0.7870\n",
      "Epoch 49/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.6521 - accuracy: 0.7829 - val_loss: 0.5630 - val_accuracy: 0.8020\n",
      "Epoch 50/300\n",
      "2404/2404 [==============================] - 2s 726us/sample - loss: 0.6449 - accuracy: 0.7845 - val_loss: 0.5602 - val_accuracy: 0.8037\n",
      "Epoch 51/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.6099 - accuracy: 0.7970 - val_loss: 0.5531 - val_accuracy: 0.8020\n",
      "Epoch 52/300\n",
      "2404/2404 [==============================] - 2s 719us/sample - loss: 0.6158 - accuracy: 0.7941 - val_loss: 0.5498 - val_accuracy: 0.8120\n",
      "Epoch 53/300\n",
      "2404/2404 [==============================] - 2s 723us/sample - loss: 0.6134 - accuracy: 0.7924 - val_loss: 0.5303 - val_accuracy: 0.8136\n",
      "Epoch 54/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.6094 - accuracy: 0.8003 - val_loss: 0.5548 - val_accuracy: 0.8003\n",
      "Epoch 55/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.6041 - accuracy: 0.7908 - val_loss: 0.5427 - val_accuracy: 0.8053\n",
      "Epoch 56/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.5950 - accuracy: 0.7891 - val_loss: 0.5330 - val_accuracy: 0.8186\n",
      "Epoch 57/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.5761 - accuracy: 0.8145 - val_loss: 0.5293 - val_accuracy: 0.8170\n",
      "Epoch 58/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.5792 - accuracy: 0.8070 - val_loss: 0.5164 - val_accuracy: 0.8186\n",
      "Epoch 59/300\n",
      "2404/2404 [==============================] - 2s 723us/sample - loss: 0.5624 - accuracy: 0.8116 - val_loss: 0.4980 - val_accuracy: 0.8136\n",
      "Epoch 60/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.5702 - accuracy: 0.8120 - val_loss: 0.4928 - val_accuracy: 0.8087\n",
      "Epoch 61/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.5615 - accuracy: 0.8070 - val_loss: 0.4859 - val_accuracy: 0.8236\n",
      "Epoch 62/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.5614 - accuracy: 0.8103 - val_loss: 0.4964 - val_accuracy: 0.8286\n",
      "Epoch 63/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.5464 - accuracy: 0.8186 - val_loss: 0.4892 - val_accuracy: 0.8170\n",
      "Epoch 64/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.5600 - accuracy: 0.8141 - val_loss: 0.4891 - val_accuracy: 0.8253\n",
      "Epoch 65/300\n",
      "2404/2404 [==============================] - 2s 721us/sample - loss: 0.5490 - accuracy: 0.8074 - val_loss: 0.4901 - val_accuracy: 0.8186\n",
      "Epoch 66/300\n",
      "2404/2404 [==============================] - 2s 719us/sample - loss: 0.5288 - accuracy: 0.8315 - val_loss: 0.4849 - val_accuracy: 0.8236\n",
      "Epoch 67/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.5404 - accuracy: 0.8232 - val_loss: 0.4862 - val_accuracy: 0.8286\n",
      "Epoch 68/300\n",
      "2404/2404 [==============================] - 2s 725us/sample - loss: 0.5225 - accuracy: 0.8353 - val_loss: 0.4767 - val_accuracy: 0.8353\n",
      "Epoch 69/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.5171 - accuracy: 0.8245 - val_loss: 0.4671 - val_accuracy: 0.8386\n",
      "Epoch 70/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.5246 - accuracy: 0.8278 - val_loss: 0.4728 - val_accuracy: 0.8253\n",
      "Epoch 71/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.5122 - accuracy: 0.8361 - val_loss: 0.4866 - val_accuracy: 0.8336\n",
      "Epoch 72/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.5091 - accuracy: 0.8361 - val_loss: 0.4846 - val_accuracy: 0.8353\n",
      "Epoch 73/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.5106 - accuracy: 0.8286 - val_loss: 0.4699 - val_accuracy: 0.8403\n",
      "Epoch 74/300\n",
      "2404/2404 [==============================] - 2s 724us/sample - loss: 0.4978 - accuracy: 0.8457 - val_loss: 0.4501 - val_accuracy: 0.8519\n",
      "Epoch 75/300\n",
      "2404/2404 [==============================] - 2s 722us/sample - loss: 0.5084 - accuracy: 0.8336 - val_loss: 0.4530 - val_accuracy: 0.8386\n",
      "Epoch 76/300\n",
      "2404/2404 [==============================] - 2s 723us/sample - loss: 0.4949 - accuracy: 0.8428 - val_loss: 0.4520 - val_accuracy: 0.8469\n",
      "Epoch 77/300\n",
      "2404/2404 [==============================] - 2s 739us/sample - loss: 0.4948 - accuracy: 0.8324 - val_loss: 0.4388 - val_accuracy: 0.8436\n",
      "Epoch 78/300\n",
      "2404/2404 [==============================] - 2s 718us/sample - loss: 0.4894 - accuracy: 0.8407 - val_loss: 0.4270 - val_accuracy: 0.8502\n",
      "Epoch 79/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.4839 - accuracy: 0.8399 - val_loss: 0.4403 - val_accuracy: 0.8419\n",
      "Epoch 80/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.4748 - accuracy: 0.8436 - val_loss: 0.4481 - val_accuracy: 0.8436\n",
      "Epoch 81/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.4710 - accuracy: 0.8507 - val_loss: 0.4260 - val_accuracy: 0.8453\n",
      "Epoch 82/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.4774 - accuracy: 0.8369 - val_loss: 0.4257 - val_accuracy: 0.8386\n",
      "Epoch 83/300\n",
      "2404/2404 [==============================] - 2s 725us/sample - loss: 0.4659 - accuracy: 0.8436 - val_loss: 0.4324 - val_accuracy: 0.8369\n",
      "Epoch 84/300\n",
      "2404/2404 [==============================] - 2s 724us/sample - loss: 0.4524 - accuracy: 0.8511 - val_loss: 0.4281 - val_accuracy: 0.8419\n",
      "Epoch 85/300\n",
      "2404/2404 [==============================] - 2s 782us/sample - loss: 0.4667 - accuracy: 0.8399 - val_loss: 0.4056 - val_accuracy: 0.8569\n",
      "Epoch 86/300\n",
      "2404/2404 [==============================] - 2s 735us/sample - loss: 0.4621 - accuracy: 0.8486 - val_loss: 0.4234 - val_accuracy: 0.8453\n",
      "Epoch 87/300\n",
      "2404/2404 [==============================] - 2s 731us/sample - loss: 0.4499 - accuracy: 0.8498 - val_loss: 0.4177 - val_accuracy: 0.8502\n",
      "Epoch 88/300\n",
      "2404/2404 [==============================] - 2s 731us/sample - loss: 0.4476 - accuracy: 0.8490 - val_loss: 0.4176 - val_accuracy: 0.8403\n",
      "Epoch 89/300\n",
      "2404/2404 [==============================] - 2s 728us/sample - loss: 0.4518 - accuracy: 0.8507 - val_loss: 0.4080 - val_accuracy: 0.8502\n",
      "Epoch 90/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.4425 - accuracy: 0.8527 - val_loss: 0.4131 - val_accuracy: 0.8519\n",
      "Epoch 91/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.4375 - accuracy: 0.8598 - val_loss: 0.3899 - val_accuracy: 0.8552\n",
      "Epoch 92/300\n",
      "2404/2404 [==============================] - 2s 721us/sample - loss: 0.4367 - accuracy: 0.8586 - val_loss: 0.3919 - val_accuracy: 0.8486\n",
      "Epoch 93/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.4346 - accuracy: 0.8594 - val_loss: 0.4051 - val_accuracy: 0.8552\n",
      "Epoch 94/300\n",
      "2404/2404 [==============================] - 2s 728us/sample - loss: 0.4219 - accuracy: 0.8598 - val_loss: 0.4193 - val_accuracy: 0.8486\n",
      "Epoch 95/300\n",
      "2404/2404 [==============================] - 2s 721us/sample - loss: 0.4195 - accuracy: 0.8586 - val_loss: 0.4043 - val_accuracy: 0.8369\n",
      "Epoch 96/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.4303 - accuracy: 0.8573 - val_loss: 0.4005 - val_accuracy: 0.8453\n",
      "Epoch 97/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.4156 - accuracy: 0.8611 - val_loss: 0.3903 - val_accuracy: 0.8586\n",
      "Epoch 98/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.4055 - accuracy: 0.8656 - val_loss: 0.3942 - val_accuracy: 0.8602\n",
      "Epoch 99/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.4031 - accuracy: 0.8686 - val_loss: 0.3865 - val_accuracy: 0.8619\n",
      "Epoch 100/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.3934 - accuracy: 0.8765 - val_loss: 0.3815 - val_accuracy: 0.8652\n",
      "Epoch 101/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.3970 - accuracy: 0.8727 - val_loss: 0.3841 - val_accuracy: 0.8686\n",
      "Epoch 102/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.4041 - accuracy: 0.8648 - val_loss: 0.3719 - val_accuracy: 0.8636\n",
      "Epoch 103/300\n",
      "2404/2404 [==============================] - 2s 725us/sample - loss: 0.4074 - accuracy: 0.8640 - val_loss: 0.3691 - val_accuracy: 0.8686\n",
      "Epoch 104/300\n",
      "2404/2404 [==============================] - 2s 720us/sample - loss: 0.3905 - accuracy: 0.8656 - val_loss: 0.3745 - val_accuracy: 0.8669\n",
      "Epoch 105/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.3840 - accuracy: 0.8773 - val_loss: 0.3715 - val_accuracy: 0.8619\n",
      "Epoch 106/300\n",
      "2404/2404 [==============================] - 2s 731us/sample - loss: 0.3950 - accuracy: 0.8677 - val_loss: 0.3533 - val_accuracy: 0.8719\n",
      "Epoch 107/300\n",
      "2404/2404 [==============================] - 2s 746us/sample - loss: 0.3710 - accuracy: 0.8852 - val_loss: 0.3643 - val_accuracy: 0.8702\n",
      "Epoch 108/300\n",
      "2404/2404 [==============================] - 2s 766us/sample - loss: 0.3724 - accuracy: 0.8814 - val_loss: 0.3493 - val_accuracy: 0.8702\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 2s 721us/sample - loss: 0.3709 - accuracy: 0.8802 - val_loss: 0.3402 - val_accuracy: 0.8702\n",
      "Epoch 110/300\n",
      "2404/2404 [==============================] - 2s 725us/sample - loss: 0.3714 - accuracy: 0.8794 - val_loss: 0.3473 - val_accuracy: 0.8652\n",
      "Epoch 111/300\n",
      "2404/2404 [==============================] - 2s 721us/sample - loss: 0.3698 - accuracy: 0.8790 - val_loss: 0.3451 - val_accuracy: 0.8619\n",
      "Epoch 112/300\n",
      "2404/2404 [==============================] - 2s 722us/sample - loss: 0.3779 - accuracy: 0.8698 - val_loss: 0.3588 - val_accuracy: 0.8453\n",
      "Epoch 113/300\n",
      "2404/2404 [==============================] - 2s 723us/sample - loss: 0.3756 - accuracy: 0.8777 - val_loss: 0.3418 - val_accuracy: 0.8619\n",
      "Epoch 114/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.3590 - accuracy: 0.8810 - val_loss: 0.3405 - val_accuracy: 0.8602\n",
      "Epoch 115/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.3489 - accuracy: 0.8902 - val_loss: 0.3304 - val_accuracy: 0.8636\n",
      "Epoch 116/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.3462 - accuracy: 0.8860 - val_loss: 0.3196 - val_accuracy: 0.8636\n",
      "Epoch 117/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.3454 - accuracy: 0.8873 - val_loss: 0.3217 - val_accuracy: 0.8735\n",
      "Epoch 118/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.3343 - accuracy: 0.8948 - val_loss: 0.3179 - val_accuracy: 0.8735\n",
      "Epoch 119/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.3407 - accuracy: 0.8864 - val_loss: 0.3023 - val_accuracy: 0.8802\n",
      "Epoch 120/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.3391 - accuracy: 0.8923 - val_loss: 0.3031 - val_accuracy: 0.8802\n",
      "Epoch 121/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.3344 - accuracy: 0.8873 - val_loss: 0.3103 - val_accuracy: 0.8702\n",
      "Epoch 122/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.3351 - accuracy: 0.8935 - val_loss: 0.3088 - val_accuracy: 0.8835\n",
      "Epoch 123/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.3198 - accuracy: 0.9022 - val_loss: 0.3056 - val_accuracy: 0.8819\n",
      "Epoch 124/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.3368 - accuracy: 0.8923 - val_loss: 0.3067 - val_accuracy: 0.8819\n",
      "Epoch 125/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.3313 - accuracy: 0.8906 - val_loss: 0.3053 - val_accuracy: 0.8752\n",
      "Epoch 126/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.3176 - accuracy: 0.9010 - val_loss: 0.3023 - val_accuracy: 0.8819\n",
      "Epoch 127/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.3123 - accuracy: 0.9006 - val_loss: 0.3045 - val_accuracy: 0.8835\n",
      "Epoch 128/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.3144 - accuracy: 0.8989 - val_loss: 0.3055 - val_accuracy: 0.8802\n",
      "Epoch 129/300\n",
      "2404/2404 [==============================] - 2s 718us/sample - loss: 0.3120 - accuracy: 0.9031 - val_loss: 0.3008 - val_accuracy: 0.8785\n",
      "Epoch 130/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.3105 - accuracy: 0.8943 - val_loss: 0.3117 - val_accuracy: 0.8819\n",
      "Epoch 131/300\n",
      "2404/2404 [==============================] - 2s 706us/sample - loss: 0.3233 - accuracy: 0.8964 - val_loss: 0.3138 - val_accuracy: 0.8835\n",
      "Epoch 132/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.3038 - accuracy: 0.9039 - val_loss: 0.2893 - val_accuracy: 0.8918\n",
      "Epoch 133/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.3101 - accuracy: 0.8989 - val_loss: 0.2969 - val_accuracy: 0.8885\n",
      "Epoch 134/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.2943 - accuracy: 0.9081 - val_loss: 0.3068 - val_accuracy: 0.8869\n",
      "Epoch 135/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.2961 - accuracy: 0.9143 - val_loss: 0.2814 - val_accuracy: 0.8952\n",
      "Epoch 136/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.3039 - accuracy: 0.9031 - val_loss: 0.2848 - val_accuracy: 0.8918\n",
      "Epoch 137/300\n",
      "2404/2404 [==============================] - 2s 704us/sample - loss: 0.2939 - accuracy: 0.9081 - val_loss: 0.2878 - val_accuracy: 0.8869\n",
      "Epoch 138/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.2833 - accuracy: 0.9131 - val_loss: 0.2677 - val_accuracy: 0.8952\n",
      "Epoch 139/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.2962 - accuracy: 0.9006 - val_loss: 0.2850 - val_accuracy: 0.8935\n",
      "Epoch 140/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2854 - accuracy: 0.9114 - val_loss: 0.2699 - val_accuracy: 0.8952\n",
      "Epoch 141/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.2803 - accuracy: 0.9110 - val_loss: 0.2643 - val_accuracy: 0.9002\n",
      "Epoch 142/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.2990 - accuracy: 0.9043 - val_loss: 0.2552 - val_accuracy: 0.9101\n",
      "Epoch 143/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2945 - accuracy: 0.8927 - val_loss: 0.2463 - val_accuracy: 0.9118\n",
      "Epoch 144/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.2735 - accuracy: 0.9081 - val_loss: 0.2529 - val_accuracy: 0.9068\n",
      "Epoch 145/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2722 - accuracy: 0.9118 - val_loss: 0.2602 - val_accuracy: 0.9002\n",
      "Epoch 146/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.2796 - accuracy: 0.9156 - val_loss: 0.2504 - val_accuracy: 0.8985\n",
      "Epoch 147/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.2706 - accuracy: 0.9110 - val_loss: 0.2562 - val_accuracy: 0.8985\n",
      "Epoch 148/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.2731 - accuracy: 0.9151 - val_loss: 0.2449 - val_accuracy: 0.9101\n",
      "Epoch 149/300\n",
      "2404/2404 [==============================] - 2s 719us/sample - loss: 0.2724 - accuracy: 0.9160 - val_loss: 0.2392 - val_accuracy: 0.9118\n",
      "Epoch 150/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.2527 - accuracy: 0.9243 - val_loss: 0.2475 - val_accuracy: 0.9052\n",
      "Epoch 151/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.2726 - accuracy: 0.9143 - val_loss: 0.2597 - val_accuracy: 0.9068\n",
      "Epoch 152/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.2601 - accuracy: 0.9264 - val_loss: 0.2530 - val_accuracy: 0.9068\n",
      "Epoch 153/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.2662 - accuracy: 0.9181 - val_loss: 0.2595 - val_accuracy: 0.8968\n",
      "Epoch 154/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2545 - accuracy: 0.9181 - val_loss: 0.2569 - val_accuracy: 0.8968\n",
      "Epoch 155/300\n",
      "2404/2404 [==============================] - 2s 718us/sample - loss: 0.2576 - accuracy: 0.9210 - val_loss: 0.2492 - val_accuracy: 0.9101\n",
      "Epoch 156/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2511 - accuracy: 0.9218 - val_loss: 0.2542 - val_accuracy: 0.9101\n",
      "Epoch 157/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.2460 - accuracy: 0.9222 - val_loss: 0.2545 - val_accuracy: 0.8985\n",
      "Epoch 158/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2361 - accuracy: 0.9301 - val_loss: 0.2427 - val_accuracy: 0.9101\n",
      "Epoch 159/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.2487 - accuracy: 0.9218 - val_loss: 0.2500 - val_accuracy: 0.9018\n",
      "Epoch 160/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.2447 - accuracy: 0.9260 - val_loss: 0.2506 - val_accuracy: 0.9085\n",
      "Epoch 161/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.2485 - accuracy: 0.9151 - val_loss: 0.2480 - val_accuracy: 0.9068\n",
      "Epoch 162/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2446 - accuracy: 0.9205 - val_loss: 0.2478 - val_accuracy: 0.9002\n",
      "Epoch 163/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.2418 - accuracy: 0.9222 - val_loss: 0.2433 - val_accuracy: 0.9118\n",
      "Epoch 164/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2439 - accuracy: 0.9239 - val_loss: 0.2391 - val_accuracy: 0.9118\n",
      "Epoch 165/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2360 - accuracy: 0.9214 - val_loss: 0.2540 - val_accuracy: 0.9135\n",
      "Epoch 166/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.2339 - accuracy: 0.9318 - val_loss: 0.2413 - val_accuracy: 0.9185\n",
      "Epoch 167/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.2407 - accuracy: 0.9193 - val_loss: 0.2360 - val_accuracy: 0.9185\n",
      "Epoch 168/300\n",
      "2404/2404 [==============================] - 2s 706us/sample - loss: 0.2391 - accuracy: 0.9280 - val_loss: 0.2340 - val_accuracy: 0.9201\n",
      "Epoch 169/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.2364 - accuracy: 0.9247 - val_loss: 0.2373 - val_accuracy: 0.9168\n",
      "Epoch 170/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.2226 - accuracy: 0.9339 - val_loss: 0.2295 - val_accuracy: 0.9151\n",
      "Epoch 171/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.2257 - accuracy: 0.9326 - val_loss: 0.2339 - val_accuracy: 0.9135\n",
      "Epoch 172/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.2258 - accuracy: 0.9326 - val_loss: 0.2283 - val_accuracy: 0.9118\n",
      "Epoch 173/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2172 - accuracy: 0.9347 - val_loss: 0.2206 - val_accuracy: 0.9185\n",
      "Epoch 174/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.2136 - accuracy: 0.9293 - val_loss: 0.2230 - val_accuracy: 0.9201\n",
      "Epoch 175/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.2195 - accuracy: 0.9264 - val_loss: 0.2167 - val_accuracy: 0.9201\n",
      "Epoch 176/300\n",
      "2404/2404 [==============================] - 2s 735us/sample - loss: 0.2126 - accuracy: 0.9322 - val_loss: 0.2199 - val_accuracy: 0.9201\n",
      "Epoch 177/300\n",
      "2404/2404 [==============================] - 2s 719us/sample - loss: 0.2129 - accuracy: 0.9372 - val_loss: 0.2194 - val_accuracy: 0.9201\n",
      "Epoch 178/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.2116 - accuracy: 0.9409 - val_loss: 0.2228 - val_accuracy: 0.9118\n",
      "Epoch 179/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.2168 - accuracy: 0.9343 - val_loss: 0.2262 - val_accuracy: 0.9101\n",
      "Epoch 180/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.2134 - accuracy: 0.9351 - val_loss: 0.2212 - val_accuracy: 0.9201\n",
      "Epoch 181/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.2124 - accuracy: 0.9330 - val_loss: 0.2133 - val_accuracy: 0.9235\n",
      "Epoch 182/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.2020 - accuracy: 0.9376 - val_loss: 0.2213 - val_accuracy: 0.9168\n",
      "Epoch 183/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.2051 - accuracy: 0.9355 - val_loss: 0.2208 - val_accuracy: 0.9168\n",
      "Epoch 184/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2004 - accuracy: 0.9368 - val_loss: 0.2101 - val_accuracy: 0.9168\n",
      "Epoch 185/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.2013 - accuracy: 0.9355 - val_loss: 0.2193 - val_accuracy: 0.9151\n",
      "Epoch 186/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.2054 - accuracy: 0.9355 - val_loss: 0.2221 - val_accuracy: 0.9118\n",
      "Epoch 187/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.1980 - accuracy: 0.9380 - val_loss: 0.2187 - val_accuracy: 0.9168\n",
      "Epoch 188/300\n",
      "2404/2404 [==============================] - 2s 724us/sample - loss: 0.1975 - accuracy: 0.9426 - val_loss: 0.2162 - val_accuracy: 0.9118\n",
      "Epoch 189/300\n",
      "2404/2404 [==============================] - 2s 720us/sample - loss: 0.1963 - accuracy: 0.9501 - val_loss: 0.2124 - val_accuracy: 0.9118\n",
      "Epoch 190/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.1999 - accuracy: 0.9376 - val_loss: 0.2077 - val_accuracy: 0.9251\n",
      "Epoch 191/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.2010 - accuracy: 0.9405 - val_loss: 0.2167 - val_accuracy: 0.9118\n",
      "Epoch 192/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.1870 - accuracy: 0.9463 - val_loss: 0.2220 - val_accuracy: 0.9052\n",
      "Epoch 193/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.2043 - accuracy: 0.9413 - val_loss: 0.2174 - val_accuracy: 0.9251\n",
      "Epoch 194/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1952 - accuracy: 0.9430 - val_loss: 0.2151 - val_accuracy: 0.9201\n",
      "Epoch 195/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.1940 - accuracy: 0.9393 - val_loss: 0.2160 - val_accuracy: 0.9218\n",
      "Epoch 196/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1869 - accuracy: 0.9443 - val_loss: 0.2002 - val_accuracy: 0.9301\n",
      "Epoch 197/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.1804 - accuracy: 0.9501 - val_loss: 0.2028 - val_accuracy: 0.9351\n",
      "Epoch 198/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.1780 - accuracy: 0.9438 - val_loss: 0.2041 - val_accuracy: 0.9268\n",
      "Epoch 199/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1765 - accuracy: 0.9509 - val_loss: 0.2042 - val_accuracy: 0.9268\n",
      "Epoch 200/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1706 - accuracy: 0.9538 - val_loss: 0.1960 - val_accuracy: 0.9318\n",
      "Epoch 201/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1780 - accuracy: 0.9513 - val_loss: 0.2032 - val_accuracy: 0.9334\n",
      "Epoch 202/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.1808 - accuracy: 0.9501 - val_loss: 0.2048 - val_accuracy: 0.9318\n",
      "Epoch 203/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.1798 - accuracy: 0.9480 - val_loss: 0.1924 - val_accuracy: 0.9318\n",
      "Epoch 204/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.1751 - accuracy: 0.9501 - val_loss: 0.1894 - val_accuracy: 0.9401\n",
      "Epoch 205/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.1689 - accuracy: 0.9526 - val_loss: 0.2003 - val_accuracy: 0.9318\n",
      "Epoch 206/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.1661 - accuracy: 0.9526 - val_loss: 0.1941 - val_accuracy: 0.9285\n",
      "Epoch 207/300\n",
      "2404/2404 [==============================] - 2s 704us/sample - loss: 0.1639 - accuracy: 0.9563 - val_loss: 0.1965 - val_accuracy: 0.9185\n",
      "Epoch 208/300\n",
      "2404/2404 [==============================] - 2s 734us/sample - loss: 0.1715 - accuracy: 0.9509 - val_loss: 0.2014 - val_accuracy: 0.9185\n",
      "Epoch 209/300\n",
      "2404/2404 [==============================] - 2s 726us/sample - loss: 0.1709 - accuracy: 0.9509 - val_loss: 0.1924 - val_accuracy: 0.9318\n",
      "Epoch 210/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1651 - accuracy: 0.9472 - val_loss: 0.2074 - val_accuracy: 0.9185\n",
      "Epoch 211/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.1591 - accuracy: 0.9538 - val_loss: 0.1958 - val_accuracy: 0.9235\n",
      "Epoch 212/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1549 - accuracy: 0.9588 - val_loss: 0.1917 - val_accuracy: 0.9384\n",
      "Epoch 213/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1498 - accuracy: 0.9534 - val_loss: 0.1927 - val_accuracy: 0.9235\n",
      "Epoch 214/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1609 - accuracy: 0.9551 - val_loss: 0.1941 - val_accuracy: 0.9285\n",
      "Epoch 215/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.1457 - accuracy: 0.9584 - val_loss: 0.1833 - val_accuracy: 0.9334\n",
      "Epoch 216/300\n",
      "2404/2404 [==============================] - 2s 706us/sample - loss: 0.1452 - accuracy: 0.9588 - val_loss: 0.1902 - val_accuracy: 0.9201\n",
      "Epoch 217/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.1522 - accuracy: 0.9538 - val_loss: 0.1757 - val_accuracy: 0.9451\n",
      "Epoch 218/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.1530 - accuracy: 0.9601 - val_loss: 0.1808 - val_accuracy: 0.9384\n",
      "Epoch 219/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1532 - accuracy: 0.9601 - val_loss: 0.1766 - val_accuracy: 0.9418\n",
      "Epoch 220/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.1488 - accuracy: 0.9592 - val_loss: 0.1727 - val_accuracy: 0.9468\n",
      "Epoch 221/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.1577 - accuracy: 0.9530 - val_loss: 0.1643 - val_accuracy: 0.9551\n",
      "Epoch 222/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.1564 - accuracy: 0.9559 - val_loss: 0.1770 - val_accuracy: 0.9451\n",
      "Epoch 223/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.1578 - accuracy: 0.9509 - val_loss: 0.1814 - val_accuracy: 0.9318\n",
      "Epoch 224/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.1509 - accuracy: 0.9592 - val_loss: 0.1721 - val_accuracy: 0.9434\n",
      "Epoch 225/300\n",
      "2404/2404 [==============================] - 2s 705us/sample - loss: 0.1571 - accuracy: 0.9542 - val_loss: 0.1726 - val_accuracy: 0.9434\n",
      "Epoch 226/300\n",
      "2404/2404 [==============================] - 2s 705us/sample - loss: 0.1484 - accuracy: 0.9592 - val_loss: 0.1701 - val_accuracy: 0.9401\n",
      "Epoch 227/300\n",
      "2404/2404 [==============================] - 2s 768us/sample - loss: 0.1501 - accuracy: 0.9580 - val_loss: 0.1710 - val_accuracy: 0.9501\n",
      "Epoch 228/300\n",
      "2404/2404 [==============================] - 2s 718us/sample - loss: 0.1497 - accuracy: 0.9555 - val_loss: 0.1734 - val_accuracy: 0.9418\n",
      "Epoch 229/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1418 - accuracy: 0.9617 - val_loss: 0.1681 - val_accuracy: 0.9434\n",
      "Epoch 230/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1362 - accuracy: 0.9671 - val_loss: 0.1667 - val_accuracy: 0.9418\n",
      "Epoch 231/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1395 - accuracy: 0.9617 - val_loss: 0.1707 - val_accuracy: 0.9384\n",
      "Epoch 232/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1398 - accuracy: 0.9572 - val_loss: 0.1705 - val_accuracy: 0.9351\n",
      "Epoch 233/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.1393 - accuracy: 0.9576 - val_loss: 0.1726 - val_accuracy: 0.9401\n",
      "Epoch 234/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.1355 - accuracy: 0.9601 - val_loss: 0.1693 - val_accuracy: 0.9451\n",
      "Epoch 235/300\n",
      "2404/2404 [==============================] - 2s 703us/sample - loss: 0.1318 - accuracy: 0.9621 - val_loss: 0.1794 - val_accuracy: 0.9434\n",
      "Epoch 236/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.1397 - accuracy: 0.9617 - val_loss: 0.1751 - val_accuracy: 0.9418\n",
      "Epoch 237/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1318 - accuracy: 0.9630 - val_loss: 0.1829 - val_accuracy: 0.9384\n",
      "Epoch 238/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.1311 - accuracy: 0.9634 - val_loss: 0.1815 - val_accuracy: 0.9384\n",
      "Epoch 239/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.1280 - accuracy: 0.9667 - val_loss: 0.1831 - val_accuracy: 0.9418\n",
      "Epoch 240/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1285 - accuracy: 0.9613 - val_loss: 0.1847 - val_accuracy: 0.9368\n",
      "Epoch 241/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.1229 - accuracy: 0.9667 - val_loss: 0.1733 - val_accuracy: 0.9434\n",
      "Epoch 242/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.1179 - accuracy: 0.9721 - val_loss: 0.1759 - val_accuracy: 0.9368\n",
      "Epoch 243/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1123 - accuracy: 0.9692 - val_loss: 0.1811 - val_accuracy: 0.9285\n",
      "Epoch 244/300\n",
      "2404/2404 [==============================] - 2s 713us/sample - loss: 0.1190 - accuracy: 0.9684 - val_loss: 0.1777 - val_accuracy: 0.9318\n",
      "Epoch 245/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1310 - accuracy: 0.9634 - val_loss: 0.1733 - val_accuracy: 0.9418\n",
      "Epoch 246/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.1194 - accuracy: 0.9667 - val_loss: 0.1764 - val_accuracy: 0.9384\n",
      "Epoch 247/300\n",
      "2404/2404 [==============================] - 2s 720us/sample - loss: 0.1259 - accuracy: 0.9671 - val_loss: 0.1749 - val_accuracy: 0.9401\n",
      "Epoch 248/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1240 - accuracy: 0.9671 - val_loss: 0.1732 - val_accuracy: 0.9434\n",
      "Epoch 249/300\n",
      "2404/2404 [==============================] - 2s 720us/sample - loss: 0.1210 - accuracy: 0.9709 - val_loss: 0.1685 - val_accuracy: 0.9384\n",
      "Epoch 250/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1203 - accuracy: 0.9713 - val_loss: 0.1634 - val_accuracy: 0.9534\n",
      "Epoch 251/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.1186 - accuracy: 0.9705 - val_loss: 0.1585 - val_accuracy: 0.9468\n",
      "Epoch 252/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1095 - accuracy: 0.9725 - val_loss: 0.1630 - val_accuracy: 0.9484\n",
      "Epoch 253/300\n",
      "2404/2404 [==============================] - 2s 718us/sample - loss: 0.1166 - accuracy: 0.9642 - val_loss: 0.1596 - val_accuracy: 0.9368\n",
      "Epoch 254/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.1135 - accuracy: 0.9688 - val_loss: 0.1565 - val_accuracy: 0.9351\n",
      "Epoch 255/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.1137 - accuracy: 0.9696 - val_loss: 0.1527 - val_accuracy: 0.9434\n",
      "Epoch 256/300\n",
      "2404/2404 [==============================] - 2s 705us/sample - loss: 0.1146 - accuracy: 0.9692 - val_loss: 0.1572 - val_accuracy: 0.9334\n",
      "Epoch 257/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.1198 - accuracy: 0.9692 - val_loss: 0.1446 - val_accuracy: 0.9517\n",
      "Epoch 258/300\n",
      "2404/2404 [==============================] - 2s 705us/sample - loss: 0.1094 - accuracy: 0.9759 - val_loss: 0.1456 - val_accuracy: 0.9534\n",
      "Epoch 259/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.1094 - accuracy: 0.9763 - val_loss: 0.1483 - val_accuracy: 0.9451\n",
      "Epoch 260/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1133 - accuracy: 0.9713 - val_loss: 0.1444 - val_accuracy: 0.9501\n",
      "Epoch 261/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.1058 - accuracy: 0.9742 - val_loss: 0.1403 - val_accuracy: 0.9567\n",
      "Epoch 262/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.1030 - accuracy: 0.9742 - val_loss: 0.1378 - val_accuracy: 0.9551\n",
      "Epoch 263/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.1010 - accuracy: 0.9784 - val_loss: 0.1420 - val_accuracy: 0.9584\n",
      "Epoch 264/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.0990 - accuracy: 0.9734 - val_loss: 0.1460 - val_accuracy: 0.9468\n",
      "Epoch 265/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.1109 - accuracy: 0.9684 - val_loss: 0.1468 - val_accuracy: 0.9517\n",
      "Epoch 266/300\n",
      "2404/2404 [==============================] - 2s 724us/sample - loss: 0.1020 - accuracy: 0.9734 - val_loss: 0.1485 - val_accuracy: 0.9418\n",
      "Epoch 267/300\n",
      "2404/2404 [==============================] - 2s 715us/sample - loss: 0.0990 - accuracy: 0.9738 - val_loss: 0.1416 - val_accuracy: 0.9551\n",
      "Epoch 268/300\n",
      "2404/2404 [==============================] - 2s 720us/sample - loss: 0.0915 - accuracy: 0.9788 - val_loss: 0.1521 - val_accuracy: 0.9384\n",
      "Epoch 269/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.0953 - accuracy: 0.9784 - val_loss: 0.1424 - val_accuracy: 0.9517\n",
      "Epoch 270/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.0997 - accuracy: 0.9700 - val_loss: 0.1447 - val_accuracy: 0.9517\n",
      "Epoch 271/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.0943 - accuracy: 0.9775 - val_loss: 0.1470 - val_accuracy: 0.9484\n",
      "Epoch 272/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.0986 - accuracy: 0.9725 - val_loss: 0.1475 - val_accuracy: 0.9484\n",
      "Epoch 273/300\n",
      "2404/2404 [==============================] - 2s 702us/sample - loss: 0.1014 - accuracy: 0.9730 - val_loss: 0.1469 - val_accuracy: 0.9418\n",
      "Epoch 274/300\n",
      "2404/2404 [==============================] - 2s 712us/sample - loss: 0.0929 - accuracy: 0.9784 - val_loss: 0.1399 - val_accuracy: 0.9601\n",
      "Epoch 275/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.0903 - accuracy: 0.9784 - val_loss: 0.1338 - val_accuracy: 0.9634\n",
      "Epoch 276/300\n",
      "2404/2404 [==============================] - 2s 707us/sample - loss: 0.0971 - accuracy: 0.9750 - val_loss: 0.1374 - val_accuracy: 0.9534\n",
      "Epoch 277/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.0927 - accuracy: 0.9784 - val_loss: 0.1399 - val_accuracy: 0.9584\n",
      "Epoch 278/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.0904 - accuracy: 0.9780 - val_loss: 0.1452 - val_accuracy: 0.9517\n",
      "Epoch 279/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.0892 - accuracy: 0.9792 - val_loss: 0.1432 - val_accuracy: 0.9501\n",
      "Epoch 280/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.0863 - accuracy: 0.9788 - val_loss: 0.1330 - val_accuracy: 0.9601\n",
      "Epoch 281/300\n",
      "2404/2404 [==============================] - 2s 753us/sample - loss: 0.0904 - accuracy: 0.9813 - val_loss: 0.1376 - val_accuracy: 0.9551\n",
      "Epoch 282/300\n",
      "2404/2404 [==============================] - 2s 785us/sample - loss: 0.0923 - accuracy: 0.9759 - val_loss: 0.1343 - val_accuracy: 0.9601\n",
      "Epoch 283/300\n",
      "2404/2404 [==============================] - 2s 787us/sample - loss: 0.0878 - accuracy: 0.9784 - val_loss: 0.1434 - val_accuracy: 0.9451\n",
      "Epoch 284/300\n",
      "2404/2404 [==============================] - 2s 785us/sample - loss: 0.0880 - accuracy: 0.9775 - val_loss: 0.1419 - val_accuracy: 0.9517\n",
      "Epoch 285/300\n",
      "2404/2404 [==============================] - 2s 732us/sample - loss: 0.0835 - accuracy: 0.9829 - val_loss: 0.1383 - val_accuracy: 0.9484\n",
      "Epoch 286/300\n",
      "2404/2404 [==============================] - 2s 779us/sample - loss: 0.0860 - accuracy: 0.9813 - val_loss: 0.1342 - val_accuracy: 0.9517\n",
      "Epoch 287/300\n",
      "2404/2404 [==============================] - 2s 772us/sample - loss: 0.0833 - accuracy: 0.9842 - val_loss: 0.1476 - val_accuracy: 0.9517\n",
      "Epoch 288/300\n",
      "2404/2404 [==============================] - 2s 782us/sample - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.1381 - val_accuracy: 0.9567\n",
      "Epoch 289/300\n",
      "2404/2404 [==============================] - 2s 754us/sample - loss: 0.0787 - accuracy: 0.9829 - val_loss: 0.1399 - val_accuracy: 0.9501\n",
      "Epoch 290/300\n",
      "2404/2404 [==============================] - 2s 705us/sample - loss: 0.0819 - accuracy: 0.9834 - val_loss: 0.1497 - val_accuracy: 0.9468\n",
      "Epoch 291/300\n",
      "2404/2404 [==============================] - 2s 716us/sample - loss: 0.0786 - accuracy: 0.9834 - val_loss: 0.1470 - val_accuracy: 0.9468\n",
      "Epoch 292/300\n",
      "2404/2404 [==============================] - 2s 706us/sample - loss: 0.0873 - accuracy: 0.9796 - val_loss: 0.1361 - val_accuracy: 0.9584\n",
      "Epoch 293/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.0868 - accuracy: 0.9804 - val_loss: 0.1366 - val_accuracy: 0.9584\n",
      "Epoch 294/300\n",
      "2404/2404 [==============================] - 2s 711us/sample - loss: 0.0766 - accuracy: 0.9821 - val_loss: 0.1336 - val_accuracy: 0.9551\n",
      "Epoch 295/300\n",
      "2404/2404 [==============================] - 2s 708us/sample - loss: 0.0812 - accuracy: 0.9821 - val_loss: 0.1350 - val_accuracy: 0.9601\n",
      "Epoch 296/300\n",
      "2404/2404 [==============================] - 2s 710us/sample - loss: 0.0791 - accuracy: 0.9838 - val_loss: 0.1344 - val_accuracy: 0.9567\n",
      "Epoch 297/300\n",
      "2404/2404 [==============================] - 2s 717us/sample - loss: 0.0818 - accuracy: 0.9813 - val_loss: 0.1308 - val_accuracy: 0.9567\n",
      "Epoch 298/300\n",
      "2404/2404 [==============================] - 2s 709us/sample - loss: 0.0750 - accuracy: 0.9838 - val_loss: 0.1350 - val_accuracy: 0.9451\n",
      "Epoch 299/300\n",
      "2404/2404 [==============================] - 2s 705us/sample - loss: 0.0810 - accuracy: 0.9788 - val_loss: 0.1289 - val_accuracy: 0.9634\n",
      "Epoch 300/300\n",
      "2404/2404 [==============================] - 2s 714us/sample - loss: 0.0706 - accuracy: 0.9859 - val_loss: 0.1259 - val_accuracy: 0.9601\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x=[X_act_batched_train, X_acw_batched_train, X_dc_batched_train, X_pm_batched_train],\n",
    "                    y=y_train, \n",
    "                    validation_data=(\n",
    "                        [X_act_batched_test,\n",
    "                         X_acw_batched_test,X_dc_batched_test, X_pm_batched_test], y_test),\n",
    "                    epochs=300,  batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "43e8c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 96.00665557404326\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x345.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = model.predict([X_act_batched_test, X_acw_batched_test, X_dc_batched_test, X_pm_batched_test])\n",
    "yhat = np.argmax(yhat, axis=1)\n",
    "y_test_actual = np.argmax(y_test, axis=1)\n",
    "print('Validation:', accuracy_score(y_test_actual, yhat)*100)\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv2022] *",
   "language": "python",
   "name": "conda-env-mlenv2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
