{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723a5bd0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7bd5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b888dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On act\n",
      "On acw\n",
      "On dc\n",
      "On pm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, '1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "# Test out the read in helper function\n",
    "def get_subject_action(sensor, full_path):\n",
    "    index = full_path.find(sensor)\n",
    "    index += len(sensor)\n",
    "    subject = int(full_path[index+1:index+3])\n",
    "    action = int(full_path[index+4:index+6])\n",
    "    if action == 4:\n",
    "        if full_path.find(f\"{sensor}_1\") > 0:\n",
    "            action = '4-1'\n",
    "        else:\n",
    "            action = '4-2'\n",
    "        \n",
    "    return (subject, str(action))\n",
    "\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                #print(full_path, get_subject_action(sensor, full_path))\n",
    "                \n",
    "test_str = '.\\\\data\\\\act\\\\01\\\\01_act_1.csv'\n",
    "get_subject_action('act', test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201498a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1982839cd264ef6a445d1861b6ae599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load data:   0%|          | 0/956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_data = {\n",
    "    'act': None,\n",
    "    'acw': None,\n",
    "    'dc': None,\n",
    "    'pm': None,\n",
    "}\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'act': ['times', 'X', 'Y', 'Z'],\n",
    "    'acw': ['times', 'X', 'Y', 'Z'],\n",
    "    'dc': ['times'],\n",
    "    'pm': ['times']\n",
    "}\n",
    "for i in range(1,513):\n",
    "    headers['pm'].append(f\"sensor_{i}\")\n",
    "for i in range(1,193):\n",
    "    headers['dc'].append(f\"sensor_{i}\")\n",
    "\n",
    "actions = ['1', '2', '3', '4-1', '4-2', '5', '6', '7']\n",
    "\n",
    "sensor_list = ['act', 'acw', 'dc', 'pm']\n",
    "sensor_list = ['acw']\n",
    "\n",
    "# there are 956 files in our dataset\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(desc=\"load data\", total=956)\n",
    "for sensor in sensor_list:\n",
    "    for sensor_dir in glob.iglob('.\\\\data\\\\' + sensor ):\n",
    "        #print(f\"On {sensor}\")\n",
    "        for subject_id, subject_dir in enumerate(glob.iglob(f\"{sensor_dir}\\\\*\")):\n",
    "            for action_id, file in enumerate(os.listdir(subject_dir)):\n",
    "                full_path = f\"{subject_dir}\\\\{file}\"\n",
    "                df_tmp = pd.read_csv(full_path, names=headers[sensor])\n",
    "                i+=1\n",
    "                pbar.update(1)\n",
    "                subject, action = get_subject_action(sensor, full_path)\n",
    "                # add one to make it match the given format\n",
    "                df_tmp['subject'] = subject\n",
    "                df_tmp['action'] = action\n",
    "                if total_data[sensor] is None:\n",
    "                    total_data[sensor] = df_tmp\n",
    "                else:\n",
    "                    total_data[sensor] = pd.concat([total_data[sensor], df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59df85fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2904/3491877615.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "total_data['dc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23401cb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2904/3224333569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'act'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "total_data['act'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da7e5a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 5496.6317991631795\n",
      "median 6042.0\n",
      "max 11320\n",
      "min 1628\n",
      "count 239\n"
     ]
    }
   ],
   "source": [
    "total_data['acw'].head()\n",
    "df_grouped = total_data['acw'].groupby([\"subject\",\"action\"]).count()\n",
    "type(df_grouped)\n",
    "print('mean', df_grouped[\"times\"].mean())\n",
    "print('median', df_grouped[\"times\"].median())\n",
    "print('max', df_grouped[\"times\"].max())\n",
    "print('min', df_grouped[\"times\"].min())\n",
    "print('count', df_grouped[\"times\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d06220",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2904/873497721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "total_data['pm'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96bab8df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acw\n",
      "['1' '2' '3' '4-1' '4-2' '5' '6' '7']\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1313695 entries, 0 to 6013\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count    Dtype  \n",
      "---  ------   --------------    -----  \n",
      " 0   times    1313695 non-null  object \n",
      " 1   X        1313695 non-null  float64\n",
      " 2   Y        1313695 non-null  float64\n",
      " 3   Z        1313695 non-null  float64\n",
      " 4   subject  1313695 non-null  int64  \n",
      " 5   action   1313695 non-null  object \n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 70.2+ MB\n",
      "None\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in total_data.keys():\n",
    "    if total_data[key] is not None:\n",
    "        print(key)\n",
    "        print(total_data[key]['action'].unique())\n",
    "        print(total_data[key]['subject'].unique())\n",
    "        for header in headers[key]:\n",
    "            if(total_data[key][header].isnull().values.any()):\n",
    "                print(f\"{header} has Null data\")\n",
    "        print(total_data[key].info())\n",
    "        print('-------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450c4b3",
   "metadata": {},
   "source": [
    "# New attpempt.\n",
    "Sample each observartion into equal chunks to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74a1c7",
   "metadata": {},
   "source": [
    "## Get the y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6401c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times         X         Y        Z  subject action\n",
       "0  2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1  2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2  2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3  2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4  2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist = total_data['acw']\n",
    "df_wrist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741d1d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "      <th>action_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times         X         Y        Z  subject action  \\\n",
       "0  2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1   \n",
       "1  2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1   \n",
       "2  2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1   \n",
       "3  2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1   \n",
       "4  2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1   \n",
       "\n",
       "   action_encoded  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df_wrist['action'].values)\n",
    "df_wrist['action_encoded'] = y\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(df_wrist['action_encoded'])\n",
    "\n",
    "df_wrist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bfd8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.get_dummies(df_wrist.action, prefix='action_ohe')\n",
    "\n",
    "y_ohe_columns = df_y.columns\n",
    "\n",
    "df_wrist = pd.concat([df_wrist, df_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c99c471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['action_ohe_1', 'action_ohe_2', 'action_ohe_3', 'action_ohe_4-1',\n",
       "       'action_ohe_4-2', 'action_ohe_5', 'action_ohe_6', 'action_ohe_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00404f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "      <th>action_encoded</th>\n",
       "      <th>action_ohe_1</th>\n",
       "      <th>action_ohe_2</th>\n",
       "      <th>action_ohe_3</th>\n",
       "      <th>action_ohe_4-1</th>\n",
       "      <th>action_ohe_4-2</th>\n",
       "      <th>action_ohe_5</th>\n",
       "      <th>action_ohe_6</th>\n",
       "      <th>action_ohe_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times         X         Y        Z  subject action  \\\n",
       "0  2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1   \n",
       "1  2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1   \n",
       "2  2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1   \n",
       "3  2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1   \n",
       "4  2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1   \n",
       "\n",
       "   action_encoded  action_ohe_1  action_ohe_2  action_ohe_3  action_ohe_4-1  \\\n",
       "0               0             1             0             0               0   \n",
       "1               0             1             0             0               0   \n",
       "2               0             1             0             0               0   \n",
       "3               0             1             0             0               0   \n",
       "4               0             1             0             0               0   \n",
       "\n",
       "   action_ohe_4-2  action_ohe_5  action_ohe_6  action_ohe_7  \n",
       "0               0             0             0             0  \n",
       "1               0             0             0             0  \n",
       "2               0             0             0             0  \n",
       "3               0             0             0             0  \n",
       "4               0             0             0             0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f859b",
   "metadata": {},
   "source": [
    "### Testing out a SIMPLE RNN on just the wrist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1fea0070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "283249d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator from page 211 from text book (first edition)\n",
    "def generator(data, target, lookback, min_index,\n",
    "              max_index, batch_size=128, step=1):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - 1\n",
    "    i = min_index + lookback\n",
    "    cnt = 0\n",
    "    while 1:\n",
    "        \n",
    "        if i + batch_size >= max_index:\n",
    "            yield None, None\n",
    "        rows = np.arange(i, min(i + batch_size, max_index))\n",
    "        \n",
    "        \n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                            lookback // step,\n",
    "                            data.shape[-1]))\n",
    "        targets = np.zeros((len(rows), len(y_ohe_columns)))\n",
    "        for j, row in enumerate(rows):\n",
    "            indicies = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = data[indicies]\n",
    "            targets[j] = target\n",
    "        cnt += 1\n",
    "        i += samples.shape[1]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1ccc7",
   "metadata": {},
   "source": [
    "## This is used to count how many more next()'s we have to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6fd9e0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_total_steps(data, target, lookback, min_index,\n",
    "                      max_index, batch_size=128, step=1):\n",
    "    \n",
    "    cnt = 0\n",
    "    gen = generator(data, target, lookback, min_index, max_index, batch_size=128, step=1)\n",
    "    samples, target = next(gen)\n",
    "    while samples is not None:\n",
    "        cnt += 1\n",
    "        samples, target = next(gen)\n",
    "        \n",
    "    return cnt\n",
    "\n",
    "def count_total_steps_set(df, subjects, lookback, min_index,\n",
    "                          max_index, batch_size=128, step=1):\n",
    "    \n",
    "    cnt = 0\n",
    "    for subject in subjects:\n",
    "        actions = df[df['subject'] == subject]['action'].unique()\n",
    "        for action in actions:\n",
    "            df_subset = df[(df['action'] == action) & (df['subject'] == subject)]\n",
    "            x_data = df_subset[[\"X\", \"Y\", \"Z\"]].to_numpy()\n",
    "            target = df_subset[y_ohe_columns].to_numpy()[0]\n",
    "            cnt += count_total_steps(x_data, target, lookback, min_index,\n",
    "                          max_index, batch_size, step)\n",
    "    return cnt\n",
    "\n",
    "subjects = [1,1]\n",
    "count_total_steps_set(df_wrist, subjects, lookback=500, min_index=0,\n",
    "                      max_index=None, batch_size=1, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "48d72a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_generator(df, lookback, min_index,\n",
    "                     max_index, batch_size=128, step=1):\n",
    "    \n",
    "    subjects = df['subject'].unique()\n",
    "    idx_subjects = 0\n",
    "    actions = df[df['subject'] == subjects[idx_subjects]]['action_encoded'].unique()\n",
    "    idx_actions = 0\n",
    "    data = df[(df['subject'] == subjects[idx_subjects]) \n",
    "              & (df['action_encoded'] == actions[idx_actions])]\n",
    "    \n",
    "    data = data[[\"X\", \"Y\", \"Z\"]]\n",
    "    target = df[y_ohe_columns].to_numpy()[0]\n",
    "    gen = generator(data.to_numpy(), target, lookback, min_index=0,\n",
    "                    max_index=None, batch_size=batch_size, step=step)\n",
    "    \n",
    "    samples, targets = next(gen)\n",
    "    while 1:\n",
    "        while samples is not None:\n",
    "            yield samples, targets\n",
    "            samples, targets = next(gen)\n",
    "        idx_actions += 1\n",
    "        if idx_actions >= len(actions):\n",
    "            actions = df[df['subject'] == subjects[idx_subjects]]['action_encoded'].unique()\n",
    "            idx_actions = 0\n",
    "            idx_subjects = (idx_subjects + 1) % len(subjects)\n",
    "        \n",
    "        data = df[(df['subject'] == subjects[idx_subjects]) \n",
    "                  & (df['action_encoded'] == actions[idx_actions])]\n",
    "        data = data[[\"X\", \"Y\", \"Z\"]]\n",
    "        target = df[y_ohe_columns].to_numpy()[0]\n",
    "        gen = generator(data.to_numpy(), target, lookback, min_index=0,\n",
    "                        max_index=None, batch_size=batch_size, step=step)\n",
    "        samples, targets = next(gen)\n",
    "    \n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b6858a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 5, 6, 7])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist[df_wrist['subject'] == 22]['action_encoded'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5509a",
   "metadata": {},
   "source": [
    "## Temprarily split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "196242b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4-1', '5', '6', '7'], dtype=object)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df_wrist[df_wrist['subject'] == 22]['action'].unique()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "716deaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813 1624\n"
     ]
    }
   ],
   "source": [
    "test_steps = count_total_steps_set(df_wrist, range(21,31), lookback=500, min_index=0,\n",
    "                                   max_index=None, batch_size=1, step=1)\n",
    "train_steps = count_total_steps_set(df_wrist, range(1,21), lookback=500, min_index=0,\n",
    "                                    max_index=None, batch_size=1, step=1)\n",
    "print(test_steps, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "00d9d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use subject 1-20 as train and 21-30 as test.\n",
    "df_train = df_wrist[(df_wrist['subject'] >= 1) & df_wrist['subject'] <= 20]\n",
    "df_test = df_wrist[(df_wrist['subject'] >= 21) & df_wrist['subject'] <= 30]\n",
    "gen_train = parent_generator(df_train, lookback=500, min_index=0,\n",
    "                             max_index=None, batch_size=1, step=1)\n",
    "\n",
    "gen_test = parent_generator(df_test, lookback=500, min_index=0,\n",
    "                            max_index=None, batch_size=1, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5b95933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.GRU(32, input_shape=(500,3), return_sequences=True))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(8))\n",
    "\n",
    "model.compile(optimizer=RMSprop(), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "170caf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 248/1624 [===>..........................] - ETA: 10:05 - loss: 0.0400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit_generator(gen_train,\n",
    "                              steps_per_epoch=1624,\n",
    "                              epochs=10,\n",
    "                              validation_data=gen_test,\n",
    "                              validation_steps=813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "906916c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f295c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5114678740501404"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate_generator(generator=gen_test,\n",
    "                                 steps=100)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9f6e669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0145549 ,  0.00976152,  0.10503835,  0.04565459, -0.03340241,\n",
       "        -0.0442297 ,  0.02833325, -0.03756842],\n",
       "       [-1.0178233 ,  0.01124291,  0.10404504,  0.04416018, -0.03258038,\n",
       "        -0.04285943,  0.02684881, -0.03867058],\n",
       "       [-1.0159602 ,  0.00932069,  0.10596977,  0.044293  , -0.03253376,\n",
       "        -0.04134046,  0.02452804, -0.03747151],\n",
       "       [-1.015951  ,  0.00764417,  0.10586486,  0.04318611, -0.02906533,\n",
       "        -0.04183165,  0.02208826, -0.03831754],\n",
       "       [-1.0136027 ,  0.00682264,  0.10654686,  0.0445296 , -0.02879378,\n",
       "        -0.04037816,  0.02283987, -0.03783885],\n",
       "       [-1.0140193 ,  0.00601384,  0.10667387,  0.04528576, -0.03075778,\n",
       "        -0.03951227,  0.02433395, -0.03603151],\n",
       "       [-1.0141785 ,  0.00371129,  0.10604554,  0.04666936, -0.03249029,\n",
       "        -0.0395259 ,  0.02923448, -0.03490284],\n",
       "       [-1.0158632 ,  0.0062406 ,  0.10369238,  0.04347461, -0.03462474,\n",
       "        -0.04227839,  0.03201219, -0.03662262],\n",
       "       [-1.0173702 ,  0.00678103,  0.10531112,  0.04373437, -0.03847118,\n",
       "        -0.04057399,  0.03243859, -0.03636907],\n",
       "       [-1.0192782 ,  0.00669905,  0.10693869,  0.04279293, -0.04029401,\n",
       "        -0.03990717,  0.03311299, -0.03639473]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_generator(generator=gen_test,\n",
    "                        steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8baefc6",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36e12008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times         X         Y        Z  subject action\n",
       "0  2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1  2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2  2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3  2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4  2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist_sample_1 = df_wrist[(df_wrist['subject'] == 1) & (df_wrist['action'] == '1')]\n",
    "df_wrist_sample_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c09db90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.125   , -0.046875,  0.90625 ],\n",
       "       [ 0.109375, -0.0625  ,  0.90625 ],\n",
       "       [ 0.109375, -0.0625  ,  0.90625 ],\n",
       "       ...,\n",
       "       [ 0.09375 , -0.265625,  0.875   ],\n",
       "       [ 0.09375 , -0.265625,  0.875   ],\n",
       "       [ 0.09375 , -0.265625,  0.875   ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X = df_wrist_sample_1[['X', 'Y', 'Z']].to_numpy()\n",
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "064c514e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '1', '1', '1'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Y = df_wrist_sample_1['action'].to_numpy()\n",
    "data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f2931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1d6f44c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5222\n"
     ]
    }
   ],
   "source": [
    "###### print(data_X.shape)\n",
    "ret = generator(data_X, '1', lookback=1000, min_index=0,\n",
    "                max_index=None, step=5, batch_size=1)\n",
    "train, test = next(ret)\n",
    "ct = 0\n",
    "samps = []\n",
    "while train is not None:\n",
    "    ct += 1\n",
    "    train, test = next(ret)\n",
    "    if train is not None:\n",
    "        samps.append(train)\n",
    "        \n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ff809",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8dcb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for subject in df_wrist['subject'].unique():\n",
    "    for action in df_wrist['action'].unique():\n",
    "        subset = df_wrist[(df_wrist['subject'] == subject) & (df_wrist['action'] == action)]\n",
    "        a = subset[[\"X\", \"Y\", \"Z\"]].to_numpy()\n",
    "        x.append(a)\n",
    "        y.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edf7ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, dtype=object)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89d94ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "942efd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb80f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "252cd475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidir-lstm (Bidirectional)   (None, 128)               33792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 42,113\n",
      "Trainable params: 42,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## build the model\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(3,1), name='input-layer'),\n",
    "    \n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, name='lstm-layer'),\n",
    "        name='bidir-lstm'), \n",
    "\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523deac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ec85066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "456679f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input-layer to have 3 dimensions, but got array with shape (240, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8140/2251146293.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     epochs=10)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input-layer to have 3 dimensions, but got array with shape (240, 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "643b6aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5958, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96981e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 1440)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                46112     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 46,376\n",
      "Trainable params: 46,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(20 //3, x.shape[-1])))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(8))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "188b4838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.484375, -0.53125 , -0.75    ],\n",
       "       [-0.484375, -0.546875, -0.734375],\n",
       "       [-0.46875 , -0.546875, -0.734375],\n",
       "       ...,\n",
       "       [ 0.234375, -0.578125, -0.796875],\n",
       "       [ 0.25    , -0.578125, -0.78125 ],\n",
       "       [ 0.234375, -0.578125, -0.78125 ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e6daff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 50)                10800     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,851\n",
      "Trainable params: 10,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_test = tf.keras.Sequential()\n",
    "model_test.add(layers.LSTM(50, input_shape=(240, 3)))\n",
    "model_test.add(layers.Dense(1))\n",
    "model_test.compile(loss='mae', optimizer='adam')\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fdfe4aef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_9_input to have 3 dimensions, but got array with shape (240, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8140/3262812390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_9_input to have 3 dimensions, but got array with shape (240, 1)"
     ]
    }
   ],
   "source": [
    "hist = model_test.fit(x, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ec8c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8bc7b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "72e8679d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_1_input to have 3 dimensions, but got array with shape (240, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8140/1659118047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_1_input to have 3 dimensions, but got array with shape (240, 1)"
     ]
    }
   ],
   "source": [
    "model.fit(x=x, y=y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6ff8c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a52f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrist = total_data['acw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a680071d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        times         X         Y        Z  subject action\n",
       "0  2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1  2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2  2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3  2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4  2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "578061fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist['subject'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee40a253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>subject</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-08 11:34:51.474000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-08 11:34:51.485000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-08 11:34:51.495000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-08 11:34:51.505000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-08 11:34:51.516000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>2018-11-08 11:35:56.373000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>2018-11-08 11:35:56.383000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>2018-11-08 11:35:56.394000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272</th>\n",
       "      <td>2018-11-08 11:35:56.404000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>2018-11-08 11:35:56.414000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6274 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           times         X         Y        Z  subject action\n",
       "0     2018-11-08 11:34:51.474000  0.125000 -0.046875  0.90625        1      1\n",
       "1     2018-11-08 11:34:51.485000  0.109375 -0.062500  0.90625        1      1\n",
       "2     2018-11-08 11:34:51.495000  0.109375 -0.062500  0.90625        1      1\n",
       "3     2018-11-08 11:34:51.505000  0.125000 -0.062500  0.90625        1      1\n",
       "4     2018-11-08 11:34:51.516000  0.125000 -0.062500  0.90625        1      1\n",
       "...                          ...       ...       ...      ...      ...    ...\n",
       "6269  2018-11-08 11:35:56.373000  0.093750 -0.265625  0.87500        1      1\n",
       "6270  2018-11-08 11:35:56.383000  0.093750 -0.281250  0.87500        1      1\n",
       "6271  2018-11-08 11:35:56.394000  0.093750 -0.265625  0.87500        1      1\n",
       "6272  2018-11-08 11:35:56.404000  0.093750 -0.265625  0.87500        1      1\n",
       "6273  2018-11-08 11:35:56.414000  0.093750 -0.265625  0.87500        1      1\n",
       "\n",
       "[6274 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrist[(df_wrist['subject'] == 1) & (df_wrist['action'] == '1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79efbf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac91fec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff54927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 37644)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp/ipykernel_11344/4143097367.py\", line 11, in <module>\n",
      "    X = np.vstack([X, tmp_np])\n",
      "  File \"<__array_function__ internals>\", line 6, in vstack\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 282, in vstack\n",
      "    return _nx.concatenate(arrs, 0)\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 37644\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp/ipykernel_11344/4143097367.py\", line 11, in <module>\n",
      "    X = np.vstack([X, tmp_np])\n",
      "  File \"<__array_function__ internals>\", line 6, in vstack\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 282, in vstack\n",
      "    return _nx.concatenate(arrs, 0)\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 37644\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp/ipykernel_11344/4143097367.py\", line 11, in <module>\n",
      "    X = np.vstack([X, tmp_np])\n",
      "  File \"<__array_function__ internals>\", line 6, in vstack\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 282, in vstack\n",
      "    return _nx.concatenate(arrs, 0)\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 37644\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Nick\\anaconda3\\envs\\mlenv2022\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "# Reformate the data to be each sample X, Y, Z, X, Y, Z, ....\n",
    "X = ma.empty\n",
    "\n",
    "for subject in df_wrist['subject'].unique():\n",
    "    for action in df_wrist['action'].unique():\n",
    "        subset = df_wrist[(df_wrist['subject'] == subject) & (df_wrist['action'] == action)]\n",
    "        tmp_np = subset.to_numpy()\n",
    "        tmp_shape = tmp_np.shape\n",
    "        tmp_np = tmp_np.reshape(1, tmp_shape[0] * tmp_shape[1])\n",
    "        print(tmp_np.shape)\n",
    "        X = np.vstack([X, tmp_np])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c5808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv2022] *",
   "language": "python",
   "name": "conda-env-mlenv2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
